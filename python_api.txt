--- FILE: groggy/graph_table.py ---
"""
GraphTable - DataFrame-like views for graph data

This module provides GraphTable class for tabular views of graph nodes and edges,
similar to pandas DataFrames but optimized for graph data.
"""

from typing import Dict, List, Any, Optional, Set, Union
import json
import csv
from io import StringIO

class GraphTable:
    """DataFrame-like table view for graph nodes or edges."""
    
    def __init__(self, data_source, table_type="nodes", graph=None):
        """
        Initialize GraphTable from a graph data source.
        
        Args:
            data_source: Graph, Subgraph, or list of node/edge IDs
            table_type: "nodes" or "edges"
            graph: Optional graph reference for subgraphs that don't have graph access
        """
        self.data_source = data_source
        self.table_type = table_type
        self.graph_override = graph
        self._cached_data = None
        self._cached_columns = None
    
    def _get_graph(self):
        """Get the underlying graph object."""
        # Use override graph if provided
        if self.graph_override is not None:
            return self.graph_override
        # Check if it's a EnhancedSubgraph - these don't have graph references
        elif hasattr(self.data_source, 'subgraph_type') and hasattr(self.data_source, 'nodes'):
            # This is an EnhancedSubgraph - we need to get the graph from somewhere else
            raise ValueError("EnhancedSubgraph needs graph reference - pass graph parameter to GraphTable")
        elif hasattr(self.data_source, 'graph') and hasattr(self.data_source.graph, 'borrow'):
            # This is a subgraph with a graph reference
            return self.data_source.graph.borrow()
        elif hasattr(self.data_source, 'nodes') and hasattr(self.data_source, 'edges'):
            # This is a graph object
            return self.data_source
        else:
            raise ValueError("Cannot extract graph from data source")
    
    def _extract_value(self, value):
        """Extract the actual value from AttrValue objects."""
        if hasattr(value, 'value'):
            return value.value
        else:
            return value
    
    def _get_ids(self):
        """Get the list of node or edge IDs to include in the table."""
        if hasattr(self.data_source, 'nodes') and hasattr(self.data_source, 'edges'):
            # Graph or Subgraph object
            if self.table_type == "nodes":
                if hasattr(self.data_source, 'nodes') and isinstance(self.data_source.nodes, list):
                    # Subgraph with nodes list
                    return self.data_source.nodes
                else:
                    # Graph with node_ids property
                    return list(self.data_source.node_ids)
            else:  # edges
                if hasattr(self.data_source, 'edges') and isinstance(self.data_source.edges, list):
                    # Subgraph with edges list
                    return self.data_source.edges
                else:
                    # Graph with edge_ids property
                    return list(self.data_source.edge_ids)
        elif isinstance(self.data_source, list):
            # Direct list of IDs
            return self.data_source
        else:
            raise ValueError(f"Unsupported data source type: {type(self.data_source)}")
    
    def _discover_attributes(self) -> Set[str]:
        """Discover all attributes present across nodes or edges."""
        graph = self._get_graph()
        ids = self._get_ids()
        attributes = set()
        
        # Comprehensive list of common attributes to check
        # TODO: Replace with dynamic attribute discovery from graph API
        if self.table_type == "nodes":
            common_attrs = [
                'name', 'age', 'dept', 'salary', 'seniority', 'index', 'level', 
                'component_id', 'influence_score', 'id', 'value', 'test_val',
                'height', 'active', 'years_experience', 'department'
            ]
        else:
            common_attrs = [
                'weight', 'type', 'relationship', 'strength', 'frequency', 
                'last_contact', 'source', 'target'
            ]
        
        if self.table_type == "nodes":
            for node_id in ids:
                try:
                    node_view = graph.nodes[node_id]
                    # Check all common attributes
                    for attr_name in common_attrs:
                        try:
                            if hasattr(node_view, '__getitem__'):
                                _ = node_view[attr_name]
                                attributes.add(attr_name)
                        except (KeyError, AttributeError):
                            continue
                except Exception:
                    continue
        else:  # edges
            for edge_id in ids:
                try:
                    edge_view = graph.edges[edge_id]
                    # Check all common attributes
                    for attr_name in common_attrs:
                        try:
                            if hasattr(edge_view, '__getitem__'):
                                _ = edge_view[attr_name]
                                attributes.add(attr_name)
                        except (KeyError, AttributeError):
                            continue
                    # Always include source and target for edges
                    attributes.add('source')
                    attributes.add('target')
                except Exception:
                    continue
        
        return attributes
    
    def _detect_column_types(self, rows, columns):
        """Detect the data type of each column based on sample values."""
        dtypes = {}
        
        for col in columns:
            # Sample some non-None values to determine type
            sample_values = []
            for row in rows[:min(10, len(rows))]:  # Sample first 10 rows
                value = row.get(col)
                if value is not None:
                    sample_values.append(value)
                if len(sample_values) >= 5:  # Enough samples
                    break
            
            if not sample_values:
                dtypes[col] = 'object'
                continue
            
            # Analyze the sample values to determine type
            first_value = sample_values[0]
            
            if col == 'id':
                # ID columns are always integers
                dtypes[col] = 'int64'
            elif isinstance(first_value, bool):
                # Check if all samples are boolean
                if all(isinstance(v, bool) for v in sample_values):
                    dtypes[col] = 'bool'
                else:
                    dtypes[col] = 'object'
            elif isinstance(first_value, int):
                # Check if all samples are integers
                if all(isinstance(v, int) for v in sample_values):
                    dtypes[col] = 'int64'
                else:
                    dtypes[col] = 'object'
            elif isinstance(first_value, float):
                # Check if all samples are numeric (int or float)
                if all(isinstance(v, (int, float)) for v in sample_values):
                    dtypes[col] = 'float64'
                else:
                    dtypes[col] = 'object'
            elif isinstance(first_value, str):
                # String type - could be category if limited unique values
                unique_values = set(sample_values)
                if len(unique_values) <= 3 and len(sample_values) >= 3:
                    dtypes[col] = 'category'
                else:
                    dtypes[col] = 'string'
            else:
                dtypes[col] = 'object'
        
        return dtypes
    
    def _build_table_data(self):
        """Build the complete table data with all attributes."""
        if self._cached_data is not None:
            return self._cached_data, self._cached_columns
        
        graph = self._get_graph()
        ids = self._get_ids()
        attributes = self._discover_attributes()
        
        # Always include 'id' as first column
        columns = ['id'] + sorted([attr for attr in attributes if attr != 'id'])
        self._cached_columns = columns
        
        # OPTIMIZATION: Use bulk column access for 5-10x speedup
        # Instead of O(n*m) individual calls, make O(m) bulk column calls
        attribute_columns = {}
        
        if self.table_type == "nodes":
            # Check if graph has the optimized bulk column access methods
            if hasattr(graph, '_get_node_attribute_column'):
                # OPTIMIZED PATH: Bulk column access
                try:
                    # Get each attribute column in bulk (O(m) calls instead of O(n*m))
                    for attr_name in columns[1:]:  # Skip 'id' column
                        if hasattr(self.data_source, 'nodes') and isinstance(self.data_source.nodes, list):
                            # Subgraph case: use _get_node_attributes_for_nodes
                            column_values = graph._get_node_attributes_for_nodes(ids, attr_name)
                        else:
                            # Full graph case: use _get_node_attribute_column  
                            all_column_values = graph._get_node_attribute_column(attr_name)
                            # Create O(1) lookup map instead of O(n) list.index() calls
                            node_id_list = list(graph.node_ids)
                            id_to_index = {node_id: i for i, node_id in enumerate(node_id_list)}
                            column_values = []
                            for item_id in ids:
                                idx = id_to_index.get(item_id)
                                if idx is not None and idx < len(all_column_values):
                                    column_values.append(all_column_values[idx])
                                else:
                                    column_values.append(None)
                        attribute_columns[attr_name] = column_values
                except Exception as e:
                    # Fall back to individual access if bulk fails
                    print(f"Warning: Bulk column access failed ({e}), falling back to individual access")
                    attribute_columns = None
            else:
                attribute_columns = None
        else:  # edges
            # Similar optimization for edges
            if hasattr(graph, '_get_edge_attribute_column'):
                try:
                    for attr_name in columns[1:]:  # Skip 'id' column
                        if attr_name in ['source', 'target']:
                            # Handle topology attributes separately
                            continue
                        if hasattr(self.data_source, 'edges') and isinstance(self.data_source.edges, list):
                            # Subgraph case: use _get_edge_attributes_for_edges
                            column_values = graph._get_edge_attributes_for_edges(ids, attr_name)
                        else:
                            # Full graph case: use _get_edge_attribute_column
                            all_column_values = graph._get_edge_attribute_column(attr_name)
                            # Create O(1) lookup map instead of O(n) list.index() calls
                            edge_id_list = list(graph.edge_ids)
                            id_to_index = {edge_id: i for i, edge_id in enumerate(edge_id_list)}
                            column_values = []
                            for item_id in ids:
                                idx = id_to_index.get(item_id)
                                if idx is not None and idx < len(all_column_values):
                                    column_values.append(all_column_values[idx])
                                else:
                                    column_values.append(None)
                        attribute_columns[attr_name] = column_values
                except Exception as e:
                    print(f"Warning: Bulk edge column access failed ({e}), falling back to individual access")
                    attribute_columns = None
            else:
                attribute_columns = None
        
        # Build table rows
        rows = []
        if attribute_columns is not None:
            # OPTIMIZED PATH: Build rows from pre-fetched columns (5-10x faster)
            for i, item_id in enumerate(ids):
                row = {'id': item_id}
                
                for attr_name in columns[1:]:  # Skip 'id' since we already set it
                    if self.table_type == "edges" and attr_name in ['source', 'target']:
                        # Handle topology attributes for edges
                        try:
                            edge_view = graph.edges[item_id]
                            if attr_name == 'source':
                                row[attr_name] = edge_view.source
                            elif attr_name == 'target':
                                row[attr_name] = edge_view.target
                        except Exception:
                            row[attr_name] = None
                    else:
                        # Get from pre-fetched column
                        column_values = attribute_columns.get(attr_name, [])
                        if i < len(column_values):
                            row[attr_name] = self._extract_value(column_values[i])
                        else:
                            row[attr_name] = None
                
                rows.append(row)
        else:
            # FALLBACK PATH: Individual attribute access (original implementation)
            for item_id in ids:
                row = {'id': item_id}
                
                if self.table_type == "nodes":
                    try:
                        node_view = graph.nodes[item_id]
                        for attr_name in columns[1:]:  # Skip 'id' since we already set it
                            try:
                                if hasattr(node_view, '__getitem__'):
                                    value = node_view[attr_name]
                                    # Handle AttrValue objects - extract inner value
                                    row[attr_name] = self._extract_value(value)
                                else:
                                    row[attr_name] = None
                            except (KeyError, AttributeError):
                                row[attr_name] = None
                    except Exception:
                        # Fill with None for inaccessible nodes
                        for attr_name in columns[1:]:
                            row[attr_name] = None
                else:  # edges
                    try:
                        edge_view = graph.edges[item_id]
                        for attr_name in columns[1:]:  # Skip 'id' since we already set it
                            try:
                                if attr_name == 'source':
                                    row[attr_name] = edge_view.source
                                elif attr_name == 'target':
                                    row[attr_name] = edge_view.target
                                elif hasattr(edge_view, '__getitem__'):
                                    value = edge_view[attr_name]
                                    # Handle AttrValue objects - extract inner value
                                    row[attr_name] = self._extract_value(value)
                                else:
                                    row[attr_name] = None
                            except (KeyError, AttributeError):
                                row[attr_name] = None
                    except Exception:
                        # Fill with None for inaccessible edges
                        for attr_name in columns[1:]:
                            row[attr_name] = None
                
                rows.append(row)
        
        self._cached_data = rows
        return rows, columns
    
    def __repr__(self):
        """String representation with rich display formatting."""
        try:
            # Try to use rich display formatter
            from . import format_table
            
            # Get display data structure
            rows, columns = self._build_table_data()
            
            # Convert rows from list of dicts to list of lists for display formatter
            data_rows = []
            for row in rows:
                data_row = [row.get(col) for col in columns]
                data_rows.append(data_row)
            
            # Detect column data types for better display
            dtypes = self._detect_column_types(rows, columns)
            
            display_data = {
                'data': data_rows,
                'columns': columns,
                'dtypes': dtypes,
                'shape': self.shape,
                'table_type': self.table_type
            }
            
            # Use rich formatter
            return format_table(display_data)
            
        except (ImportError, Exception):
            # Fallback to basic representation
            rows, columns = self._build_table_data()
            
            if not rows:
                return f"GraphTable({self.table_type}, 0 rows, 0 columns)"
            
            # Create formatted table
            lines = []
            
            # Header
            header = "   " + "  ".join(f"{col:>10}" for col in columns)
            lines.append(header)
            
            # Rows
            for i, row in enumerate(rows):
                formatted_row = f"{i:2d} "
                for col in columns:
                    value = row.get(col)
                    if value is None:
                        formatted_value = "NaN"
                    elif isinstance(value, str):
                        formatted_value = value[:10]  # Truncate long strings
                    elif isinstance(value, float):
                        formatted_value = f"{value:.2f}"
                    else:
                        formatted_value = str(value)
                    formatted_row += f"  {formatted_value:>10}"
                lines.append(formatted_row)
            
            return "\n".join(lines)
    
    def __str__(self):
        """String representation (same as __repr__ for consistency)."""
        return self.__repr__()
    
    def __len__(self):
        """Number of rows in the table."""
        ids = self._get_ids()
        return len(ids)
    
    def __getitem__(self, key):
        """Access columns or rows like a DataFrame."""
        rows, columns = self._build_table_data()
        
        if isinstance(key, str):
            # Column access - return GraphArray for enhanced analytics  
            if key not in columns:
                raise KeyError(f"Column '{key}' not found")
            
            # Use optimized Rust method that returns GraphArray directly
            # This is much more efficient than building table data and extracting columns
            graph = self._get_graph()
            if hasattr(graph, '_get_node_attribute_column') and self.table_type == "nodes":
                try:
                    # Direct GraphArray return from Rust - no Python conversion overhead
                    return graph._get_node_attribute_column(key)
                except Exception as e:
                    # Fallback to table-based extraction if direct access fails
                    print(f"Warning: Direct GraphArray access failed ({e}), using fallback")
                    pass
            
            # Fallback: extract from table data and convert to GraphArray
            column_data = [row.get(key) for row in rows]
            
            # Convert to GraphArray for consistent API
            try:
                import groggy
                return groggy.GraphArray(column_data)
            except Exception:
                # If GraphArray creation fails, return plain list as ultimate fallback
                return column_data
                
        elif isinstance(key, int):
            # Single row access
            if key < 0 or key >= len(rows):
                raise IndexError(f"Row index {key} out of range")
            return rows[key]
            
        elif isinstance(key, slice):
            # Row slicing - return new GraphTable with sliced data
            sliced_rows = rows[key]
            
            # Create a simplified data source for the sliced table
            class SlicedDataSource:
                def __init__(self, sliced_data, table_type):
                    self.sliced_data = sliced_data
                    self.table_type = table_type
                    
                def __len__(self):
                    return len(self.sliced_data)
                    
                def __iter__(self):
                    # Return IDs for compatibility
                    return iter(row.get('id') for row in self.sliced_data if 'id' in row)
                    
            sliced_source = SlicedDataSource(sliced_rows, self.table_type)
            new_table = GraphTable(sliced_source, self.table_type, self.graph_override)
            
            # Cache the sliced data and preserve column structure
            new_table._cached_data = sliced_rows
            new_table._cached_columns = columns  # Use the same columns as the parent table
            
            return new_table
            
        else:
            raise TypeError("Key must be string (column), int (row), or slice")
    
    @property
    def columns(self):
        """Get column names."""
        _, columns = self._build_table_data()
        return columns
    
    @property
    def dtypes(self):
        """Get column data types."""
        rows, columns = self._build_table_data()
        return self._detect_column_types(rows, columns)
    
    @property
    def shape(self):
        """Get table shape (rows, columns)."""
        rows, columns = self._build_table_data()
        return (len(rows), len(columns))
    
    def to_dict(self):
        """Convert to dictionary format."""
        rows, columns = self._build_table_data()
        return {
            'columns': columns,
            'data': rows,
            'shape': self.shape,
            'type': self.table_type
        }
    
    def to_pandas(self):
        """Convert to pandas DataFrame."""
        try:
            import pandas as pd
        except ImportError:
            raise ImportError("pandas is required for to_pandas(). Install with: pip install pandas")
        
        rows, columns = self._build_table_data()
        return pd.DataFrame(rows, columns=['id'] + [col for col in columns if col != 'id'])
    
    def to_csv(self, filename: str = None, **kwargs):
        """Export to CSV format."""
        rows, columns = self._build_table_data()
        
        output = StringIO()
        writer = csv.DictWriter(output, fieldnames=columns)
        writer.writeheader()
        writer.writerows(rows)
        
        csv_content = output.getvalue()
        output.close()
        
        if filename:
            with open(filename, 'w', newline='') as f:
                f.write(csv_content)
            return f"GraphTable exported to {filename}"
        else:
            return csv_content
    
    def to_json(self, filename: str = None, **kwargs):
        """Export to JSON format with graph metadata."""
        data = self.to_dict()
        
        # Add metadata
        data['metadata'] = {
            'export_type': 'groggy_graph_table',
            'table_type': self.table_type,
            'total_rows': len(data['data']),
            'total_columns': len(data['columns'])
        }
        
        json_content = json.dumps(data, indent=2, default=str)
        
        if filename:
            with open(filename, 'w') as f:
                f.write(json_content)
            return f"GraphTable exported to {filename}"
        else:
            return json_content
    
    def groupby(self, column: str):
        """Group by a column (simplified groupby)."""
        rows, columns = self._build_table_data()
        
        if column not in columns:
            raise KeyError(f"Column '{column}' not found")
        
        groups = {}
        for row in rows:
            key = row.get(column)
            if key not in groups:
                groups[key] = []
            groups[key].append(row)
        
        return GraphTableGroupBy(groups, column)

class GraphTableGroupBy:
    """Grouped GraphTable for simple aggregations."""
    
    def __init__(self, groups: Dict[Any, List[Dict]], group_column: str):
        self.groups = groups
        self.group_column = group_column
    
    def mean(self, column: str = None):
        """Calculate mean for numeric columns."""
        if column:
            return self._aggregate_column(column, 'mean')
        else:
            return {group_key: self._aggregate_group(group_rows, 'mean') 
                   for group_key, group_rows in self.groups.items()}
    
    def count(self):
        """Count rows in each group."""
        return {group_key: len(group_rows) for group_key, group_rows in self.groups.items()}
    
    def _aggregate_column(self, column: str, agg_func: str):
        """Aggregate a specific column across groups."""
        result = {}
        for group_key, group_rows in self.groups.items():
            values = [row.get(column) for row in group_rows if row.get(column) is not None]
            numeric_values = [v for v in values if isinstance(v, (int, float))]
            
            if agg_func == 'mean' and numeric_values:
                result[group_key] = sum(numeric_values) / len(numeric_values)
            else:
                result[group_key] = None
        
        return result
    
    def _aggregate_group(self, rows: List[Dict], agg_func: str):
        """Aggregate all numeric columns in a group."""
        result = {}
        if not rows:
            return result
        
        # Find numeric columns
        for column in rows[0].keys():
            values = [row.get(column) for row in rows if row.get(column) is not None]
            numeric_values = [v for v in values if isinstance(v, (int, float))]
            
            if agg_func == 'mean' and numeric_values:
                result[column] = sum(numeric_values) / len(numeric_values)
        
        return result

--- FILE: groggy/query_parser.py ---
"""
Query parser for converting string queries to filter objects.

Converts strings like "salary > 120000" to NodeFilter objects.
"""

import re
import ast
from typing import Union, Any, List
from ._groggy import NodeFilter, EdgeFilter, AttributeFilter, AttrValue

class QueryParser:
    """Parse string queries into filter objects."""
    
    # Regex patterns for different query types
    COMPARISON_PATTERN = r'(\w+)\s*(==|!=|>=|<=|>|<)\s*(.+)'
    
    def __init__(self):
        pass
    
    def _tokenize_query(self, query: str) -> List[str]:
        """Tokenize a query string, handling quoted strings and operators."""
        tokens = []
        current_token = ""
        in_quotes = False
        quote_char = None
        i = 0
        
        while i < len(query):
            char = query[i]
            
            if char in ['"', "'"] and (not in_quotes or char == quote_char):
                if in_quotes and char == quote_char:
                    # End of quoted string
                    current_token += char
                    tokens.append(current_token)
                    current_token = ""
                    in_quotes = False
                    quote_char = None
                else:
                    # Start of quoted string
                    if current_token.strip():
                        tokens.append(current_token.strip())
                    current_token = char
                    in_quotes = True
                    quote_char = char
            elif in_quotes:
                current_token += char
            elif char.isspace():
                if current_token.strip():
                    tokens.append(current_token.strip())
                    current_token = ""
            elif char == '(':
                if current_token.strip():
                    tokens.append(current_token.strip())
                    current_token = ""
                tokens.append('(')
            elif char == ')':
                if current_token.strip():
                    tokens.append(current_token.strip())
                    current_token = ""
                tokens.append(')')
            else:
                current_token += char
            
            i += 1
        
        if current_token.strip():
            tokens.append(current_token.strip())
        
        return tokens
    
    
    def parse_node_filter(self, query: str) -> NodeFilter:
        """Parse a string query into a NodeFilter with full logical operator and parentheses support."""
        query = query.strip()
        
        # Handle parentheses with recursive descent parser
        if '(' in query or ')' in query:
            return self._parse_node_expression_with_parentheses(query)
        
        # Handle logical operators directly in the parser
        normalized_query = query.upper()
        if ' AND ' in normalized_query:
            return self._parse_and_node_filter(query)
        elif ' OR ' in normalized_query:
            return self._parse_or_node_filter(query)
        elif normalized_query.startswith('NOT '):
            return self._parse_not_node_filter(query)
        else:
            # Use standard parsing for simple queries
            return self._parse_comparison(query, NodeFilter)
    
    def _parse_node_expression_with_parentheses(self, query: str) -> NodeFilter:
        """Parse node expressions with parentheses support using recursive descent."""
        tokens = self._tokenize_query(query)
        
        # Convert tokens to a format suitable for expression parsing
        pos = [0]  # Use list for mutable reference in nested functions
        
        def parse_expression() -> NodeFilter:
            """Parse a complete expression with AND/OR precedence."""
            return parse_or_expression()
        
        def parse_or_expression() -> NodeFilter:
            """Parse OR expressions (lowest precedence)."""
            left = parse_and_expression()
            
            while pos[0] < len(tokens) and tokens[pos[0]].upper() == 'OR':
                pos[0] += 1  # consume 'OR'
                right = parse_and_expression()
                left = NodeFilter.or_filters([left, right])
            
            return left
        
        def parse_and_expression() -> NodeFilter:
            """Parse AND expressions (higher precedence than OR)."""
            left = parse_not_expression()
            
            while pos[0] < len(tokens) and tokens[pos[0]].upper() == 'AND':
                pos[0] += 1  # consume 'AND'
                right = parse_not_expression()
                left = NodeFilter.and_filters([left, right])
            
            return left
        
        def parse_not_expression() -> NodeFilter:
            """Parse NOT expressions and primary expressions."""
            if pos[0] < len(tokens) and tokens[pos[0]].upper() == 'NOT':
                pos[0] += 1  # consume 'NOT'
                inner = parse_primary_expression()
                return NodeFilter.not_filter(inner)
            else:
                return parse_primary_expression()
        
        def parse_primary_expression() -> NodeFilter:
            """Parse primary expressions (comparisons or parenthesized expressions)."""
            if pos[0] < len(tokens) and tokens[pos[0]] == '(':
                pos[0] += 1  # consume '('
                result = parse_expression()
                if pos[0] < len(tokens) and tokens[pos[0]] == ')':
                    pos[0] += 1  # consume ')'
                else:
                    raise ValueError(f"Missing closing parenthesis in query: {query}")
                return result
            else:
                # Parse a comparison expression
                comparison_tokens = []
                while (pos[0] < len(tokens) and 
                       tokens[pos[0]] not in ['AND', 'OR', 'NOT', ')', '('] and
                       tokens[pos[0]].upper() not in ['AND', 'OR', 'NOT']):
                    comparison_tokens.append(tokens[pos[0]])
                    pos[0] += 1
                
                if not comparison_tokens:
                    raise ValueError(f"Expected comparison expression in query: {query}")
                
                comparison_str = ' '.join(comparison_tokens)
                return self._parse_comparison(comparison_str, NodeFilter)
        
        return parse_expression()
    
    def _parse_and_node_filter(self, query: str) -> NodeFilter:
        """Parse AND expressions for nodes with 3+ term support."""
        parts = re.split(r'\s+AND\s+', query, flags=re.IGNORECASE)
        
        if len(parts) < 2:
            raise ValueError(f"Invalid AND expression: {query}")
        
        # Handle 3+ terms by recursively combining filters
        filters = []
        for part in parts:
            part = part.strip()
            if part:
                filters.append(self.parse_node_filter(part))
        
        if len(filters) == 0:
            raise ValueError(f"No valid filters found in AND expression: {query}")
        elif len(filters) == 1:
            return filters[0]
        else:
            # Combine all filters with AND
            return NodeFilter.and_filters(filters)
    
    def _parse_or_node_filter(self, query: str) -> NodeFilter:
        """Parse OR expressions for nodes with 3+ term support."""
        parts = re.split(r'\s+OR\s+', query, flags=re.IGNORECASE)
        
        if len(parts) < 2:
            raise ValueError(f"Invalid OR expression: {query}")
        
        # Handle 3+ terms by recursively combining filters
        filters = []
        for part in parts:
            part = part.strip()
            if part:
                filters.append(self.parse_node_filter(part))
        
        if len(filters) == 0:
            raise ValueError(f"No valid filters found in OR expression: {query}")
        elif len(filters) == 1:
            return filters[0]
        else:
            # Combine all filters with OR
            return NodeFilter.or_filters(filters)
    
    def _parse_not_node_filter(self, query: str) -> NodeFilter:
        """Parse NOT expressions for nodes."""
        inner_query = re.sub(r'^NOT\s+', '', query, flags=re.IGNORECASE).strip()
        inner_filter = self.parse_node_filter(inner_query)
        
        return NodeFilter.not_filter(inner_filter)
    
    def _parse_edge_expression_with_parentheses(self, query: str) -> EdgeFilter:
        """Parse edge expressions with parentheses support using recursive descent."""
        tokens = self._tokenize_query(query)
        
        # Convert tokens to a format suitable for expression parsing
        pos = [0]  # Use list for mutable reference in nested functions
        
        def parse_expression() -> EdgeFilter:
            """Parse a complete expression with AND/OR precedence."""
            return parse_or_expression()
        
        def parse_or_expression() -> EdgeFilter:
            """Parse OR expressions (lowest precedence)."""
            left = parse_and_expression()
            
            while pos[0] < len(tokens) and tokens[pos[0]].upper() == 'OR':
                pos[0] += 1  # consume 'OR'
                right = parse_and_expression()
                left = EdgeFilter.or_filters([left, right])
            
            return left
        
        def parse_and_expression() -> EdgeFilter:
            """Parse AND expressions (higher precedence than OR)."""
            left = parse_not_expression()
            
            while pos[0] < len(tokens) and tokens[pos[0]].upper() == 'AND':
                pos[0] += 1  # consume 'AND'
                right = parse_not_expression()
                left = EdgeFilter.and_filters([left, right])
            
            return left
        
        def parse_not_expression() -> EdgeFilter:
            """Parse NOT expressions and primary expressions."""
            if pos[0] < len(tokens) and tokens[pos[0]].upper() == 'NOT':
                pos[0] += 1  # consume 'NOT'
                inner = parse_primary_expression()
                return EdgeFilter.not_filter(inner)
            else:
                return parse_primary_expression()
        
        def parse_primary_expression() -> EdgeFilter:
            """Parse primary expressions (comparisons or parenthesized expressions)."""
            if pos[0] < len(tokens) and tokens[pos[0]] == '(':
                pos[0] += 1  # consume '('
                result = parse_expression()
                if pos[0] < len(tokens) and tokens[pos[0]] == ')':
                    pos[0] += 1  # consume ')'
                else:
                    raise ValueError(f"Missing closing parenthesis in query: {query}")
                return result
            else:
                # Parse a comparison expression
                comparison_tokens = []
                while (pos[0] < len(tokens) and 
                       tokens[pos[0]] not in ['AND', 'OR', 'NOT', ')', '('] and
                       tokens[pos[0]].upper() not in ['AND', 'OR', 'NOT']):
                    comparison_tokens.append(tokens[pos[0]])
                    pos[0] += 1
                
                if not comparison_tokens:
                    raise ValueError(f"Expected comparison expression in query: {query}")
                
                comparison_str = ' '.join(comparison_tokens)
                return self._parse_comparison(comparison_str, EdgeFilter)
        
        return parse_expression()
    
    def parse_edge_filter(self, query: str) -> EdgeFilter:
        """Parse a string query into an EdgeFilter with full logical operator and parentheses support."""
        query = query.strip()
        
        # Handle parentheses with recursive descent parser
        if '(' in query or ')' in query:
            return self._parse_edge_expression_with_parentheses(query)
        
        # Handle logical operators directly in the parser
        normalized_query = query.upper()
        if ' AND ' in normalized_query:
            return self._parse_and_edge_filter(query)
        elif ' OR ' in normalized_query:
            return self._parse_or_edge_filter(query)
        elif normalized_query.startswith('NOT '):
            return self._parse_not_edge_filter(query)
        else:
            # Use standard parsing for simple queries
            return self._parse_comparison(query, EdgeFilter)
    
    def _parse_and_edge_filter(self, query: str) -> EdgeFilter:
        """Parse AND expressions for edges with 3+ term support."""
        parts = re.split(r'\s+AND\s+', query, flags=re.IGNORECASE)
        
        if len(parts) < 2:
            raise ValueError(f"Invalid AND expression: {query}")
        
        # Handle 3+ terms by recursively combining filters
        filters = []
        for part in parts:
            part = part.strip()
            if part:
                filters.append(self.parse_edge_filter(part))
        
        if len(filters) == 0:
            raise ValueError(f"No valid filters found in AND expression: {query}")
        elif len(filters) == 1:
            return filters[0]
        else:
            # Combine all filters with AND
            return EdgeFilter.and_filters(filters)
    
    def _parse_or_edge_filter(self, query: str) -> EdgeFilter:
        """Parse OR expressions for edges with 3+ term support."""
        parts = re.split(r'\s+OR\s+', query, flags=re.IGNORECASE)
        
        if len(parts) < 2:
            raise ValueError(f"Invalid OR expression: {query}")
        
        # Handle 3+ terms by recursively combining filters
        filters = []
        for part in parts:
            part = part.strip()
            if part:
                filters.append(self.parse_edge_filter(part))
        
        if len(filters) == 0:
            raise ValueError(f"No valid filters found in OR expression: {query}")
        elif len(filters) == 1:
            return filters[0]
        else:
            # Combine all filters with OR
            return EdgeFilter.or_filters(filters)
    
    def _parse_not_edge_filter(self, query: str) -> EdgeFilter:
        """Parse NOT expressions for edges."""
        inner_query = re.sub(r'^NOT\s+', '', query, flags=re.IGNORECASE).strip()
        inner_filter = self.parse_edge_filter(inner_query)
        
        return EdgeFilter.not_filter(inner_filter)
    
    def _parse_comparison(self, query: str, filter_class) -> Union[NodeFilter, EdgeFilter]:
        """Parse comparison expressions like 'salary > 120000'."""
        match = re.match(self.COMPARISON_PATTERN, query)
        if not match:
            raise ValueError(f"Invalid comparison: {query}")
        
        attr_name, operator, value_str = match.groups()
        
        # Parse the value using Python's AST for safety
        try:
            # Handle boolean literals (true/false vs True/False)
            # Note: Groggy stores Python True as AttrValue(1) and False as AttrValue(0)
            value_normalized = value_str.strip().lower()
            if value_normalized == 'true':
                value = 1  # AttrValue stores True as 1
            elif value_normalized == 'false':
                value = 0  # AttrValue stores False as 0
            else:
                # Try to safely evaluate the value
                value = ast.literal_eval(value_str.strip())
        except (ValueError, SyntaxError):
            # If it fails, treat as string (remove quotes if present)
            value = value_str.strip().strip('\'"')
        
        # Convert to AttrValue
        attr_value = AttrValue(value)
        
        # Create appropriate AttributeFilter
        if operator == '==':
            attr_filter = AttributeFilter.equals(attr_value)
        elif operator == '!=':
            attr_filter = AttributeFilter.not_equals(attr_value)
        elif operator == '>':
            attr_filter = AttributeFilter.greater_than(attr_value)
        elif operator == '<':
            attr_filter = AttributeFilter.less_than(attr_value)
        elif operator == '>=':
            attr_filter = AttributeFilter.greater_than_or_equal(attr_value)
        elif operator == '<=':
            attr_filter = AttributeFilter.less_than_or_equal(attr_value)
        else:
            raise ValueError(f"Unsupported operator: {operator}")
        
        # Create the appropriate filter
        if filter_class == NodeFilter:
            return NodeFilter.attribute_filter(attr_name, attr_filter)
        else:
            return EdgeFilter.attribute_filter(attr_name, attr_filter)

# Global parser instance
_parser = QueryParser()

def parse_node_query(query: str) -> NodeFilter:
    """Parse a string query into a NodeFilter.
    
    Examples:
        parse_node_query("salary > 120000")
        parse_node_query("department == 'Engineering'")
        parse_node_query("age < 30")
    """
    return _parser.parse_node_filter(query)

def parse_edge_query(query: str) -> EdgeFilter:
    """Parse a string query into an EdgeFilter.
    
    Examples:
        parse_edge_query("weight > 0.5")
        parse_edge_query("relationship == 'collaborates'")
        parse_edge_query("weight > 0.5 AND strength != 'weak'")
    """
    return _parser.parse_edge_filter(query)



--- FILE: groggy/graph.py ---
from typing import Dict, List, Optional, Tuple, Union
from .types import NodeId, EdgeId, AttrName, AttrValue, StateId, BranchName
from .errors import GroggyError, NodeNotFoundError, EdgeNotFoundError, NotImplementedError
from ._groggy import Graph as _RustGraph, AttrValue as _RustAttrValue

class Graph:
    """
    Main Graph interface - Python wrapper around Rust Graph implementation.
    
    This class provides a Pythonic interface to the high-performance Rust graph library,
    with memory optimization, Git-like version control, and advanced query capabilities.
    """
    
    def __init__(self, config: Optional[Dict] = None):
        """
        Create a new empty graph.
        
        Args:
            config: Optional configuration dictionary
        """
        self._rust_graph = _RustGraph(config)
    
    @classmethod  
    def load_from_path(cls, path: str) -> 'Graph':
        """
        Load an existing graph from storage.
        
        Args:
            path: Path to the saved graph file
            
        Returns:
            Graph instance loaded from file
            
        Raises:
            NotImplementedError: Feature not yet implemented
        """
        raise NotImplementedError("load_from_path")
    
    # === CORE GRAPH OPERATIONS ===
    
    def add_node(self) -> NodeId:
        """
        Add a new node to the graph.
        
        Returns:
            ID of the newly created node
        """
        return self._rust_graph.add_node()
    
    def add_nodes(self, count: int) -> List[NodeId]:
        """
        Add multiple nodes efficiently.
        
        Args:
            count: Number of nodes to create
            
        Returns:
            List of newly created node IDs
        """
        return self._rust_graph.add_nodes(count)
    
    def add_edge(self, source: NodeId, target: NodeId) -> EdgeId:
        """
        Add an edge between two existing nodes.
        
        Args:
            source: Source node ID
            target: Target node ID
            
        Returns:
            ID of the newly created edge
            
        Raises:
            NodeNotFoundError: If either node doesn't exist
        """
        try:
            return self._rust_graph.add_edge(source, target)
        except ValueError as e:
            # Convert generic ValueError to more specific errors
            error_msg = str(e)
            if "Node" in error_msg and "not found" in error_msg:
                raise NodeNotFoundError(source if "source" in error_msg else target, "add_edge") from e
            raise GroggyError(error_msg) from e
    
    def add_edges(self, edges: List[Tuple[NodeId, NodeId]]) -> List[EdgeId]:
        """
        Add multiple edges efficiently.
        
        Args:
            edges: List of (source, target) node ID pairs
            
        Returns:
            List of newly created edge IDs
        """
        try:
            return self._rust_graph.add_edges(edges)
        except ValueError as e:
            raise GroggyError(str(e)) from e
    
    def remove_node(self, node: NodeId) -> None:
        """
        Remove a node and all its incident edges.
        
        Args:
            node: Node ID to remove
            
        Raises:
            NodeNotFoundError: If node doesn't exist
        """
        try:
            self._rust_graph.remove_node(node)
        except ValueError as e:
            error_msg = str(e)
            if "Node" in error_msg and "not found" in error_msg:
                raise NodeNotFoundError(node, "remove_node") from e
            raise GroggyError(error_msg) from e
    
    def remove_edge(self, edge: EdgeId) -> None:
        """
        Remove an edge from the graph.
        
        Args:
            edge: Edge ID to remove
            
        Raises:
            EdgeNotFoundError: If edge doesn't exist
        """
        try:
            self._rust_graph.remove_edge(edge)
        except ValueError as e:
            error_msg = str(e)
            if "Edge" in error_msg and "not found" in error_msg:
                raise EdgeNotFoundError(edge, "remove_edge") from e
            raise GroggyError(error_msg) from e
    
    def remove_nodes(self, nodes: List[NodeId]) -> None:
        """
        Remove multiple nodes efficiently.
        
        Args:
            nodes: List of node IDs to remove
        """
        try:
            self._rust_graph.remove_nodes(nodes)
        except ValueError as e:
            raise GroggyError(str(e)) from e
    
    def remove_edges(self, edges: List[EdgeId]) -> None:
        """
        Remove multiple edges efficiently.
        
        Args:
            edges: List of edge IDs to remove
        """
        try:
            self._rust_graph.remove_edges(edges)
        except ValueError as e:
            raise GroggyError(str(e)) from e
    
    # === ATTRIBUTE OPERATIONS ===
    
    def set_node_attribute(self, node: NodeId, attr: AttrName, value: AttrValue) -> None:
        """
        Set an attribute value on a node.
        
        Args:
            node: Node ID
            attr: Attribute name
            value: Attribute value
            
        Raises:
            NodeNotFoundError: If node doesn't exist
        """
        # Convert Python AttrValue to Rust AttrValue
        rust_value = _RustAttrValue(value.value)
        try:
            self._rust_graph.set_node_attribute(node, attr, rust_value)
        except ValueError as e:
            error_msg = str(e)
            if "Node" in error_msg and "not found" in error_msg:
                raise NodeNotFoundError(node, "set_node_attribute") from e
            raise GroggyError(error_msg) from e
    
    def set_edge_attribute(self, edge: EdgeId, attr: AttrName, value: AttrValue) -> None:
        """
        Set an attribute value on an edge.
        
        Args:
            edge: Edge ID
            attr: Attribute name
            value: Attribute value
            
        Raises:
            EdgeNotFoundError: If edge doesn't exist
        """
        # Convert Python AttrValue to Rust AttrValue
        rust_value = _RustAttrValue(value.value)
        try:
            self._rust_graph.set_edge_attribute(edge, attr, rust_value)
        except ValueError as e:
            error_msg = str(e)
            if "Edge" in error_msg and "not found" in error_msg:
                raise EdgeNotFoundError(edge, "set_edge_attribute") from e
            raise GroggyError(error_msg) from e
    
    def get_node_attribute(self, node: NodeId, attr: AttrName) -> Optional[AttrValue]:
        """
        Get an attribute value from a node.
        
        Args:
            node: Node ID
            attr: Attribute name
            
        Returns:
            Attribute value if it exists, None otherwise
            
        Raises:
            NodeNotFoundError: If node doesn't exist
        """
        try:
            rust_value = self._rust_graph.get_node_attribute(node, attr)
            if rust_value is None:
                return None
            # Convert Rust AttrValue back to Python AttrValue
            return AttrValue(rust_value.value)
        except ValueError as e:
            error_msg = str(e)
            if "Node" in error_msg and "not found" in error_msg:
                raise NodeNotFoundError(node, "get_node_attribute") from e
            raise GroggyError(error_msg) from e
    
    def get_edge_attribute(self, edge: EdgeId, attr: AttrName) -> Optional[AttrValue]:
        """
        Get an attribute value from an edge.
        
        Args:
            edge: Edge ID
            attr: Attribute name
            
        Returns:
            Attribute value if it exists, None otherwise
            
        Raises:
            EdgeNotFoundError: If edge doesn't exist
        """
        try:
            rust_value = self._rust_graph.get_edge_attribute(edge, attr)
            if rust_value is None:
                return None
            # Convert Rust AttrValue back to Python AttrValue
            return AttrValue(rust_value.value)
        except ValueError as e:
            error_msg = str(e)
            if "Edge" in error_msg and "not found" in error_msg:
                raise EdgeNotFoundError(edge, "get_edge_attribute") from e
            raise GroggyError(error_msg) from e
    
    def get_node_attributes(self, node: NodeId) -> Dict[AttrName, AttrValue]:
        """
        Get all attributes for a node.
        
        Args:
            node: Node ID
            
        Returns:
            Dictionary mapping attribute names to values
            
        Raises:
            NodeNotFoundError: If node doesn't exist
        """
        try:
            rust_attrs = self._rust_graph.get_node_attributes(node)
            # Convert Rust AttrValue objects to Python AttrValue objects
            python_attrs = {}
            for attr_name, rust_value in rust_attrs.items():
                python_attrs[attr_name] = AttrValue(rust_value.value)
            return python_attrs
        except ValueError as e:
            error_msg = str(e)
            if "Node" in error_msg and "not found" in error_msg:
                raise NodeNotFoundError(node, "get_node_attributes") from e
            raise GroggyError(error_msg) from e
    
    def get_edge_attributes(self, edge: EdgeId) -> Dict[AttrName, AttrValue]:
        """
        Get all attributes for an edge.
        
        Args:
            edge: Edge ID
            
        Returns:
            Dictionary mapping attribute names to values
            
        Raises:
            EdgeNotFoundError: If edge doesn't exist
        """
        try:
            rust_attrs = self._rust_graph.get_edge_attributes(edge)
            # Convert Rust AttrValue objects to Python AttrValue objects
            python_attrs = {}
            for attr_name, rust_value in rust_attrs.items():
                python_attrs[attr_name] = AttrValue(rust_value.value)
            return python_attrs
        except ValueError as e:
            error_msg = str(e)
            if "Edge" in error_msg and "not found" in error_msg:
                raise EdgeNotFoundError(edge, "get_edge_attributes") from e
            raise GroggyError(error_msg) from e
    
    # === BULK ATTRIBUTE OPERATIONS (Phase 2) ===
    
    def set_node_attributes(self, attrs: Dict[AttrName, List[Tuple[NodeId, AttrValue]]]) -> None:
        """
        Set multiple attributes on multiple nodes efficiently.
        
        Args:
            attrs: Dictionary mapping attribute names to lists of (node_id, value) pairs
            
        Example:
            graph.set_node_attributes({
                "name": [(1, AttrValue("Alice")), (2, AttrValue("Bob"))],
                "age": [(1, AttrValue(25)), (2, AttrValue(30))]
            })
            
        Raises:
            NodeNotFoundError: If any node doesn't exist
        """
        # Convert Python AttrValue objects to Rust AttrValue objects
        rust_attrs = {}
        for attr_name, pairs in attrs.items():
            rust_pairs = []
            for node_id, attr_value in pairs:
                rust_value = _RustAttrValue(attr_value.value)
                rust_pairs.append((node_id, rust_value))
            rust_attrs[attr_name] = rust_pairs
        
        try:
            self._rust_graph.set_node_attributes(rust_attrs)
        except ValueError as e:
            error_msg = str(e)
            if "Node" in error_msg and "not found" in error_msg:
                raise NodeNotFoundError(-1, "set_node_attributes") from e
            raise GroggyError(error_msg) from e
    
    def set_edge_attributes(self, attrs: Dict[AttrName, List[Tuple[EdgeId, AttrValue]]]) -> None:
        """
        Set multiple attributes on multiple edges efficiently.
        
        Args:
            attrs: Dictionary mapping attribute names to lists of (edge_id, value) pairs
            
        Example:
            graph.set_edge_attributes({
                "weight": [(1, AttrValue(0.9)), (2, AttrValue(0.8))],
                "type": [(1, AttrValue("friend")), (2, AttrValue("colleague"))]
            })
            
        Raises:
            EdgeNotFoundError: If any edge doesn't exist
        """
        # Convert Python AttrValue objects to Rust AttrValue objects
        rust_attrs = {}
        for attr_name, pairs in attrs.items():
            rust_pairs = []
            for edge_id, attr_value in pairs:
                rust_value = _RustAttrValue(attr_value.value)
                rust_pairs.append((edge_id, rust_value))
            rust_attrs[attr_name] = rust_pairs
        
        try:
            self._rust_graph.set_edge_attributes(rust_attrs)
        except ValueError as e:
            error_msg = str(e)
            if "Edge" in error_msg and "not found" in error_msg:
                raise EdgeNotFoundError(-1, "set_edge_attributes") from e
            raise GroggyError(error_msg) from e
    
    def get_nodes_attributes(self, attr: AttrName, nodes: List[NodeId]) -> List[Optional[AttrValue]]:
        """
        Get a single attribute from multiple nodes efficiently.
        
        Args:
            attr: Attribute name to retrieve
            nodes: List of node IDs to get the attribute from
            
        Returns:
            List of attribute values (None if attribute doesn't exist for a node)
            
        Example:
            names = graph.get_nodes_attributes("name", [1, 2, 3])
            # Returns [AttrValue("Alice"), None, AttrValue("Charlie")]
        """
        try:
            rust_values = self._rust_graph.get_nodes_attributes(attr, nodes)
            # Convert Rust AttrValue objects to Python AttrValue objects
            python_values = []
            for rust_value in rust_values:
                if rust_value is None:
                    python_values.append(None)
                else:
                    python_values.append(AttrValue(rust_value.value))
            return python_values
        except ValueError as e:
            raise GroggyError(str(e)) from e
    
    def get_edges_attributes(self, attr: AttrName, edges: List[EdgeId]) -> List[Optional[AttrValue]]:
        """
        Get a single attribute from multiple edges efficiently.
        
        Args:
            attr: Attribute name to retrieve
            edges: List of edge IDs to get the attribute from
            
        Returns:
            List of attribute values (None if attribute doesn't exist for an edge)
            
        Example:
            weights = graph.get_edges_attributes("weight", [1, 2, 3])
            # Returns [AttrValue(0.9), AttrValue(0.8), None]
        """
        try:
            rust_values = self._rust_graph.get_edges_attributes(attr, edges)
            # Convert Rust AttrValue objects to Python AttrValue objects
            python_values = []
            for rust_value in rust_values:
                if rust_value is None:
                    python_values.append(None)
                else:
                    python_values.append(AttrValue(rust_value.value))
            return python_values
        except ValueError as e:
            raise GroggyError(str(e)) from e
    
    # === TOPOLOGY OPERATIONS ===
    
    def contains_node(self, node: NodeId) -> bool:
        """Check if a node exists in the graph."""
        return self._rust_graph.contains_node(node)
    
    def contains_edge(self, edge: EdgeId) -> bool:
        """Check if an edge exists in the graph."""
        return self._rust_graph.contains_edge(edge)
    
    def node_ids(self) -> List[NodeId]:
        """Get all active node IDs."""
        return self._rust_graph.node_ids()
    
    def edge_ids(self) -> List[EdgeId]:
        """Get all active edge IDs."""
        return self._rust_graph.edge_ids()
    
    def edge_endpoints(self, edge: EdgeId) -> Tuple[NodeId, NodeId]:
        """
        Get the endpoints of an edge.
        
        Args:
            edge: Edge ID
            
        Returns:
            Tuple of (source, target) node IDs
            
        Raises:
            EdgeNotFoundError: If edge doesn't exist
        """
        try:
            return self._rust_graph.edge_endpoints(edge)
        except ValueError as e:
            error_msg = str(e)
            if "Edge" in error_msg and "not found" in error_msg:
                raise EdgeNotFoundError(edge, "edge_endpoints") from e
            raise GroggyError(error_msg) from e
    
    def neighbors(self, node: NodeId) -> List[NodeId]:
        """
        Get all neighbors of a node.
        
        Args:
            node: Node ID
            
        Returns:
            List of neighboring node IDs
            
        Raises:
            NodeNotFoundError: If node doesn't exist
        """
        try:
            return self._rust_graph.neighbors(node)
        except ValueError as e:
            error_msg = str(e)
            if "Node" in error_msg and "not found" in error_msg:
                raise NodeNotFoundError(node, "neighbors") from e
            raise GroggyError(error_msg) from e
    
    def degree(self, node: NodeId) -> int:
        """
        Get the degree (number of incident edges) of a node.
        
        Args:
            node: Node ID
            
        Returns:
            Number of incident edges
            
        Raises:
            NodeNotFoundError: If node doesn't exist
        """
        try:
            return self._rust_graph.degree(node)
        except ValueError as e:
            error_msg = str(e)
            if "Node" in error_msg and "not found" in error_msg:
                raise NodeNotFoundError(node, "degree") from e
            raise GroggyError(error_msg) from e
    
    # === STATISTICS AND ANALYSIS ===
    
    def statistics(self) -> Dict:
        """
        Get comprehensive graph statistics.
        
        Returns:
            Dictionary containing graph statistics
        """
        return self._rust_graph.statistics()
    
    def memory_statistics(self) -> Dict:
        """
        Get detailed memory usage statistics.
        
        Returns:
            Dictionary containing memory statistics
        """
        return self._rust_graph.memory_statistics()
    
    def __repr__(self) -> str:
        return str(self._rust_graph)
    
    def __len__(self) -> int:
        """Return the number of nodes in the graph."""
        return len(self.node_ids())
    
    # === FUTURE PHASES - TO BE IMPLEMENTED ===
    
    def commit(self, message: str, author: str) -> StateId:
        """Commit current changes to create a new state."""
        raise NotImplementedError("commit")
    
    def has_uncommitted_changes(self) -> bool:
        """Check if there are uncommitted changes."""
        raise NotImplementedError("has_uncommitted_changes")
    
    def create_branch(self, branch_name: BranchName) -> None:
        """Create a new branch."""
        raise NotImplementedError("create_branch")
    
    def checkout_branch(self, branch_name: BranchName) -> None:
        """Switch to a different branch."""
        raise NotImplementedError("checkout_branch")


--- FILE: groggy/enhanced_query.py ---
"""
Enhanced Query Engine - Logical operators and complex expressions

This module provides an enhanced query interface that supports logical operators
(AND, OR, NOT) and complex expressions by applying filters in Python rather than
relying on the Rust core for logical combinations.
"""

import re
from typing import Union, List, Set
from . import Graph
from .query_parser import parse_node_query, parse_edge_query
from ._groggy import NodeFilter, EdgeFilter

class EnhancedQueryEngine:
    """Enhanced query engine with support for logical operators."""
    
    def __init__(self, graph: Graph):
        self.graph = graph
    
    def filter_nodes(self, query: str):
        """Filter nodes using enhanced query syntax with logical operators."""
        return self._evaluate_node_query(query)
    
    def filter_edges(self, query: str):
        """Filter edges using enhanced query syntax with logical operators."""
        return self._evaluate_edge_query(query)
    
    def _evaluate_node_query(self, query: str):
        """Evaluate a node query with logical operators."""
        # Normalize the query
        query = query.strip()
        normalized_query = query.upper()
        
        # Check for logical operators
        if ' AND ' in normalized_query:
            return self._evaluate_and_node_query(query)
        elif ' OR ' in normalized_query:
            return self._evaluate_or_node_query(query)
        elif normalized_query.startswith('NOT '):
            return self._evaluate_not_node_query(query)
        else:
            # Single filter - use the original parsing
            node_filter = parse_node_query(query)
            return self.graph.filter_nodes(node_filter)
    
    def _evaluate_edge_query(self, query: str):
        """Evaluate an edge query with logical operators."""
        # Normalize the query
        query = query.strip()
        normalized_query = query.upper()
        
        # Check for logical operators
        if ' AND ' in normalized_query:
            return self._evaluate_and_edge_query(query)
        elif ' OR ' in normalized_query:
            return self._evaluate_or_edge_query(query)
        elif normalized_query.startswith('NOT '):
            return self._evaluate_not_edge_query(query)
        else:
            # Single filter - use the original parsing
            edge_filter = parse_edge_query(query)
            return self.graph.filter_edges(edge_filter)
    
    def _evaluate_and_node_query(self, query: str):
        """Evaluate an AND node query by intersecting results."""
        parts = re.split(r'\s+AND\s+', query, flags=re.IGNORECASE)
        if len(parts) != 2:
            raise ValueError(f"Complex AND expressions with more than 2 parts not yet supported: {query}")
        
        # Get results for each part
        left_result = self._evaluate_node_query(parts[0].strip())
        right_result = self._evaluate_node_query(parts[1].strip())
        
        # Intersect the node sets
        left_nodes = set(left_result.nodes)
        right_nodes = set(right_result.nodes)
        intersection_nodes = left_nodes & right_nodes
        
        # Create a subgraph with the intersection
        return self._create_node_subgraph(intersection_nodes, f"AND({parts[0].strip()}, {parts[1].strip()})")
    
    def _evaluate_or_node_query(self, query: str):
        """Evaluate an OR node query by unioning results."""
        parts = re.split(r'\s+OR\s+', query, flags=re.IGNORECASE)
        if len(parts) != 2:
            raise ValueError(f"Complex OR expressions with more than 2 parts not yet supported: {query}")
        
        # Get results for each part
        left_result = self._evaluate_node_query(parts[0].strip())
        right_result = self._evaluate_node_query(parts[1].strip())
        
        # Union the node sets
        left_nodes = set(left_result.nodes)
        right_nodes = set(right_result.nodes)
        union_nodes = left_nodes | right_nodes
        
        # Create a subgraph with the union
        return self._create_node_subgraph(union_nodes, f"OR({parts[0].strip()}, {parts[1].strip()})")
    
    def _evaluate_not_node_query(self, query: str):
        """Evaluate a NOT node query by complementing results."""
        # Remove 'NOT ' from the beginning
        inner_query = re.sub(r'^NOT\s+', '', query, flags=re.IGNORECASE).strip()
        
        # Get all nodes
        all_nodes = set(self.graph.node_ids)
        
        # Get nodes that match the inner query
        inner_result = self._evaluate_node_query(inner_query)
        matching_nodes = set(inner_result.nodes)
        
        # Complement: all nodes that don't match
        complement_nodes = all_nodes - matching_nodes
        
        # Create a subgraph with the complement
        return self._create_node_subgraph(complement_nodes, f"NOT({inner_query})")
    
    def _evaluate_and_edge_query(self, query: str):
        """Evaluate an AND edge query by intersecting results."""
        parts = re.split(r'\s+AND\s+', query, flags=re.IGNORECASE)
        if len(parts) != 2:
            raise ValueError(f"Complex AND expressions with more than 2 parts not yet supported: {query}")
        
        # Get results for each part
        left_result = self._evaluate_edge_query(parts[0].strip())
        right_result = self._evaluate_edge_query(parts[1].strip())
        
        # Intersect the edge sets
        left_edges = set(left_result if isinstance(left_result, list) else left_result.edges)
        right_edges = set(right_result if isinstance(right_result, list) else right_result.edges)
        intersection_edges = left_edges & right_edges
        
        return list(intersection_edges)
    
    def _evaluate_or_edge_query(self, query: str):
        """Evaluate an OR edge query by unioning results."""
        parts = re.split(r'\s+OR\s+', query, flags=re.IGNORECASE)
        if len(parts) != 2:
            raise ValueError(f"Complex OR expressions with more than 2 parts not yet supported: {query}")
        
        # Get results for each part
        left_result = self._evaluate_edge_query(parts[0].strip())
        right_result = self._evaluate_edge_query(parts[1].strip())
        
        # Union the edge sets
        left_edges = set(left_result if isinstance(left_result, list) else left_result.edges)
        right_edges = set(right_result if isinstance(right_result, list) else right_result.edges)
        union_edges = left_edges | right_edges
        
        return list(union_edges)
    
    def _evaluate_not_edge_query(self, query: str):
        """Evaluate a NOT edge query by complementing results."""
        # Remove 'NOT ' from the beginning
        inner_query = re.sub(r'^NOT\s+', '', query, flags=re.IGNORECASE).strip()
        
        # Get all edges
        all_edges = set(self.graph.edge_ids)
        
        # Get edges that match the inner query
        inner_result = self._evaluate_edge_query(inner_query)
        matching_edges = set(inner_result if isinstance(inner_result, list) else inner_result.edges)
        
        # Complement: all edges that don't match
        complement_edges = all_edges - matching_edges
        
        return list(complement_edges)
    
    def _create_node_subgraph(self, node_ids: Set[int], description: str):
        """Create a subgraph from a set of node IDs."""
        
        # Find all edges that connect nodes in the set
        connecting_edges = []
        for edge_id in self.graph.edge_ids:
            edge_view = self.graph.edges[edge_id]
            source = edge_view.source
            target = edge_view.target
            if source in node_ids and target in node_ids:
                connecting_edges.append(edge_id)
        
        return EnhancedSubgraph(node_ids, connecting_edges, description)

class EnhancedSubgraph:
    """A subgraph-like object that combines multiple filters with logical operators."""
    
    def __init__(self, nodes, edges, subgraph_type):
        self.nodes = list(nodes)
        self.edges = edges
        self.subgraph_type = subgraph_type
    
    def __repr__(self):
        return f"EnhancedSubgraph({len(self.nodes)} nodes, {len(self.edges)} edges, {self.subgraph_type})"

# Convenience functions for backward compatibility
def enhanced_filter_nodes(graph: Graph, query: str):
    """Filter nodes using enhanced query syntax."""
    engine = EnhancedQueryEngine(graph)
    return engine.filter_nodes(query)

def enhanced_filter_edges(graph: Graph, query: str):
    """Filter edges using enhanced query syntax."""
    engine = EnhancedQueryEngine(graph)
    return engine.filter_edges(query)

--- FILE: groggy/__init__.py ---
"""
Groggy - High-performance graph library with memory optimization and Git-like version control

This package provides a Pythonic interface to the high-performance Rust graph library.
"""

# Import directly from Rust extension for Phase 3 functionality
from ._groggy import (
    Graph,
    AttrValue,
    NodeFilter,
    EdgeFilter, 
    AttributeFilter,
    TraversalResult,
    AggregationResult,
    GroupedAggregationResult,
    PyResultHandle,
    PyAttributeCollection,
    # Version control classes
    Commit,
    BranchInfo,
    HistoryStatistics,
    HistoricalView,
    # Statistical arrays and matrices
    GraphArray,
    GraphMatrix,
    # Display functionality
    DisplayConfig,
    format_array,
    format_matrix,
    format_table,
    format_data_structure,
    detect_display_type,
)

from .types import NodeId, EdgeId, AttrName, StateId, BranchName
from .errors import (
    GroggyError, 
    NodeNotFoundError, 
    EdgeNotFoundError, 
    InvalidInputError, 
    NotImplementedError
)
from .query_parser import parse_node_query, parse_edge_query
from . import generators
from .generators import (
    complete_graph,
    erdos_renyi,
    barabasi_albert,
    watts_strogatz,
    cycle_graph,
    path_graph,
    star_graph,
    grid_graph,
    tree,
    karate_club,
    social_network,
)
from . import networkx_compat
from .enhanced_query import enhanced_filter_nodes, enhanced_filter_edges
from .graph_table import GraphTable
from . import table_extensions

# Import display formatters for rich display integration
try:
    from .display.formatters import format_array, format_matrix, format_table
    _DISPLAY_AVAILABLE = True
except ImportError:
    _DISPLAY_AVAILABLE = False
    
    # Provide fallback functions if display module is not available
    def format_array(data):
        return f"GraphArray(len={len(data.get('data', []))}, dtype={data.get('dtype', 'object')})"
    
    def format_matrix(data):
        shape = data.get('shape', (0, 0))
        return f"GraphMatrix(shape={shape}, dtype={data.get('dtype', 'object')})"
        
    def format_table(data):
        shape = data.get('shape', (0, 0))
        return f"GraphTable(shape={shape})"

__version__ = "0.1.0"
__all__ = [
    "Graph",
    "AttrValue", 
    "NodeId",
    "EdgeId", 
    "AttrName",
    "StateId",
    "BranchName",
    "GroggyError",
    "NodeNotFoundError",
    "EdgeNotFoundError", 
    "InvalidInputError",
    "NotImplementedError",
    # Phase 3 classes
    "NodeFilter",
    "EdgeFilter",
    "AttributeFilter", 
    "TraversalResult",
    "AggregationResult",
    "GroupedAggregationResult",
    "PyResultHandle",
    "PyAttributeCollection",
    # Version control classes
    "Commit",
    "BranchInfo", 
    "HistoryStatistics",
    "HistoricalView",
    # Statistical arrays and matrices
    "GraphArray",
    "GraphMatrix",
    # Display functionality  
    "DisplayConfig",
    "format_array",
    "format_matrix", 
    "format_table",
    "format_data_structure",
    "detect_display_type",
    # Graph generators
    "generators",
    "complete_graph",
    "erdos_renyi",
    "barabasi_albert", 
    "watts_strogatz",
    "cycle_graph",
    "path_graph",
    "star_graph",
    "grid_graph",
    "tree",
    "karate_club",
    "social_network",
    # NetworkX interoperability
    "networkx_compat",
    # Enhanced query functions
    "enhanced_filter_nodes",
    "enhanced_filter_edges",
    # Graph table functionality
    "GraphTable",
]


--- FILE: groggy/types.py ---
from typing import Union, List, Dict, Optional, Tuple
from enum import Enum

# Type aliases matching Rust
NodeId = int
EdgeId = int  
AttrName = str
StateId = int
BranchName = str

class AttrValue:
    """Python representation of Rust AttrValue enum"""
    
    def __init__(self, value: Union[int, float, str, bool, List[float], bytes]):
        self._value = value
        self._type = self._determine_type(value)
    
    def _determine_type(self, value):
        if isinstance(value, int):
            return "int"
        elif isinstance(value, float):
            return "float"
        elif isinstance(value, str):
            return "text"
        elif isinstance(value, bool):
            return "bool"
        elif isinstance(value, list) and all(isinstance(x, float) for x in value):
            return "float_vec"
        elif isinstance(value, bytes):
            return "bytes"
        else:
            raise ValueError(f"Unsupported attribute value type: {type(value)}")
    
    @property
    def value(self):
        return self._value
    
    @property 
    def type_name(self) -> str:
        return self._type
    
    def __repr__(self) -> str:
        return f"AttrValue({self._value!r})"
    
    def __eq__(self, other) -> bool:
        if isinstance(other, AttrValue):
            return self._value == other._value
        return False

# Query filter types
class AttributeFilter:
    def __init__(self, filter_type: str, value: AttrValue, **kwargs):
        self.filter_type = filter_type
        self.value = value
        self.kwargs = kwargs

class NodeFilter:
    def __init__(self, filter_type: str, **kwargs):
        self.filter_type = filter_type
        self.kwargs = kwargs

class EdgeFilter:
    def __init__(self, filter_type: str, **kwargs):
        self.filter_type = filter_type
        self.kwargs = kwargs


--- FILE: groggy/generators.py ---
"""
Graph Generators - Create various graph families and synthetic datasets

This module provides functions to generate different types of graphs including:
- Classic graph families (complete, cycle, path, star, etc.)
- Random graph models (Erdős-Rényi, Barabási-Albert, Watts-Strogatz)
- Real-world network models (karate club, social networks)
- Synthetic datasets with attributes
"""

import random
import math
from typing import List, Dict, Any, Optional, Tuple, Union
from . import Graph
from .types import NodeId, EdgeId

def complete_graph(n: int, **node_attrs) -> Graph:
    """
    Generate a complete graph with n nodes (every pair of nodes connected).
    
    Args:
        n: Number of nodes
        **node_attrs: Additional attributes to set on all nodes
        
    Returns:
        Graph: Complete graph with n nodes and n*(n-1)/2 edges
        
    Example:
        >>> g = complete_graph(5, group="test")
        >>> print(f"Nodes: {g.node_count()}, Edges: {g.edge_count()}")
        Nodes: 5, Edges: 10
    """
    g = Graph()
    
    # ✅ BULK: Create node data with attributes
    node_data = []
    for i in range(n):
        node_dict = {"index": i, **node_attrs}
        node_data.append(node_dict)
    
    # Add all nodes with data at once
    nodes = g.add_nodes(node_data)
    
    # ✅ BULK: Create all edge pairs, then add at once
    edge_pairs = []
    for i in range(n):
        for j in range(i + 1, n):
            edge_pairs.append((nodes[i], nodes[j]))
    
    g.add_edges(edge_pairs)
    
    return g

def erdos_renyi(n: int, p: float, directed: bool = False, seed: Optional[int] = None, **node_attrs) -> Graph:
    """
    Generate an Erdős-Rényi random graph G(n,p).
    
    Args:
        n: Number of nodes
        p: Probability of edge creation between any pair of nodes (0 <= p <= 1)
        directed: If True, create directed edges
        seed: Random seed for reproducibility
        **node_attrs: Additional attributes to set on all nodes
        
    Returns:
        Graph: Random graph with n nodes and approximately p*n*(n-1)/2 edges
        
    Example:
        >>> g = erdos_renyi(100, 0.05, seed=42)
        >>> print(f"Nodes: {g.node_count()}, Edges: {g.edge_count()}")
    """
    if seed is not None:
        random.seed(seed)
    
    g = Graph()
    
    # ✅ BULK: Create node data with attributes
    node_data = []
    for i in range(n):
        node_dict = {"index": i, **node_attrs}
        node_data.append(node_dict)
    
    # Add all nodes with data at once
    nodes = g.add_nodes(node_data)
    
    # ✅ BULK: Create edge pairs, optimized for sparse graphs
    edge_pairs = []
    
    # For sparse graphs (p < 0.1), use sampling approach to avoid O(n²)
    if p < 0.1 and n > 1000:
        # Calculate expected number of edges
        if directed:
            total_possible_edges = n * (n - 1)
        else:
            total_possible_edges = n * (n - 1) // 2
        
        expected_edges = int(p * total_possible_edges)
        
        # Generate edges by sampling without replacement
        edges_created = 0
        max_attempts = min(expected_edges * 10, total_possible_edges)  # Avoid infinite loops
        attempts = 0
        
        used_pairs = set()
        while edges_created < expected_edges and attempts < max_attempts:
            i = random.randint(0, n - 1)
            j = random.randint(0, n - 1)
            
            if i == j:
                attempts += 1
                continue
            
            # Ensure consistent ordering for undirected graphs
            if not directed and i > j:
                i, j = j, i
            
            pair = (i, j)
            if pair not in used_pairs:
                used_pairs.add(pair)
                edge_pairs.append((nodes[i], nodes[j]))
                edges_created += 1
            
            attempts += 1
    else:
        # Use traditional O(n²) approach for dense graphs or small n
        for i in range(n):
            start_j = 0 if directed else i + 1
            for j in range(start_j, n):
                if i != j and random.random() < p:
                    edge_pairs.append((nodes[i], nodes[j]))
    
    g.add_edges(edge_pairs)
    
    return g

def barabasi_albert(n: int, m: int, seed: Optional[int] = None, **node_attrs) -> Graph:
    """
    Generate a Barabási-Albert scale-free network using preferential attachment.
    
    Args:
        n: Number of nodes
        m: Number of edges to attach from a new node to existing nodes
        seed: Random seed for reproducibility
        **node_attrs: Additional attributes to set on all nodes
        
    Returns:
        Graph: Scale-free graph with n nodes and approximately n*m edges
        
    Example:
        >>> g = barabasi_albert(1000, 3, seed=42)
        >>> print(f"Nodes: {g.node_count()}, Edges: {g.edge_count()}")
    """
    if seed is not None:
        random.seed(seed)
    
    if m >= n:
        raise ValueError("m must be less than n")
    
    g = Graph()
    
    # ✅ BULK: Create all node data first
    node_data = []
    for i in range(n):
        node_dict = {"index": i, **node_attrs}
        node_data.append(node_dict)
    
    # Add all nodes at once
    nodes = g.add_nodes(node_data)
    
    # ✅ BULK: Collect all edges, then add at once
    edge_pairs = []
    
    # Start with initial complete graph edges (m+1 nodes)
    for i in range(m + 1):
        for j in range(i + 1, m + 1):
            edge_pairs.append((nodes[i], nodes[j]))
    
    # Keep track of degree for preferential attachment
    degrees = [m] * (m + 1)  # Each initial node has degree m
    total_degree = sum(degrees)
    
    # Generate remaining edges with preferential attachment
    for i in range(m + 1, n):
        # Choose m nodes to connect to based on degree (preferential attachment)
        targets = set()  # Use set to avoid duplicates efficiently
        
        # More efficient preferential attachment using weighted sampling
        while len(targets) < m:
            # Weighted random selection based on degrees
            rand_val = random.randint(0, total_degree - 1)
            cumsum = 0
            for j, degree in enumerate(degrees):
                cumsum += degree
                if rand_val < cumsum and j not in targets:
                    targets.add(j)
                    break
            
            # Fallback: if we couldn't find a target after reasonable attempts
            if len(targets) == 0:
                available = [j for j in range(i) if j not in targets]
                if available:
                    targets.add(random.choice(available))
        
        # Add edges to collected pairs
        for target_idx in targets:
            edge_pairs.append((nodes[i], nodes[target_idx]))
            degrees[target_idx] += 1
        
        # Add degree for new node
        degrees.append(m)
        total_degree += 2 * m  # Each edge adds 2 to total degree
    
    g.add_edges(edge_pairs)
    
    return g

def watts_strogatz(n: int, k: int, p: float, seed: Optional[int] = None, **node_attrs) -> Graph:
    """
    Generate a Watts-Strogatz small-world network.
    
    Args:
        n: Number of nodes
        k: Each node is connected to k nearest neighbors in ring topology
        p: Probability of rewiring each edge
        seed: Random seed for reproducibility
        **node_attrs: Additional attributes to set on all nodes
        
    Returns:
        Graph: Small-world network with n nodes
        
    Example:
        >>> g = watts_strogatz(1000, 6, 0.1, seed=42)
        >>> print(f"Nodes: {g.node_count()}, Edges: {g.edge_count()}")
    """
    if seed is not None:
        random.seed(seed)
    
    if k >= n:
        raise ValueError("k must be less than n")
    if k % 2 != 0:
        raise ValueError("k must be even")
    
    g = Graph()
    
    # ✅ BULK: Create all node data first
    node_data = []
    for i in range(n):
        node_dict = {"index": i, **node_attrs}
        node_data.append(node_dict)
    
    # Add all nodes at once
    nodes = g.add_nodes(node_data)
    
    # Create ring lattice (each node connected to k/2 neighbors on each side)
    edges = []
    for i in range(n):
        for j in range(1, k // 2 + 1):
            neighbor = (i + j) % n
            edges.append((i, neighbor))
    
    # Rewire edges with probability p
    rewired_edges = []
    for i, j in edges:
        if random.random() < p:
            # Rewire: choose new target randomly
            possible_targets = [x for x in range(n) if x != i and x not in [edge[1] for edge in rewired_edges if edge[0] == i]]
            if possible_targets:
                j = random.choice(possible_targets)
        rewired_edges.append((i, j))
    
    # ✅ BULK: Convert to node pairs and add all edges at once
    edge_pairs = []
    for i, j in rewired_edges:
        edge_pairs.append((nodes[i], nodes[j]))
    
    g.add_edges(edge_pairs)
    
    return g

def cycle_graph(n: int, **node_attrs) -> Graph:
    """
    Generate a cycle graph with n nodes.
    
    Args:
        n: Number of nodes
        **node_attrs: Additional attributes to set on all nodes
        
    Returns:
        Graph: Cycle graph with n nodes and n edges
    """
    g = Graph()
    
    # ✅ BULK: Create all node data first
    node_data = []
    for i in range(n):
        node_dict = {"index": i, **node_attrs}
        node_data.append(node_dict)
    
    # Add all nodes at once
    nodes = g.add_nodes(node_data)
    
    # ✅ BULK: Create all edge pairs, then add at once
    edge_pairs = []
    for i in range(n):
        next_node = (i + 1) % n
        edge_pairs.append((nodes[i], nodes[next_node]))
    
    g.add_edges(edge_pairs)
    
    return g

def path_graph(n: int, **node_attrs) -> Graph:
    """
    Generate a path graph with n nodes.
    
    Args:
        n: Number of nodes
        **node_attrs: Additional attributes to set on all nodes
        
    Returns:
        Graph: Path graph with n nodes and n-1 edges
    """
    g = Graph()
    
    # ✅ BULK: Create all node data first
    node_data = []
    for i in range(n):
        node_dict = {"index": i, **node_attrs}
        node_data.append(node_dict)
    
    # Add all nodes at once
    nodes = g.add_nodes(node_data)
    
    # ✅ BULK: Create all edge pairs, then add at once
    edge_pairs = []
    for i in range(n - 1):
        edge_pairs.append((nodes[i], nodes[i + 1]))
    
    g.add_edges(edge_pairs)
    
    return g

def star_graph(n: int, **node_attrs) -> Graph:
    """
    Generate a star graph with n nodes (one central node connected to all others).
    
    Args:
        n: Number of nodes
        **node_attrs: Additional attributes to set on all nodes
        
    Returns:
        Graph: Star graph with n nodes and n-1 edges
    """
    g = Graph()
    
    # ✅ BULK: Create all node data first
    node_data = []
    for i in range(n):
        node_dict = {"index": i, **node_attrs}
        node_data.append(node_dict)
    
    # Add all nodes at once
    nodes = g.add_nodes(node_data)
    
    # ✅ BULK: Create all edge pairs (center to all others), then add at once
    edge_pairs = []
    center = nodes[0]
    for i in range(1, n):
        edge_pairs.append((center, nodes[i]))
    
    g.add_edges(edge_pairs)
    
    return g

def grid_graph(dims: List[int], **node_attrs) -> Graph:
    """
    Generate a grid graph with given dimensions.
    
    Args:
        dims: List of dimensions [width, height] or [width, height, depth]
        **node_attrs: Additional attributes to set on all nodes
        
    Returns:
        Graph: Grid graph
        
    Example:
        >>> g = grid_graph([10, 10])  # 10x10 2D grid
        >>> g = grid_graph([5, 5, 5])  # 5x5x5 3D grid
    """
    g = Graph()
    
    if len(dims) == 2:
        width, height = dims
        
        # ✅ BULK: Create all node data first
        node_data = []
        coord_to_idx = {}
        idx = 0
        for x in range(width):
            for y in range(height):
                node_dict = {"x": x, "y": y, **node_attrs}
                node_data.append(node_dict)
                coord_to_idx[(x, y)] = idx
                idx += 1
        
        # Add all nodes at once
        nodes = g.add_nodes(node_data)
        
        # ✅ BULK: Create all edge pairs, then add at once
        edge_pairs = []
        for x in range(width):
            for y in range(height):
                current_idx = coord_to_idx[(x, y)]
                current = nodes[current_idx]
                # Right neighbor
                if x + 1 < width:
                    neighbor_idx = coord_to_idx[(x + 1, y)]
                    edge_pairs.append((current, nodes[neighbor_idx]))
                # Down neighbor  
                if y + 1 < height:
                    neighbor_idx = coord_to_idx[(x, y + 1)]
                    edge_pairs.append((current, nodes[neighbor_idx]))
        
        g.add_edges(edge_pairs)
    
    elif len(dims) == 3:
        width, height, depth = dims
        
        # ✅ BULK: Create all node data first
        node_data = []
        coord_to_idx = {}
        idx = 0
        for x in range(width):
            for y in range(height):
                for z in range(depth):
                    node_dict = {"x": x, "y": y, "z": z, **node_attrs}
                    node_data.append(node_dict)
                    coord_to_idx[(x, y, z)] = idx
                    idx += 1
        
        # Add all nodes at once
        nodes = g.add_nodes(node_data)
        
        # ✅ BULK: Create all edge pairs, then add at once
        edge_pairs = []
        for x in range(width):
            for y in range(height):
                for z in range(depth):
                    current_idx = coord_to_idx[(x, y, z)]
                    current = nodes[current_idx]
                    # Right neighbor
                    if x + 1 < width:
                        neighbor_idx = coord_to_idx[(x + 1, y, z)]
                        edge_pairs.append((current, nodes[neighbor_idx]))
                    # Down neighbor
                    if y + 1 < height:
                        neighbor_idx = coord_to_idx[(x, y + 1, z)]
                        edge_pairs.append((current, nodes[neighbor_idx]))
                    # Forward neighbor
                    if z + 1 < depth:
                        neighbor_idx = coord_to_idx[(x, y, z + 1)]
                        edge_pairs.append((current, nodes[neighbor_idx]))
        
        g.add_edges(edge_pairs)
    
    else:
        raise ValueError("Only 2D and 3D grids are supported")
    
    return g

def tree(n: int, branching_factor: int = 2, **node_attrs) -> Graph:
    """
    Generate a regular tree with n nodes.
    
    Args:
        n: Number of nodes
        branching_factor: Number of children per internal node
        **node_attrs: Additional attributes to set on all nodes
        
    Returns:
        Graph: Tree with n nodes and n-1 edges
    """
    g = Graph()
    
    if n <= 0:
        return g
    
    # ✅ BULK: Create all node data first
    node_data = []
    for i in range(n):
        level = 0
        temp_i = i
        temp_bf = branching_factor
        while temp_i >= temp_bf:
            temp_i -= temp_bf
            temp_bf *= branching_factor
            level += 1
        
        node_dict = {"index": i, "level": level, **node_attrs}
        node_data.append(node_dict)
    
    # Add all nodes at once
    nodes = g.add_nodes(node_data)
    
    # ✅ BULK: Create all edge pairs, then add at once
    edge_pairs = []
    
    # Create parent-child relationships
    for i in range(1, n):  # Skip root (node 0)
        parent_idx = (i - 1) // branching_factor
        if parent_idx < len(nodes):
            edge_pairs.append((nodes[parent_idx], nodes[i]))
    
    g.add_edges(edge_pairs)
    
    return g

# Real-world network models
def karate_club() -> Graph:
    """
    Generate Zachary's karate club graph.
    
    Returns:
        Graph: The famous karate club social network (34 nodes, 78 edges)
    """
    g = Graph()
    
    # ✅ BULK: Create all node data first
    node_data = []
    for i in range(34):
        node_dict = {"index": i, "name": f"Member_{i}"}
        node_data.append(node_dict)
    
    # Add all nodes at once
    nodes = g.add_nodes(node_data)
    
    # Define the edges from the original dataset
    edges = [
        (0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (0, 6), (0, 7), (0, 8), 
        (0, 10), (0, 11), (0, 12), (0, 13), (0, 17), (0, 19), (0, 21), (0, 31),
        (1, 2), (1, 3), (1, 7), (1, 13), (1, 17), (1, 19), (1, 21), (1, 30),
        (2, 3), (2, 7), (2, 8), (2, 9), (2, 13), (2, 27), (2, 28), (2, 32),
        (3, 7), (3, 12), (3, 13), (4, 6), (4, 10), (5, 6), (5, 10), (5, 16),
        (6, 16), (8, 30), (8, 32), (8, 33), (9, 33), (13, 33), (14, 32), (14, 33),
        (15, 32), (15, 33), (18, 32), (18, 33), (19, 33), (20, 32), (20, 33),
        (22, 32), (22, 33), (23, 25), (23, 27), (23, 29), (23, 32), (23, 33),
        (24, 25), (24, 27), (24, 31), (25, 31), (26, 29), (26, 33), (27, 33),
        (28, 31), (28, 33), (29, 32), (29, 33), (30, 32), (30, 33), (31, 32), (31, 33), (32, 33)
    ]
    
    # ✅ BULK: Create all edge data with attributes, then add at once
    edge_data = []
    for i, j in edges:
        edge_data.append((nodes[i], nodes[j], {"relationship": "friendship"}))
    
    g.add_edges(edge_data)
    
    return g

def social_network(n: int, communities: int = 3, 
                  node_attrs: Optional[List[str]] = None,
                  edge_attrs: Optional[List[str]] = None,
                  seed: Optional[int] = None) -> Graph:
    """
    Generate a synthetic social network with realistic attributes.
    
    Args:
        n: Number of nodes (people)
        communities: Number of communities/clusters
        node_attrs: List of node attribute names to generate
        edge_attrs: List of edge attribute names to generate  
        seed: Random seed for reproducibility
        
    Returns:
        Graph: Synthetic social network with attributes
    """
    if seed is not None:
        random.seed(seed)
    
    if node_attrs is None:
        node_attrs = ['age', 'income', 'location']
    if edge_attrs is None:
        edge_attrs = ['strength', 'frequency']
    
    g = Graph()
    
    # Generate realistic attribute values
    locations = ['NYC', 'SF', 'LA', 'Chicago', 'Boston', 'Austin', 'Seattle', 'Denver']
    
    # ✅ BULK: Create all node data first
    node_data = []
    for i in range(n):
        attrs = {'index': i, 'community': i % communities}
        
        if 'age' in node_attrs:
            attrs['age'] = random.randint(18, 65)
        if 'income' in node_attrs:
            attrs['income'] = random.randint(30000, 200000)
        if 'location' in node_attrs:
            attrs['location'] = random.choice(locations)
        
        node_data.append(attrs)
    
    # Add all nodes at once
    nodes = g.add_nodes(node_data)
    
    # ✅ BULK: Create edges more efficiently using expected degree approach
    edge_data = []
    
    # Group nodes by community for efficient sampling
    community_nodes = {}
    for i, node_id in enumerate(nodes):
        community = i % communities
        if community not in community_nodes:
            community_nodes[community] = []
        community_nodes[community].append((i, node_id))
    
    # Generate edges within communities (higher probability)
    within_community_p = 0.15
    for community, node_list in community_nodes.items():
        community_size = len(node_list)
        expected_edges = int(within_community_p * community_size * (community_size - 1) / 2)
        
        # Sample edge pairs efficiently
        all_pairs = [(i, j) for i in range(community_size) for j in range(i + 1, community_size)]
        if len(all_pairs) > 0:
            # Sample without replacement up to expected number
            num_edges = min(expected_edges, len(all_pairs))
            selected_pairs = random.sample(all_pairs, num_edges)
            
            for i_idx, j_idx in selected_pairs:
                i, node_i = node_list[i_idx]
                j, node_j = node_list[j_idx]
                
                edge_attrs_dict = {}
                if 'strength' in edge_attrs:
                    edge_attrs_dict['strength'] = random.uniform(0.1, 1.0)
                if 'frequency' in edge_attrs:
                    edge_attrs_dict['frequency'] = random.choice(['daily', 'weekly', 'monthly', 'rarely'])
                
                edge_data.append((node_i, node_j, edge_attrs_dict))
    
    # Generate edges between communities (lower probability)
    between_community_p = 0.02
    total_inter_community_pairs = 0
    for i in range(communities):
        for j in range(i + 1, communities):
            total_inter_community_pairs += len(community_nodes[i]) * len(community_nodes[j])
    
    expected_inter_edges = int(between_community_p * total_inter_community_pairs)
    
    # Efficiently sample inter-community edges
    inter_community_edges = 0
    for i in range(communities):
        for j in range(i + 1, communities):
            if inter_community_edges >= expected_inter_edges:
                break
                
            nodes_i = community_nodes[i]
            nodes_j = community_nodes[j]
            
            # Sample a reasonable number of pairs between these communities
            pairs_needed = min(len(nodes_i) * len(nodes_j), 
                             expected_inter_edges - inter_community_edges)
            
            for _ in range(pairs_needed):
                if random.random() < between_community_p:
                    node_i_idx, node_i = random.choice(nodes_i)
                    node_j_idx, node_j = random.choice(nodes_j)
                    
                    edge_attrs_dict = {}
                    if 'strength' in edge_attrs:
                        edge_attrs_dict['strength'] = random.uniform(0.1, 1.0)
                    if 'frequency' in edge_attrs:
                        edge_attrs_dict['frequency'] = random.choice(['daily', 'weekly', 'monthly', 'rarely'])
                    
                    edge_data.append((node_i, node_j, edge_attrs_dict))
                    inter_community_edges += 1
    
    g.add_edges(edge_data)
    
    return g

--- FILE: groggy/networkx_compat.py ---
"""
NetworkX Interoperability - Seamless conversion to/from NetworkX

This module provides functions to convert between Groggy graphs and NetworkX graphs,
enabling users to leverage the NetworkX ecosystem while benefiting from Groggy's
performance and advanced features.
"""

from typing import Dict, Any, Optional, Union, List
from . import Graph
from .types import NodeId, EdgeId

def to_networkx(graph: Graph, 
                directed: bool = False,
                include_attributes: bool = True,
                node_attr_prefix: str = "",
                edge_attr_prefix: str = "") -> 'networkx.Graph':
    """
    Convert a Groggy graph to a NetworkX graph.
    
    Args:
        graph: Groggy graph to convert
        directed: If True, create a directed NetworkX graph
        include_attributes: If True, include node and edge attributes
        node_attr_prefix: Prefix for node attribute names in NetworkX
        edge_attr_prefix: Prefix for edge attribute names in NetworkX
        
    Returns:
        NetworkX graph (Graph or DiGraph depending on directed parameter)
        
    Example:
        >>> import groggy as gr
        >>> g = gr.generators.karate_club()
        >>> nx_graph = to_networkx(g)
        >>> print(f"NetworkX graph: {nx_graph.number_of_nodes()} nodes, {nx_graph.number_of_edges()} edges")
    """
    try:
        import networkx as nx
    except ImportError:
        raise ImportError("NetworkX is required for interoperability. Install with: pip install networkx")
    
    # Create NetworkX graph
    if directed:
        nx_graph = nx.DiGraph()
    else:
        nx_graph = nx.Graph()
    
    # Add nodes
    node_ids = graph.node_ids
    for node_id in node_ids:
        node_attrs = {}
        if include_attributes:
            # Try to get common attributes
            for attr_name in ['name', 'index', 'level', 'component_id', 'age', 'dept', 'salary', 'location', 'community']:
                try:
                    if hasattr(graph.nodes[node_id], '__getitem__'):
                        attr_value = graph.nodes[node_id][attr_name]
                        # Convert to Python native types for NetworkX compatibility
                        if hasattr(attr_value, 'inner'):
                            attr_value = attr_value.inner
                        node_attrs[f"{node_attr_prefix}{attr_name}"] = attr_value
                except (KeyError, AttributeError):
                    continue
        
        nx_graph.add_node(node_id, **node_attrs)
    
    # Add edges
    edge_ids = graph.edge_ids
    for edge_id in edge_ids:
        try:
            edge_view = graph.edges[edge_id]
            source = edge_view.source
            target = edge_view.target
            
            edge_attrs = {}
            if include_attributes:
                # Try to get common edge attributes
                for attr_name in ['weight', 'relationship', 'type', 'strength', 'frequency']:
                    try:
                        attr_value = edge_view[attr_name]
                        # Convert to Python native types for NetworkX compatibility
                        if hasattr(attr_value, 'inner'):
                            attr_value = attr_value.inner
                        edge_attrs[f"{edge_attr_prefix}{attr_name}"] = attr_value
                    except (KeyError, AttributeError):
                        continue
            
            nx_graph.add_edge(source, target, **edge_attrs)
            
        except Exception:
            # Skip edges that can't be processed
            continue
    
    return nx_graph

def from_networkx(nx_graph: 'networkx.Graph',
                 preserve_node_attrs: bool = True,
                 preserve_edge_attrs: bool = True,
                 handle_multiedges: str = 'keep_first',
                 node_attr_mapping: Optional[Dict[str, str]] = None,
                 edge_attr_mapping: Optional[Dict[str, str]] = None) -> Graph:
    """
    Convert a NetworkX graph to a Groggy graph.
    
    Args:
        nx_graph: NetworkX graph to convert
        preserve_node_attrs: If True, preserve node attributes
        preserve_edge_attrs: If True, preserve edge attributes
        handle_multiedges: How to handle multiple edges ('keep_first', 'keep_last', 'merge')
        node_attr_mapping: Mapping from NetworkX attr names to Groggy attr names
        edge_attr_mapping: Mapping from NetworkX attr names to Groggy attr names
        
    Returns:
        Groggy graph with equivalent structure and attributes
        
    Example:
        >>> import networkx as nx
        >>> import groggy as gr
        >>> nx_g = nx.karate_club_graph()
        >>> groggy_g = from_networkx(nx_g)
        >>> print(f"Groggy graph: {groggy_g.node_count()} nodes, {groggy_g.edge_count()} edges")
    """
    try:
        import networkx as nx
    except ImportError:
        raise ImportError("NetworkX is required for interoperability. Install with: pip install networkx")
    
    g = Graph()
    
    # Mapping from NetworkX node IDs to Groggy node IDs
    node_mapping = {}
    
    # Add nodes
    for nx_node_id in nx_graph.nodes():
        node_attrs = {}
        
        if preserve_node_attrs:
            nx_attrs = nx_graph.nodes[nx_node_id]
            for attr_name, attr_value in nx_attrs.items():
                # Apply attribute name mapping if provided
                groggy_attr_name = attr_name
                if node_attr_mapping and attr_name in node_attr_mapping:
                    groggy_attr_name = node_attr_mapping[attr_name]
                
                # Convert NetworkX attributes to Groggy-compatible types
                node_attrs[groggy_attr_name] = _convert_networkx_attr_value(attr_value)
        
        # Add original NetworkX node ID as an attribute for reference
        node_attrs['nx_node_id'] = nx_node_id
        
        groggy_node_id = g.add_node(**node_attrs)
        node_mapping[nx_node_id] = groggy_node_id
    
    # Add edges
    edges_added = set()  # Track edges for multiedge handling
    
    for nx_source, nx_target in nx_graph.edges():
        groggy_source = node_mapping[nx_source]
        groggy_target = node_mapping[nx_target]
        
        # Handle multiedges
        edge_key = (min(groggy_source, groggy_target), max(groggy_source, groggy_target))
        if edge_key in edges_added:
            if handle_multiedges == 'keep_first':
                continue  # Skip additional edges
            elif handle_multiedges == 'keep_last':
                # Would need to remove previous edge, but for simplicity, just skip
                continue
            # For 'merge', we could combine attributes, but skip for now
        
        edge_attrs = {}
        
        if preserve_edge_attrs:
            # Handle edge attributes (NetworkX can have different formats)
            if hasattr(nx_graph, 'edges') and hasattr(nx_graph.edges, '__getitem__'):
                try:
                    if nx_graph.is_multigraph():
                        # MultiGraph case - get first edge's attributes
                        edge_data = nx_graph.edges[nx_source, nx_target, 0]
                    else:
                        edge_data = nx_graph.edges[nx_source, nx_target]
                    
                    for attr_name, attr_value in edge_data.items():
                        # Apply attribute name mapping if provided
                        groggy_attr_name = attr_name
                        if edge_attr_mapping and attr_name in edge_attr_mapping:
                            groggy_attr_name = edge_attr_mapping[attr_name]
                        
                        # Convert NetworkX attributes to Groggy-compatible types
                        edge_attrs[groggy_attr_name] = _convert_networkx_attr_value(attr_value)
                
                except (KeyError, AttributeError):
                    pass
        
        g.add_edge(groggy_source, groggy_target, **edge_attrs)
        edges_added.add(edge_key)
    
    return g

def _convert_networkx_attr_value(value: Any) -> Any:
    """Convert NetworkX attribute values to Groggy-compatible types."""
    import numpy as np
    
    # Handle numpy types
    if isinstance(value, np.integer):
        return int(value)
    elif isinstance(value, np.floating):
        return float(value)
    elif isinstance(value, np.bool_):
        return bool(value)
    elif isinstance(value, np.ndarray):
        return value.tolist()
    
    # Handle basic Python types (already compatible)
    if isinstance(value, (int, float, str, bool)):
        return value
    elif isinstance(value, (list, tuple)):
        return [_convert_networkx_attr_value(v) for v in value]
    elif isinstance(value, dict):
        return {k: _convert_networkx_attr_value(v) for k, v in value.items()}
    
    # For other types, convert to string
    return str(value)

# Add convenience methods to Graph class
def _add_networkx_methods():
    """Add NetworkX interoperability methods to the Graph class."""
    
    def to_networkx_method(self, directed: bool = False, include_attributes: bool = True):
        """Convert this graph to a NetworkX graph."""
        return to_networkx(self, directed=directed, include_attributes=include_attributes)
    
    # Add method to Graph class if it exists
    try:
        from . import Graph
        Graph.to_networkx = to_networkx_method
    except ImportError:
        pass

# Initialize NetworkX compatibility when module is imported
_add_networkx_methods()

--- FILE: groggy/errors.py ---
from typing import Optional
from .types import NodeId, EdgeId

class GroggyError(Exception):
    """Base exception for all Groggy errors"""
    pass

class NodeNotFoundError(GroggyError):
    """Raised when a node is not found"""
    def __init__(self, node_id: NodeId, operation: str, suggestion: str = ""):
        self.node_id = node_id
        self.operation = operation
        self.suggestion = suggestion
        super().__init__(f"Node {node_id} not found during {operation}. {suggestion}")

class EdgeNotFoundError(GroggyError):
    """Raised when an edge is not found"""
    def __init__(self, edge_id: EdgeId, operation: str, suggestion: str = ""):
        self.edge_id = edge_id
        self.operation = operation
        self.suggestion = suggestion
        super().__init__(f"Edge {edge_id} not found during {operation}. {suggestion}")

class InvalidInputError(GroggyError):
    """Raised for invalid input parameters"""
    pass

class NotImplementedError(GroggyError):
    """Raised for features not yet implemented"""
    def __init__(self, feature: str, tracking_issue: Optional[str] = None):
        self.feature = feature
        self.tracking_issue = tracking_issue
        message = f"Feature '{feature}' is not yet implemented"
        if tracking_issue:
            message += f". See: {tracking_issue}"
        super().__init__(message)


--- FILE: groggy/table_extensions.py ---
"""
Table Extensions - Add table() methods to Graph and Subgraph classes

This module adds DataFrame-like table() methods to existing graph classes.
"""

from .graph_table import GraphTable

def add_table_methods():
    """Add table() methods to Graph and related classes."""
    
    # Try to import the graph classes
    try:
        from ._groggy import Graph
        
        def graph_table(self):
            """Return a GraphTable view of all nodes."""
            return GraphTable(self, "nodes")
        
        # Add table method to Graph
        Graph.table = graph_table
        
    except ImportError:
        pass
    
    # Add table method to enhanced subgraphs
    try:
        from .enhanced_query import EnhancedSubgraph
        
        def enhanced_subgraph_table(self):
            """Return a GraphTable view of subgraph nodes."""
            return GraphTable(self, "nodes")
        
        EnhancedSubgraph.table = enhanced_subgraph_table
        
    except ImportError:
        pass

# Add edges table access
class EdgesTableAccessor:
    """Accessor for edges table functionality."""
    
    def __init__(self, graph_or_subgraph):
        self.graph_or_subgraph = graph_or_subgraph
    
    def table(self):
        """Return a GraphTable view of edges."""
        return GraphTable(self.graph_or_subgraph, "edges")

def add_edges_table_accessor():
    """Add edges.table() accessor to Graph classes."""
    
    try:
        from ._groggy import Graph
        
        # Store original edges property if it exists
        original_edges = getattr(Graph, 'edges', None)
        
        def enhanced_edges(self):
            """Enhanced edges accessor with table functionality."""
            accessor = EdgesTableAccessor(self)
            # If there's an original edges implementation, add it as an attribute
            if original_edges:
                accessor.original = original_edges.__get__(self, Graph)
            return accessor
        
        Graph.edges_table = enhanced_edges
        
    except ImportError:
        pass

# Initialize table functionality when module is imported
add_table_methods()
add_edges_table_accessor()

--- FILE: groggy/display/formatters.py ---
"""
Main formatters module providing high-level formatting functions.
"""

from typing import Dict, Any
from .table_display import format_table, TableDisplayFormatter
from .matrix_display import format_matrix, MatrixDisplayFormatter
from .array_display import format_array, ArrayDisplayFormatter

# Re-export main formatting functions
__all__ = [
    'format_table',
    'format_matrix', 
    'format_array',
    'TableDisplayFormatter',
    'MatrixDisplayFormatter',
    'ArrayDisplayFormatter'
]

# Convenience function that routes to appropriate formatter based on data type
def format_data_structure(data: Dict[str, Any], data_type: str = 'auto', **kwargs) -> str:
    """
    Format any groggy data structure for rich display.
    
    Args:
        data: The data structure to format
        data_type: Type hint ('table', 'matrix', 'array', or 'auto' for auto-detection)
        **kwargs: Additional formatting options
    
    Returns:
        Formatted string ready for display
    """
    if data_type == 'auto':
        data_type = _detect_data_type(data)
    
    if data_type == 'table':
        return format_table(data, **kwargs)
    elif data_type == 'matrix':
        return format_matrix(data, **kwargs)
    elif data_type == 'array':
        return format_array(data, **kwargs)
    else:
        raise ValueError(f"Unknown data type: {data_type}")

def _detect_data_type(data: Dict[str, Any]) -> str:
    """Auto-detect the data structure type based on contents."""
    if 'columns' in data and 'dtypes' in data:
        return 'table'
    elif 'data' in data and isinstance(data.get('data'), list):
        first_item = data['data'][0] if data['data'] else None
        if isinstance(first_item, list):
            return 'matrix'
        else:
            return 'array'
    else:
        # Default fallback
        return 'table'


--- FILE: groggy/display/integration_example.py ---
"""
Integration example showing how to hook the display module into existing Groggy classes.

This is a mockup showing how the display system would integrate with 
PyGraphTable, PyGraphMatrix, and PyGraphArray classes.
"""

from typing import Dict, Any, List
from groggy.display import format_table, format_matrix, format_array

class PyGraphTableWithDisplay:
    """Example PyGraphTable class with rich display integration."""
    
    def __init__(self, data: List[List[Any]], columns: List[str], dtypes: Dict[str, str]):
        self.data = data
        self.columns = columns
        self.dtypes = dtypes
    
    def _get_display_data(self) -> Dict[str, Any]:
        """Extract data in format expected by display module."""
        return {
            'columns': self.columns,
            'dtypes': self.dtypes,
            'data': self.data,
            'shape': (len(self.data), len(self.columns)),
            'nulls': self._count_nulls(),
            'index_type': 'int64'
        }
    
    def _count_nulls(self) -> Dict[str, int]:
        """Count null values per column."""
        nulls = {}
        for col_idx, col_name in enumerate(self.columns):
            null_count = sum(1 for row in self.data if row[col_idx] is None)
            if null_count > 0:
                nulls[col_name] = null_count
        return nulls
    
    def __repr__(self) -> str:
        """Rich display representation."""
        try:
            return format_table(self._get_display_data())
        except Exception as e:
            # Fallback to simple representation
            return f"PyGraphTable(shape={len(self.data), len(self.columns)}, columns={self.columns})"
    
    def __str__(self) -> str:
        """String representation (same as repr for rich display)."""
        return self.__repr__()

class PyGraphMatrixWithDisplay:
    """Example PyGraphMatrix class with rich display integration."""
    
    def __init__(self, data: List[List[Any]], dtype: str = 'f32'):
        self.data = data
        self.dtype = dtype
    
    def _get_display_data(self) -> Dict[str, Any]:
        """Extract data in format expected by display module."""
        return {
            'data': self.data,
            'shape': (len(self.data), len(self.data[0]) if self.data else 0),
            'dtype': self.dtype
        }
    
    def __repr__(self) -> str:
        """Rich display representation."""
        try:
            return format_matrix(self._get_display_data())
        except Exception as e:
            # Fallback to simple representation
            shape = (len(self.data), len(self.data[0]) if self.data else 0)
            return f"PyGraphMatrix(shape={shape}, dtype={self.dtype})"
    
    def __str__(self) -> str:
        """String representation (same as repr for rich display)."""
        return self.__repr__()

class PyGraphArrayWithDisplay:
    """Example PyGraphArray class with rich display integration."""
    
    def __init__(self, data: List[Any], dtype: str = 'f32', name: str = 'col1'):
        self.data = data
        self.dtype = dtype
        self.name = name
    
    def _get_display_data(self) -> Dict[str, Any]:
        """Extract data in format expected by display module."""
        return {
            'data': self.data,
            'dtype': self.dtype,
            'shape': (len(self.data),),
            'name': self.name
        }
    
    def __repr__(self) -> str:
        """Rich display representation."""
        try:
            return format_array(self._get_display_data())
        except Exception as e:
            # Fallback to simple representation
            return f"PyGraphArray(shape=({len(self.data)},), dtype={self.dtype})"
    
    def __str__(self) -> str:
        """String representation (same as repr for rich display)."""
        return self.__repr__()

# Demo the integration
def demo_integration():
    """Demonstrate the integrated display system."""
    print("Groggy Display Integration Demo")
    print("==============================\n")
    
    # Demo GraphTable with display
    table = PyGraphTableWithDisplay(
        data=[
            ['Alice', 'NYC', 25, 91.5],
            ['Bob', 'Paris', 30, 87.0],
            ['Charlie', 'Tokyo', 35, None]
        ],
        columns=['name', 'city', 'age', 'score'],
        dtypes={'name': 'string', 'city': 'category', 'age': 'int64', 'score': 'float32'}
    )
    
    print("GraphTable with Rich Display:")
    print(table)
    print()
    
    # Demo GraphMatrix with display
    matrix = PyGraphMatrixWithDisplay(
        data=[
            [0.12, -1.50, 2.00],
            [3.14, 0.00, 1.25],
            [-0.01, 4.50, 8.00]
        ],
        dtype='f32'
    )
    
    print("GraphMatrix with Rich Display:")
    print(matrix)
    print()
    
    # Demo GraphArray with display  
    array = PyGraphArrayWithDisplay(
        data=[0.125, 3.1416, float('nan'), -2.75, 8.0],
        dtype='f32',
        name='values'
    )
    
    print("GraphArray with Rich Display:")
    print(array)
    print()

if __name__ == '__main__':
    demo_integration()


--- FILE: groggy/display/test_simple.py ---
#!/usr/bin/env python3
"""Simple test of the table formatter."""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from groggy.display import format_table

def simple_test():
    table_data = {
        'columns': ['name', 'age'],
        'dtypes': {'name': 'string', 'age': 'int64'},
        'data': [
            ['Alice', 25],
            ['Bob', 30],
        ],
        'shape': (2, 2),
        'nulls': {},
        'index_type': 'int64'
    }
    
    formatted = format_table(table_data)
    print("Raw string:")
    print(repr(formatted))
    print("\nFormatted output:")
    print(formatted)

if __name__ == '__main__':
    simple_test()


--- FILE: groggy/display/__init__.py ---
"""
Rich Display Module for Groggy Data Structures

Provides beautiful, professional formatting for GraphTable, GraphMatrix, and GraphArray
using Unicode box-drawing characters and smart truncation.

Based on display_draft.txt requirements.
"""

from .formatters import format_table, format_matrix, format_array
from .table_display import TableDisplayFormatter
from .matrix_display import MatrixDisplayFormatter
from .array_display import ArrayDisplayFormatter

__all__ = [
    'format_table',
    'format_matrix', 
    'format_array',
    'TableDisplayFormatter',
    'MatrixDisplayFormatter',
    'ArrayDisplayFormatter'
]

# Default display settings
DEFAULT_MAX_ROWS = 10
DEFAULT_MAX_COLS = 8
DEFAULT_MAX_WIDTH = 120
DEFAULT_PRECISION = 2

def configure_display(max_rows=None, max_cols=None, max_width=None, precision=None):
    """Configure global display settings for all data structures."""
    global DEFAULT_MAX_ROWS, DEFAULT_MAX_COLS, DEFAULT_MAX_WIDTH, DEFAULT_PRECISION
    
    if max_rows is not None:
        DEFAULT_MAX_ROWS = max_rows
    if max_cols is not None:
        DEFAULT_MAX_COLS = max_cols  
    if max_width is not None:
        DEFAULT_MAX_WIDTH = max_width
    if precision is not None:
        DEFAULT_PRECISION = precision


--- FILE: groggy/display/README.md ---
# Groggy Rich Display Module

Beautiful, professional display formatting for GraphTable, GraphMatrix, and GraphArray data structures using Unicode box-drawing characters and smart truncation.

## Features

- **Professional Unicode formatting** with box-drawing characters (`╭─╮│├┤╰─╯`)
- **Smart truncation** for large datasets showing first/last rows and columns
- **Type annotations** showing data types (str[8], cat(12), f32, date, etc.)
- **Summary statistics** including row counts, column counts, null counts
- **Color support** (optional) for enhanced terminal display
- **Consistent API** across all Groggy data structures

## Example Outputs

### GraphTable Display
```
⊖⊖ gr.table
╭──────┬─────────┬───────────┬──────┬───────┬────────────╮
│    # │ name    │ city      │ age  │ score │ joined     │
│      │ str[8]  │ cat(12)   │ i64  │ f32   │ date       │
├──────┼─────────┼───────────┼──────┼───────┼────────────┤
│    0 │ Alice   │ NYC       │ 25   │ 91.50 │ 2024-02-15 │
│    1 │ Bob     │ Paris     │ 30   │ 87.00 │ 2023-11-20 │
│    … │ …       │ …         │ …    │ …     │ …          │
│   11 │ Liam    │ Amsterdam │ 30   │ 91.90 │ 2023-07-16 │
╰──────┴─────────┴───────────┴──────┴───────┴────────────╯
rows: 1,000 • cols: 5 • nulls: score=12 • index: int64
```

### GraphMatrix Display
```
⊖⊖ gr.matrix
╭────────┬────────┬────────┬────────┬────────┬────────╮
│   0.12 │  -1.50 │   2.00 │   ⋯    │   7.77 │   8.88 │
│   3.14 │   0.00 │    NaN │   ⋯    │  -2.10 │   1.25 │
│   ⋯    │   ⋯    │   ⋯    │   ⋯    │   ⋯    │   ⋯    │
│  -0.01 │   4.50 │  -2.30 │   ⋯    │   9.99 │   8.00 │
╰────────┴────────┴────────┴────────┴────────┴────────╯
shape: (500, 200) • dtype: f32
```

### GraphArray Display
```
⊖⊖ gr.array

╭───┬────────╮
│ # │ values │
│   │ f32    │
├───┼────────┤
│ 0 │  0.125 │
│ 1 │  3.142 │
│ 2 │ NaN    │
│ 3 │  -2.75 │
│ 4 │      8 │
╰───┴────────╯
shape: (5,)
```

## Usage

### Direct Formatting Functions

```python
from groggy.display import format_table, format_matrix, format_array

# Format a table
table_data = {
    'columns': ['name', 'age'],
    'dtypes': {'name': 'string', 'age': 'int64'},
    'data': [['Alice', 25], ['Bob', 30]],
    'shape': (2, 2),
    'nulls': {},
    'index_type': 'int64'
}
print(format_table(table_data))

# Format a matrix
matrix_data = {
    'data': [[1.0, 2.0], [3.0, 4.0]],
    'shape': (2, 2),
    'dtype': 'f32'
}
print(format_matrix(matrix_data))

# Format an array
array_data = {
    'data': [1.0, 2.0, 3.0],
    'dtype': 'f32',
    'shape': (3,),
    'name': 'values'
}
print(format_array(array_data))
```

### Class Integration

```python
from groggy.display import format_table

class MyDataStructure:
    def __init__(self, data):
        self.data = data
    
    def _get_display_data(self):
        return {
            'columns': ['col1', 'col2'],
            'dtypes': {'col1': 'int64', 'col2': 'float32'},
            'data': self.data,
            'shape': (len(self.data), 2),
            'nulls': {},
            'index_type': 'int64'
        }
    
    def __repr__(self):
        return format_table(self._get_display_data())
```

### Configuration

```python
from groggy.display import configure_display

# Configure global display settings
configure_display(
    max_rows=20,       # Show up to 20 rows
    max_cols=10,       # Show up to 10 columns  
    max_width=150,     # Maximum terminal width
    precision=3        # Floating point precision
)
```

## Module Structure

```
groggy/display/
├── __init__.py          # Public API and configuration
├── formatters.py        # Main formatting functions
├── table_display.py     # GraphTable formatter
├── matrix_display.py    # GraphMatrix formatter
├── array_display.py     # GraphArray formatter
├── unicode_chars.py     # Box-drawing characters
├── truncation.py        # Smart truncation algorithms
├── demo.py             # Demonstration script
└── integration_example.py # Integration examples
```

## Data Format Requirements

### GraphTable Data Format
```python
{
    'columns': ['col1', 'col2', ...],           # Column names
    'dtypes': {'col1': 'int64', 'col2': 'f32'}, # Column data types
    'data': [[val1, val2], [val3, val4], ...], # Row data
    'shape': (rows, cols),                      # Dimensions
    'nulls': {'col1': null_count},              # Null counts per column
    'index_type': 'int64'                       # Index data type
}
```

### GraphMatrix Data Format
```python
{
    'data': [[1, 2], [3, 4]],    # 2D matrix data
    'shape': (rows, cols),       # Dimensions
    'dtype': 'f32'               # Element data type
}
```

### GraphArray Data Format
```python
{
    'data': [1, 2, 3, 4],    # 1D array data
    'dtype': 'f32',          # Element data type
    'shape': (length,),      # Dimensions
    'name': 'column_name'    # Optional column name
}
```

## Implementation Notes

- **Performance**: Display formatting is optimized for interactive use with reasonable defaults
- **Fallbacks**: All formatting includes graceful error handling with simple fallback representations
- **Terminal Support**: Automatically detects color support and adjusts formatting accordingly
- **Unicode Safety**: Uses standard Unicode box-drawing characters supported by modern terminals
- **Memory Efficient**: Smart truncation prevents memory issues with large datasets

## Running the Demo

```bash
cd python-groggy/python
python groggy/display/demo.py
```

This will show example outputs for all three data structure types with various sizes and content types.


--- FILE: groggy/display/truncation.py ---
"""
Smart truncation algorithms for large datasets.
"""

from typing import List, Tuple, Any, Optional
from .unicode_chars import Symbols

def truncate_rows(data: List[Any], max_rows: int) -> Tuple[List[Any], bool]:
    """
    Truncate rows with smart first/last display.
    
    Returns (truncated_data, was_truncated)
    """
    if len(data) <= max_rows:
        return data, False
    
    if max_rows < 3:
        # Too few rows to show meaningful truncation
        return data[:max_rows], True
    
    # Show first half and last half with ellipsis in middle
    show_first = max_rows // 2
    show_last = max_rows - show_first - 1  # -1 for ellipsis row
    
    truncated = (
        data[:show_first] + 
        [create_ellipsis_row(data[0] if data else [])] +
        data[-show_last:] if show_last > 0 else []
    )
    
    return truncated, True

def truncate_columns(headers: List[str], data: List[List[Any]], max_cols: int) -> Tuple[List[str], List[List[Any]], bool]:
    """
    Truncate columns with smart first/last display.
    
    Returns (truncated_headers, truncated_data, was_truncated)
    """
    if len(headers) <= max_cols:
        return headers, data, False
    
    if max_cols < 3:
        # Too few columns to show meaningful truncation
        return headers[:max_cols], [row[:max_cols] for row in data], True
    
    # Show first half and last half with ellipsis in middle
    show_first = max_cols // 2
    show_last = max_cols - show_first - 1  # -1 for ellipsis column
    
    # Truncate headers
    truncated_headers = (
        headers[:show_first] + 
        [Symbols.ELLIPSIS] +
        (headers[-show_last:] if show_last > 0 else [])
    )
    
    # Truncate data rows
    truncated_data = []
    for row in data:
        truncated_row = (
            row[:show_first] + 
            [Symbols.TRUNCATION_INDICATOR] +
            (row[-show_last:] if show_last > 0 else [])
        )
        truncated_data.append(truncated_row)
    
    return truncated_headers, truncated_data, True

def create_ellipsis_row(sample_row: Any) -> Any:
    """Create an ellipsis row that matches the structure of a data row."""
    # Handle 1D arrays where sample_row is a scalar value
    if not hasattr(sample_row, '__len__') or isinstance(sample_row, str):
        return Symbols.ELLIPSIS
    
    # Handle 2D arrays where sample_row is a list/array
    return [Symbols.ELLIPSIS] * len(sample_row) if sample_row else [Symbols.ELLIPSIS]

def truncate_string(text: str, max_width: int, ellipsis: str = Symbols.ELLIPSIS) -> str:
    """Truncate a string to max_width with ellipsis if needed."""
    if len(text) <= max_width:
        return text
    
    if max_width < len(ellipsis):
        return text[:max_width]
    
    return text[:max_width - len(ellipsis)] + ellipsis

def calculate_column_widths(headers: List[str], data: List[List[Any]], max_total_width: int) -> List[int]:
    """
    Calculate optimal column widths that fit within max_total_width.
    
    Uses a fair distribution algorithm that prioritizes readability.
    """
    if not headers:
        return []
    
    num_cols = len(headers)
    if num_cols == 0:
        return []
    
    # Calculate minimum widths needed for each column
    min_widths = []
    for i, header in enumerate(headers):
        col_values = [str(row[i]) if i < len(row) else '' for row in data]
        col_values.append(header)  # Include header in width calculation
        
        min_width = max(len(str(val)) for val in col_values) if col_values else 0
        min_widths.append(max(min_width, 4))  # Minimum 4 chars per column for better readability
    
    # Account for borders and separators: | col1 | col2 | col3 |
    # Each column needs 2 extra chars for " |", plus 1 for initial "|"
    border_width = sum(min_widths) + (num_cols * 3) + 1
    
    if border_width <= max_total_width:
        # All columns fit comfortably
        return min_widths
    
    # Need to truncate - distribute available width fairly
    available_width = max_total_width - (num_cols * 3) - 1  # Account for borders
    if available_width < num_cols * 3:  # Not enough space even for minimum
        return [3] * num_cols
    
    # Distribute width proportionally but ensure minimums
    total_min = sum(min_widths)
    scale_factor = available_width / total_min
    
    scaled_widths = []
    for min_width in min_widths:
        scaled_width = max(3, int(min_width * scale_factor))
        scaled_widths.append(scaled_width)
    
    # Adjust if we went over/under
    total_scaled = sum(scaled_widths)
    if total_scaled != available_width:
        diff = available_width - total_scaled
        # Distribute the difference across columns
        for i in range(abs(diff)):
            col_idx = i % num_cols
            if diff > 0:
                scaled_widths[col_idx] += 1
            elif scaled_widths[col_idx] > 3:  # Don't go below minimum
                scaled_widths[col_idx] -= 1
    
    return scaled_widths

def smart_matrix_truncation(matrix_data: List[List[Any]], max_rows: int, max_cols: int) -> Tuple[List[List[Any]], bool, bool]:
    """
    Smart truncation for matrices showing corners and edges.
    
    Returns (truncated_matrix, rows_truncated, cols_truncated)
    """
    rows_truncated = False
    cols_truncated = False
    
    # First truncate rows
    if len(matrix_data) > max_rows:
        rows_truncated = True
        if max_rows < 3:
            matrix_data = matrix_data[:max_rows]
        else:
            show_first_rows = max_rows // 2
            show_last_rows = max_rows - show_first_rows - 1
            
            ellipsis_row = [Symbols.TRUNCATION_INDICATOR] * len(matrix_data[0]) if matrix_data else []
            matrix_data = (
                matrix_data[:show_first_rows] + 
                [ellipsis_row] +
                (matrix_data[-show_last_rows:] if show_last_rows > 0 else [])
            )
    
    # Then truncate columns
    if matrix_data and len(matrix_data[0]) > max_cols:
        cols_truncated = True
        if max_cols < 3:
            matrix_data = [row[:max_cols] for row in matrix_data]
        else:
            show_first_cols = max_cols // 2
            show_last_cols = max_cols - show_first_cols - 1
            
            truncated_matrix = []
            for row in matrix_data:
                truncated_row = (
                    row[:show_first_cols] + 
                    [Symbols.TRUNCATION_INDICATOR] +
                    (row[-show_last_cols:] if show_last_cols > 0 else [])
                )
                truncated_matrix.append(truncated_row)
            matrix_data = truncated_matrix
    
    return matrix_data, rows_truncated, cols_truncated


--- FILE: groggy/display/matrix_display.py ---
"""
Rich display formatter for GraphMatrix structures.
"""

from typing import List, Dict, Any, Optional, Tuple
from .unicode_chars import BoxChars, Symbols, Colors, colorize
from .truncation import smart_matrix_truncation, truncate_string

class MatrixDisplayFormatter:
    """Formatter for GraphMatrix rich display with shape and dtype information."""
    
    def __init__(self, max_rows: int = 10, max_cols: int = 8, max_width: int = 120, precision: int = 2):
        self.max_rows = max_rows
        self.max_cols = max_cols
        self.max_width = max_width
        self.precision = precision
    
    def format(self, matrix_data: Dict[str, Any]) -> str:
        """
        Format a GraphMatrix for rich display.
        
        Expected matrix_data structure:
        {
            'data': [
                [0.12, -1.50, 2.00, 0.00],
                [3.14, 0.00, float('nan'), 1.25],
                [-0.01, 4.50, -2.30, 8.00]
            ],
            'shape': (3, 4),
            'dtype': 'f32',
            'column_names': ['col1', 'col2', 'col3', 'col4']  # Optional
        }
        """
        data = matrix_data.get('data', [])
        shape = matrix_data.get('shape', (0, 0))
        dtype = matrix_data.get('dtype', 'object')
        column_names = matrix_data.get('column_names', None)
        
        if not data or shape[0] == 0 or shape[1] == 0:
            return self._format_empty_matrix(shape, dtype)
        
        # Smart truncation for large matrices
        truncated_data, rows_truncated, cols_truncated = smart_matrix_truncation(
            data, self.max_rows, self.max_cols
        )
        
        # Calculate column widths based on content
        col_widths = self._calculate_matrix_column_widths(truncated_data)
        
        # Build the formatted matrix
        lines = []
        
        # Header with section indicator
        lines.append(f"{Symbols.HEADER_PREFIX} gr.matrix")
        
        # Top border
        lines.append(self._build_border_line(col_widths, 'top'))
        
        # Data rows
        for row in truncated_data:
            lines.append(self._build_matrix_row(row, col_widths))
        
        # Bottom border
        lines.append(self._build_border_line(col_widths, 'bottom'))
        
        # Shape and dtype information
        shape_info = f"shape: {shape} • dtype: {dtype}"
        lines.append(shape_info)
        
        return '\n'.join(lines)
    
    def _format_empty_matrix(self, shape: Tuple[int, int], dtype: str) -> str:
        """Format an empty matrix."""
        return f"{Symbols.HEADER_PREFIX} gr.matrix (empty) • shape: {shape} • dtype: {dtype}"
    
    def _format_matrix_value(self, value: Any) -> str:
        """Format a single matrix value for display."""
        if value is None:
            return Symbols.NULL_DISPLAY
        elif isinstance(value, float):
            if str(value).lower() in ['nan', 'inf', '-inf']:
                return Symbols.NULL_DISPLAY
            else:
                return f"{value:.{self.precision}f}"
        elif value == Symbols.TRUNCATION_INDICATOR:
            return Symbols.TRUNCATION_INDICATOR
        else:
            return str(value)
    
    def _calculate_matrix_column_widths(self, data: List[List[Any]]) -> List[int]:
        """Calculate optimal column widths for matrix display."""
        if not data or not data[0]:
            return []
        
        num_cols = len(data[0])
        col_widths = []
        
        for col_idx in range(num_cols):
            # Get all values in this column
            col_values = [self._format_matrix_value(row[col_idx]) for row in data if col_idx < len(row)]
            
            # Calculate max width needed
            max_width = max(len(str(val)) for val in col_values) if col_values else 6
            
            # Ensure minimum width and maximum reasonable width
            width = max(6, min(max_width, 12))
            col_widths.append(width)
        
        return col_widths
    
    def _build_border_line(self, col_widths: List[int], position: str) -> str:
        """Build a border line for matrix display."""
        if position == 'top':
            left = BoxChars.TOP_LEFT
            right = BoxChars.TOP_RIGHT
            sep = BoxChars.T_TOP
        else:  # bottom
            left = BoxChars.BOTTOM_LEFT
            right = BoxChars.BOTTOM_RIGHT
            sep = BoxChars.T_BOTTOM
        
        segments = []
        for width in col_widths:
            segment = BoxChars.HORIZONTAL * (width + 2)  # +2 for padding
            segments.append(segment)
        
        return left + sep.join(segments) + right
    
    def _build_matrix_row(self, row_data: List[Any], col_widths: List[int]) -> str:
        """Build a matrix data row with proper alignment."""
        cells = []
        for value, width in zip(row_data, col_widths):
            formatted_value = self._format_matrix_value(value)
            
            # Right-align numeric values, center-align special symbols
            if formatted_value == Symbols.TRUNCATION_INDICATOR:
                padded = formatted_value.center(width)
            else:
                # Right-align for better number alignment
                padded = formatted_value.rjust(width)
            
            cells.append(f" {padded} ")
        
        return BoxChars.VERTICAL + BoxChars.VERTICAL.join(cells) + BoxChars.VERTICAL

def format_matrix(matrix_data: Dict[str, Any], **kwargs) -> str:
    """Convenience function to format a GraphMatrix."""
    formatter = MatrixDisplayFormatter(**kwargs)
    return formatter.format(matrix_data)


--- FILE: groggy/display/unicode_chars.py ---
"""
Unicode box-drawing characters and display symbols for rich formatting.
"""

# Box drawing characters for table borders
class BoxChars:
    """Unicode box-drawing characters for professional table display."""
    
    # Corners
    TOP_LEFT = '╭'
    TOP_RIGHT = '╮'
    BOTTOM_LEFT = '╰'
    BOTTOM_RIGHT = '╯'
    
    # Lines
    HORIZONTAL = '─'
    VERTICAL = '│'
    
    # Intersections
    CROSS = '┼'
    T_TOP = '┬'
    T_BOTTOM = '┴'
    T_LEFT = '├'
    T_RIGHT = '┤'
    
    # Double lines for emphasis
    HORIZONTAL_DOUBLE = '═'
    VERTICAL_DOUBLE = '║'

# Display symbols  
class Symbols:
    """Special symbols for data display."""
    
    ELLIPSIS = '…'          # For truncated content
    DOT_SEPARATOR = '•'     # For summary statistics  
    NULL_DISPLAY = 'NaN'    # For null/missing values
    TRUNCATION_INDICATOR = '⋯'  # For matrix truncation
    HEADER_PREFIX = '⊖⊖'    # For section headers

# Color codes (if terminal supports color)
class Colors:
    """ANSI color codes for enhanced display."""
    
    RESET = '\033[0m'
    BOLD = '\033[1m'
    DIM = '\033[2m'
    
    # Text colors
    RED = '\033[31m'
    GREEN = '\033[32m'
    YELLOW = '\033[33m'
    BLUE = '\033[34m'
    MAGENTA = '\033[35m'
    CYAN = '\033[36m'
    WHITE = '\033[37m'
    GRAY = '\033[90m'
    
    # Background colors
    BG_RED = '\033[41m'
    BG_GREEN = '\033[42m'
    BG_YELLOW = '\033[43m'
    BG_BLUE = '\033[44m'

def has_color_support():
    """Check if the current terminal supports color output."""
    import os
    import sys
    
    # Check for common indicators of color support
    if os.getenv('NO_COLOR'):
        return False
    if os.getenv('FORCE_COLOR'):
        return True
    if not hasattr(sys.stdout, 'isatty') or not sys.stdout.isatty():
        return False
    
    term = os.getenv('TERM', '').lower()
    return any(color_term in term for color_term in ['color', 'xterm', 'screen', 'tmux'])

def colorize(text, color=None, bold=False, dim=False):
    """Apply color formatting to text if color is supported."""
    if not has_color_support():
        return text
    
    result = ''
    if bold:
        result += Colors.BOLD
    if dim:
        result += Colors.DIM
    if color:
        result += color
    
    result += text
    if result != text:  # Only add reset if we added formatting
        result += Colors.RESET
        
    return result


--- FILE: groggy/display/table_display.py ---
"""
Rich display formatter for GraphTable structures.
"""

from typing import List, Dict, Any, Optional, Tuple
from .unicode_chars import BoxChars, Symbols, Colors, colorize
from .truncation import truncate_rows, truncate_columns, calculate_column_widths, truncate_string

class TableDisplayFormatter:
    """Formatter for GraphTable rich display with Polars-style formatting."""
    
    def __init__(self, max_rows: int = 10, max_cols: int = 8, max_width: int = 120, precision: int = 2):
        self.max_rows = max_rows
        self.max_cols = max_cols
        self.max_width = max_width
        self.precision = precision
    
    def format(self, table_data: Dict[str, Any]) -> str:
        """
        Format a GraphTable for rich display.
        
        Expected table_data structure:
        {
            'columns': ['name', 'city', 'age', 'score', 'joined'],
            'dtypes': {'name': 'str', 'city': 'category', 'age': 'int', 'score': 'float', 'joined': 'date'},
            'data': [
                ['Alice', 'NYC', 25, 91.5, '2024-02-15'],
                ['Bob', 'Paris', 30, 87.0, '2023-11-20'],
                ...
            ],
            'shape': (1000, 5),
            'nulls': {'score': 12},
            'index_type': 'int64'
        }
        """
        columns = table_data.get('columns', [])
        dtypes = table_data.get('dtypes', {})
        data = table_data.get('data', [])
        shape = table_data.get('shape', (0, 0))
        nulls = table_data.get('nulls', {})
        index_type = table_data.get('index_type', 'int64')
        
        if not columns or not data:
            return self._format_empty_table()
        
        # Add index column
        headers = ['#'] + columns
        type_headers = [''] + [self._format_dtype(dtypes.get(col, 'object')) for col in columns]
        
        # Add row indices to data
        indexed_data = []
        for i, row in enumerate(data):
            indexed_row = [str(i)] + [self._format_value(val, dtypes.get(columns[j], 'object')) for j, val in enumerate(row)]
            indexed_data.append(indexed_row)
        
        # Truncate if necessary
        truncated_data, rows_truncated = truncate_rows(indexed_data, self.max_rows)
        truncated_headers, truncated_data, cols_truncated = truncate_columns(
            headers, truncated_data, self.max_cols
        )
        truncated_type_headers = type_headers[:len(truncated_headers)]
        
        # Calculate column widths
        col_widths = calculate_column_widths(truncated_headers, truncated_data, self.max_width)
        
        # Build the formatted table
        lines = []
        
        # Header with section indicator
        lines.append(f"{Symbols.HEADER_PREFIX} gr.table")
        
        # Top border
        lines.append(self._build_border_line(col_widths, 'top'))
        
        # Column headers
        lines.append(self._build_data_line(truncated_headers, col_widths, bold=True))
        lines.append(self._build_data_line(truncated_type_headers, col_widths, dim=True))
        
        # Header separator
        lines.append(self._build_border_line(col_widths, 'middle'))
        
        # Data rows
        for row in truncated_data:
            lines.append(self._build_data_line(row, col_widths))
        
        # Bottom border
        lines.append(self._build_border_line(col_widths, 'bottom'))
        
        # Summary statistics
        summary_parts = [
            f"rows: {shape[0]:,}",
            f"cols: {shape[1]}",
        ]
        
        if nulls:
            null_info = ', '.join(f"{col}={count}" for col, count in nulls.items())
            summary_parts.append(f"nulls: {null_info}")
        
        summary_parts.append(f"index: {index_type}")
        summary = f" {Symbols.DOT_SEPARATOR} ".join(summary_parts)
        lines.append(summary)
        
        return '\n'.join(lines)
    
    def _format_empty_table(self) -> str:
        """Format an empty table."""
        return f"{Symbols.HEADER_PREFIX} gr.table (empty)"
    
    def _format_dtype(self, dtype: str) -> str:
        """Format data type for display."""
        dtype_map = {
            'string': 'str',
            'category': 'cat',
            'int64': 'i64',
            'int32': 'i32', 
            'float64': 'f64',
            'float32': 'f32',
            'bool': 'bool',
            'datetime': 'date',
            'object': 'obj'
        }
        
        base_type = dtype_map.get(dtype, dtype)
        
        # Add size hints for string/category types
        if dtype in ['string', 'str']:
            return f"{base_type}[8]"  # Could be dynamic based on max length
        elif dtype in ['category', 'cat']:
            return f"{base_type}(12)"  # Could be dynamic based on category count
        else:
            return base_type
    
    def _format_value(self, value: Any, dtype: str) -> str:
        """Format a single value for display."""
        if value is None or (isinstance(value, float) and str(value).lower() in ['nan', 'inf', '-inf']):
            return Symbols.NULL_DISPLAY
        
        if dtype in ['float64', 'float32', 'float'] and isinstance(value, (int, float)):
            return f"{float(value):.{self.precision}f}"
        elif dtype in ['datetime', 'date'] and isinstance(value, str):
            # Truncate dates for display
            return truncate_string(value, 10) + (Symbols.ELLIPSIS if len(value) > 10 else '')
        elif isinstance(value, str):
            # Truncate long strings
            return truncate_string(value, 12)
        else:
            return str(value)
    
    def _build_border_line(self, col_widths: List[int], position: str) -> str:
        """Build a border line (top, middle, bottom)."""
        if position == 'top':
            left = BoxChars.TOP_LEFT
            right = BoxChars.TOP_RIGHT
            sep = BoxChars.T_TOP
        elif position == 'middle':
            left = BoxChars.T_LEFT
            right = BoxChars.T_RIGHT
            sep = BoxChars.CROSS
        else:  # bottom
            left = BoxChars.BOTTOM_LEFT
            right = BoxChars.BOTTOM_RIGHT
            sep = BoxChars.T_BOTTOM
        
        segments = []
        for i, width in enumerate(col_widths):
            segment = BoxChars.HORIZONTAL * (width + 2)  # +2 for padding
            segments.append(segment)
        
        return left + sep.join(segments) + right
    
    def _build_data_line(self, row_data: List[str], col_widths: List[int], bold: bool = False, dim: bool = False) -> str:
        """Build a data line with proper padding and alignment."""
        cells = []
        for i, (value, width) in enumerate(zip(row_data, col_widths)):
            # Truncate if value is too long
            display_value = truncate_string(str(value), width)
            
            # Pad to column width (left-align for most, right-align for numbers in index)
            if i == 0:  # Index column - right align
                padded = display_value.rjust(width)
            else:  # Data columns - left align
                padded = display_value.ljust(width)
            
            # Apply formatting
            if bold:
                padded = colorize(padded, bold=True)
            elif dim:
                padded = colorize(padded, dim=True)
            
            cells.append(f" {padded} ")  # Add padding around content
        
        return BoxChars.VERTICAL + BoxChars.VERTICAL.join(cells) + BoxChars.VERTICAL

def format_table(table_data: Dict[str, Any], **kwargs) -> str:
    """Convenience function to format a GraphTable."""
    formatter = TableDisplayFormatter(**kwargs)
    return formatter.format(table_data)


--- FILE: groggy/display/demo.py ---
#!/usr/bin/env python3
"""
Demo script showing the rich display module in action.

Run this to see example outputs for GraphTable, GraphMatrix, and GraphArray.
"""

import sys
import os

# Add the python package to path so we can import groggy.display
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from groggy.display import format_table, format_matrix, format_array

def demo_table_display():
    """Demo GraphTable rich display."""
    print("=" * 60)
    print("GraphTable Display Demo")
    print("=" * 60)
    
    table_data = {
        'columns': ['name', 'city', 'age', 'score', 'joined'],
        'dtypes': {
            'name': 'string', 
            'city': 'category', 
            'age': 'int64', 
            'score': 'float32', 
            'joined': 'datetime'
        },
        'data': [
            ['Alice', 'NYC', 25, 91.5, '2024-02-15'],
            ['Bob', 'Paris', 30, 87.0, '2023-11-20'],
            ['Charlie', 'Tokyo', 35, None, '2024-06-10'],
            ['Diana', 'London', 28, 95.2, '2022-08-05'],
            ['Eve', 'Berlin', 32, 88.7, '2023-03-12'],
            ['Frank', 'Sydney', 29, 92.1, '2024-01-18'],
            ['Grace', 'Toronto', 31, 89.3, '2022-12-03'],
            ['Henry', 'Dubai', 27, 94.8, '2024-05-22'],
            ['Iris', 'Singapore', 33, 86.4, '2023-09-14'],
            ['Jack', 'Mumbai', 26, 93.7, '2024-03-08'],
            ['Kate', 'São Paulo', 34, 90.1, '2022-11-27'],
            ['Liam', 'Amsterdam', 30, 91.9, '2023-07-16'],
        ],
        'shape': (1000, 5),  # Simulating larger dataset
        'nulls': {'score': 12},
        'index_type': 'int64'
    }
    
    formatted = format_table(table_data)
    print(formatted)
    print()

def demo_matrix_display():
    """Demo GraphMatrix rich display."""
    print("=" * 60)
    print("GraphMatrix Display Demo")
    print("=" * 60)
    
    # Small matrix
    small_matrix_data = {
        'data': [
            [0.12, -1.50, 2.00, 0.00],
            [3.14, 0.00, float('nan'), 1.25],
            [-0.01, 4.50, -2.30, 8.00]
        ],
        'shape': (3, 4),
        'dtype': 'f32'
    }
    
    formatted_small = format_matrix(small_matrix_data)
    print(formatted_small)
    print()
    
    # Large matrix (will be truncated)
    large_data = []
    for i in range(500):
        row = []
        for j in range(200):
            if i == 0 and j in [0, 1, 2, 197, 198, 199]:
                # First row, specific values for demo
                values = {0: 0.12, 1: -1.50, 2: 2.00, 197: 7.77, 198: 8.88, 199: 9.99}
                row.append(values[j])
            elif i == 1 and j in [0, 1, 2, 197, 198, 199]:
                # Second row, specific values
                values = {0: 3.14, 1: 0.00, 2: float('nan'), 197: -2.10, 198: 1.25, 199: 2.35}
                row.append(values[j])
            elif i == 499 and j in [0, 1, 2, 197, 198, 199]:
                # Last row, specific values
                values = {0: -0.01, 1: 4.50, 2: -2.30, 197: 9.99, 198: 8.00, 199: 7.11}
                row.append(values[j])
            else:
                # Random-ish values
                row.append((i * 200 + j) % 100 / 10.0)
        large_data.append(row)
    
    large_matrix_data = {
        'data': large_data,
        'shape': (500, 200),
        'dtype': 'f32'
    }
    
    formatted_large = format_matrix(large_matrix_data)
    print(formatted_large)
    print()

def demo_array_display():
    """Demo GraphArray rich display."""
    print("=" * 60)
    print("GraphArray Display Demo")
    print("=" * 60)
    
    array_data = {
        'data': [0.125, 3.1416, float('nan'), -2.75, 8.0, 34],
        'dtype': 'f32',
        'shape': (6,),
        'name': 'col1'
    }
    
    formatted = format_array(array_data)
    print(formatted)
    print()

def main():
    """Run all display demos."""
    print("Groggy Rich Display Module Demo")
    print("===============================")
    print()
    
    demo_table_display()
    demo_matrix_display() 
    demo_array_display()
    
    print("Demo completed! 🎉")

if __name__ == '__main__':
    main()


--- FILE: groggy/display/array_display.py ---
"""
Rich display formatter for GraphArray structures.
"""

from typing import List, Dict, Any, Optional
from .unicode_chars import BoxChars, Symbols, Colors, colorize
from .truncation import truncate_rows, truncate_string

class ArrayDisplayFormatter:
    """Formatter for GraphArray rich display with column-style layout."""
    
    def __init__(self, max_rows: int = 10, max_width: int = 60, precision: int = 4):
        self.max_rows = max_rows
        self.max_width = max_width
        self.precision = precision
    
    def format(self, array_data: Dict[str, Any]) -> str:
        """
        Format a GraphArray for rich display.
        
        Expected array_data structure:
        {
            'data': [0.125, 3.1416, float('nan'), -2.75, 8.0, 34],
            'dtype': 'f32',
            'shape': (6,),
            'name': 'col1'  # Optional column name
        }
        """
        data = array_data.get('data', [])
        dtype = array_data.get('dtype', 'object')
        shape = array_data.get('shape', (0,))
        name = array_data.get('name', 'col1')
        
        if not data:
            return self._format_empty_array(shape, dtype, name)
        
        # Truncate data if too long
        truncated_data, was_truncated = truncate_rows(data, self.max_rows)
        
        # Calculate column widths
        index_width = len(str(len(data) - 1)) if data else 1
        index_width = max(index_width, 1)  # Minimum width
        
        # Format all values to determine value column width
        formatted_values = [self._format_array_value(val) for val in truncated_data]
        value_width = max(len(val) for val in formatted_values) if formatted_values else 6
        value_width = max(value_width, len(name))  # At least as wide as column name
        value_width = min(value_width, 20)  # Maximum reasonable width
        
        # Build the formatted array
        lines = []
        
        # Header with section indicator
        lines.append(f"{Symbols.HEADER_PREFIX} gr.array")
        lines.append("")  # Empty line for spacing
        
        # Top border
        lines.append(self._build_border_line(index_width, value_width, 'top'))
        
        # Column headers
        lines.append(self._build_header_line(index_width, value_width, name, dtype))
        
        # Header separator
        lines.append(self._build_border_line(index_width, value_width, 'middle'))
        
        # Data rows
        for i, value in enumerate(truncated_data):
            if isinstance(value, list) and len(value) == 1 and value[0] == Symbols.ELLIPSIS:
                # This is an ellipsis row
                lines.append(self._build_ellipsis_line(index_width, value_width))
            else:
                # Regular data row
                original_index = i if not was_truncated or i < self.max_rows // 2 else len(data) - (len(truncated_data) - i)
                lines.append(self._build_data_line(original_index, value, index_width, value_width))
        
        # Bottom border
        lines.append(self._build_border_line(index_width, value_width, 'bottom'))
        
        # Shape information
        shape_info = f"shape: {shape}"
        lines.append(shape_info)
        
        return '\n'.join(lines)
    
    def _format_empty_array(self, shape: tuple, dtype: str, name: str) -> str:
        """Format an empty array."""
        return f"{Symbols.HEADER_PREFIX} gr.array (empty) • shape: {shape} • dtype: {dtype}"
    
    def _format_array_value(self, value: Any) -> str:
        """Format a single array value for display."""
        if value is None:
            return Symbols.NULL_DISPLAY
        elif isinstance(value, float):
            if str(value).lower() in ['nan', 'inf', '-inf']:
                return Symbols.NULL_DISPLAY
            else:
                return f"{value:.{self.precision}g}"  # Use 'g' format for smart precision
        elif isinstance(value, int):
            return str(value)
        elif isinstance(value, str):
            return truncate_string(value, 15)
        elif value == Symbols.ELLIPSIS:
            return Symbols.ELLIPSIS
        else:
            return str(value)
    
    def _build_border_line(self, index_width: int, value_width: int, position: str) -> str:
        """Build a border line for array display."""
        if position == 'top':
            left = BoxChars.TOP_LEFT
            right = BoxChars.TOP_RIGHT
            sep = BoxChars.T_TOP
        elif position == 'middle':
            left = BoxChars.T_LEFT
            right = BoxChars.T_RIGHT
            sep = BoxChars.CROSS
        else:  # bottom
            left = BoxChars.BOTTOM_LEFT
            right = BoxChars.BOTTOM_RIGHT
            sep = BoxChars.T_BOTTOM
        
        index_segment = BoxChars.HORIZONTAL * (index_width + 2)
        value_segment = BoxChars.HORIZONTAL * (value_width + 2)
        
        return left + index_segment + sep + value_segment + right
    
    def _build_header_line(self, index_width: int, value_width: int, name: str, dtype: str) -> str:
        """Build the header line with column name and type."""
        # Index header
        index_header = "#".center(index_width)
        
        # Value header with name and type
        value_header = truncate_string(name, value_width)
        type_header = dtype
        
        # Build the line
        index_cell = f" {index_header} "
        value_cell = f" {value_header.ljust(value_width)} "
        
        line1 = BoxChars.VERTICAL + index_cell + BoxChars.VERTICAL + value_cell + BoxChars.VERTICAL
        
        # Second line with type info
        empty_index = " " * (index_width + 2)
        type_cell = f" {type_header.ljust(value_width)} "
        line2 = BoxChars.VERTICAL + empty_index + BoxChars.VERTICAL + type_cell + BoxChars.VERTICAL
        
        return line1 + '\n' + line2
    
    def _build_data_line(self, index: int, value: Any, index_width: int, value_width: int) -> str:
        """Build a data line with index and value."""
        formatted_index = str(index).rjust(index_width)
        formatted_value = self._format_array_value(value)
        
        # Right-align numbers, left-align strings
        if isinstance(value, (int, float)) and value is not None and str(value).lower() not in ['nan', 'inf', '-inf']:
            padded_value = formatted_value.rjust(value_width)
        else:
            padded_value = formatted_value.ljust(value_width)
        
        index_cell = f" {formatted_index} "
        value_cell = f" {padded_value} "
        
        return BoxChars.VERTICAL + index_cell + BoxChars.VERTICAL + value_cell + BoxChars.VERTICAL
    
    def _build_ellipsis_line(self, index_width: int, value_width: int) -> str:
        """Build an ellipsis line for truncated arrays."""
        ellipsis_index = Symbols.ELLIPSIS.center(index_width)
        ellipsis_value = Symbols.ELLIPSIS.center(value_width)
        
        index_cell = f" {ellipsis_index} "
        value_cell = f" {ellipsis_value} "
        
        return BoxChars.VERTICAL + index_cell + BoxChars.VERTICAL + value_cell + BoxChars.VERTICAL

def format_array(array_data: Dict[str, Any], **kwargs) -> str:
    """Convenience function to format a GraphArray."""
    formatter = ArrayDisplayFormatter(**kwargs)
    return formatter.format(array_data)


