{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd7746dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLI Tutorial - Graph Operations Demo\n",
      "Available backends: ['python', 'rust']\n",
      "Current backend: rust\n"
     ]
    }
   ],
   "source": [
    "# Import the GLI library\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the path to import gli\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), 'python'))\n",
    "\n",
    "import gli\n",
    "from gli import Graph, get_available_backends, set_backend, get_current_backend, create_random_graph\n",
    "import time\n",
    "import random\n",
    "\n",
    "print(\"GLI Tutorial - Graph Operations Demo\")\n",
    "print(f\"Available backends: {get_available_backends()}\")\n",
    "print(f\"Current backend: {get_current_backend()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a85e3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Created graph: 30000 employees\n",
      "âœ… Added management relationships: 1500 edges\n",
      "\n",
      "ğŸ’¾ Committing initial state...\n",
      "âœ… Initial state: 683eaad4aa340052\n",
      "\n",
      "ğŸ” Initial State Filtering:\n",
      "ğŸ“Š Managers: 50\n",
      "ğŸ“Š Engineering employees: 10000\n",
      "ğŸ“Š Remote workers: 7500\n",
      "ğŸ“Š High earners (â‰¥$90k): 120\n",
      "\n",
      "ğŸ”„ Making significant changes...\n",
      "âœ… Changes applied:\n",
      "   ğŸ“ˆ Promotions: 30\n",
      "   ğŸ’° Salary increases: 1575\n",
      "   ğŸ  New remote workers: 43\n",
      "\n",
      "ğŸ’¾ Committing modified state...\n",
      "âœ… Modified state: ca554ab1d40bc329\n",
      "\n",
      "ğŸ” Modified State Filtering:\n",
      "ğŸ“Š Managers: 50\n",
      "ğŸ“Š Seniors: 130\n",
      "ğŸ“Š Engineering employees: 10000\n",
      "ğŸ“Š Remote workers: 7532\n",
      "ğŸ“Š High earners (â‰¥$90k): 229\n",
      "\n",
      "ğŸ“ˆ Comparison:\n",
      "   ğŸ‘” Managers: 50 â†’ 50 (+0)\n",
      "   ğŸ“ Seniors: ? â†’ 130 (after promotions)\n",
      "   ğŸ”§ Engineers: 10000 â†’ 10000 (+0)\n",
      "   ğŸ  Remote workers: 7500 â†’ 7532 (+32)\n",
      "   ğŸ’° High earners: 120 â†’ 229 (+109)\n",
      "\n",
      "ğŸ‘‘ Sample promoted employees:\n",
      "   â€¢ Employee_8841: Senior in Engineering ($67,911)\n",
      "   â€¢ Employee_2024: Senior in Marketing ($84,471)\n",
      "   â€¢ Employee_14648: Senior in Marketing ($99,905)\n",
      "   â€¢ Employee_25575: Senior in Engineering ($60,244)\n",
      "   â€¢ Employee_17420: Senior in Marketing ($70,409)\n",
      "\n",
      "ğŸ“Š Final storage stats: {'edge_refs_tracked': 1500, 'pooled_nodes': 31628, 'node_refs_tracked': 31628, 'branches': 1, 'pooled_edges': 1500, 'total_states': 3}\n",
      "ğŸ“Š Remote workers: 7532\n",
      "ğŸ“Š High earners (â‰¥$90k): 229\n",
      "\n",
      "ğŸ“ˆ Comparison:\n",
      "   ğŸ‘” Managers: 50 â†’ 50 (+0)\n",
      "   ğŸ“ Seniors: ? â†’ 130 (after promotions)\n",
      "   ğŸ”§ Engineers: 10000 â†’ 10000 (+0)\n",
      "   ğŸ  Remote workers: 7500 â†’ 7532 (+32)\n",
      "   ğŸ’° High earners: 120 â†’ 229 (+109)\n",
      "\n",
      "ğŸ‘‘ Sample promoted employees:\n",
      "   â€¢ Employee_8841: Senior in Engineering ($67,911)\n",
      "   â€¢ Employee_2024: Senior in Marketing ($84,471)\n",
      "   â€¢ Employee_14648: Senior in Marketing ($99,905)\n",
      "   â€¢ Employee_25575: Senior in Engineering ($60,244)\n",
      "   â€¢ Employee_17420: Senior in Marketing ($70,409)\n",
      "\n",
      "ğŸ“Š Final storage stats: {'edge_refs_tracked': 1500, 'pooled_nodes': 31628, 'node_refs_tracked': 31628, 'branches': 1, 'pooled_edges': 1500, 'total_states': 3}\n"
     ]
    }
   ],
   "source": [
    "g = Graph()\n",
    "    \n",
    "# Create employees with predictable attributes for clear filtering\n",
    "departments = ['Engineering', 'Sales', 'Marketing']\n",
    "roles = ['Junior', 'Senior', 'Manager']\n",
    "\n",
    "employee_ids = []\n",
    "\n",
    "# Create 30000 employees with controlled attributes\n",
    "for i in range(30000):\n",
    "    # Create predictable patterns for clear filtering\n",
    "    dept = departments[i % 3]\n",
    "    \n",
    "    # Make some employees clearly senior\n",
    "    if i < 50:\n",
    "        role = 'Manager'\n",
    "        salary = random.randint(100000, 150000)\n",
    "        performance = random.uniform(4.0, 5.0)\n",
    "    elif i < 150:\n",
    "        role = 'Senior'\n",
    "        salary = random.randint(80000, 120000)\n",
    "        performance = random.uniform(3.5, 4.5)\n",
    "    else:\n",
    "        role = 'Junior'\n",
    "        salary = random.randint(50000, 80000)\n",
    "        performance = random.uniform(3.0, 4.0)\n",
    "    \n",
    "    employee_id = g.add_node(\n",
    "        name=f\"Employee_{i:03d}\",\n",
    "        department=dept,\n",
    "        role=role,\n",
    "        salary=salary,\n",
    "        performance_score=round(performance, 1),\n",
    "        employee_id=i,\n",
    "        is_remote=i % 4 == 0  # Every 4th person is remote\n",
    "    )\n",
    "    employee_ids.append(employee_id)\n",
    "\n",
    "print(f\"âœ… Created graph: {g.node_count()} employees\")\n",
    "\n",
    "# Add some management relationships\n",
    "for i in range(0, 500):  # First 500 are managers\n",
    "    manager = employee_ids[i]\n",
    "    # Each manager oversees 3-5 people\n",
    "    for j in range(3):\n",
    "        if i * 3 + j + 500 < len(employee_ids):\n",
    "            report = employee_ids[i * 3 + j + 500]\n",
    "            g.add_edge(manager, report, relationship='manages')\n",
    "\n",
    "print(f\"âœ… Added management relationships: {g.edge_count()} edges\")\n",
    "\n",
    "# Commit initial state\n",
    "print(\"\\nğŸ’¾ Committing initial state...\")\n",
    "initial_hash = g.commit(\"Initial company structure\")\n",
    "print(f\"âœ… Initial state: {initial_hash}\")\n",
    "\n",
    "# Initial filtering\n",
    "print(\"\\nğŸ” Initial State Filtering:\")\n",
    "\n",
    "if g.use_rust:\n",
    "    # Filter managers\n",
    "    managers = g.filter_nodes_by_attributes({'role': 'Manager'})\n",
    "    print(f\"ğŸ“Š Managers: {len(managers)}\")\n",
    "    \n",
    "    # Filter engineering department\n",
    "    engineers = g.filter_nodes_by_attributes({'department': 'Engineering'})\n",
    "    print(f\"ğŸ“Š Engineering employees: {len(engineers)}\")\n",
    "    \n",
    "    # Filter remote workers\n",
    "    remote_workers = g.filter_nodes_by_attributes({'is_remote': True})\n",
    "    print(f\"ğŸ“Š Remote workers: {len(remote_workers)}\")\n",
    "    \n",
    "    # Filter high earners (>= 90k)\n",
    "    high_earners = []\n",
    "    for node_id in employee_ids:\n",
    "        node = g.get_node(node_id)\n",
    "        if node and node.attributes.get('salary', 0) >= 90000:\n",
    "            high_earners.append(node_id)\n",
    "    print(f\"ğŸ“Š High earners (â‰¥$90k): {len(high_earners)}\")\n",
    "\n",
    "# Make significant changes\n",
    "print(\"\\nğŸ”„ Making significant changes...\")\n",
    "\n",
    "changes_made = {\n",
    "    'promotions': 0,\n",
    "    'salary_bumps': 0,\n",
    "    'new_remote': 0\n",
    "}\n",
    "\n",
    "# Promote some juniors to seniors\n",
    "juniors = g.filter_nodes_by_attributes({'role': 'Junior'})\n",
    "for i, node_id in enumerate(juniors[:30]):  # Promote first 30 juniors\n",
    "    g.set_node_attribute(node_id, 'role', 'Senior')\n",
    "    # Give them a salary bump\n",
    "    current_node = g.get_node(node_id)\n",
    "    if current_node:\n",
    "        new_salary = int(current_node.attributes.get('salary', 50000) * 1.2)\n",
    "        g.set_node_attribute(node_id, 'salary', new_salary)\n",
    "    changes_made['promotions'] += 1\n",
    "\n",
    "# Give raises to top performers\n",
    "for node_id in employee_ids:\n",
    "    node = g.get_node(node_id)\n",
    "    if node and node.attributes.get('performance_score', 0) >= 4.0:\n",
    "        current_salary = node.attributes.get('salary', 50000)\n",
    "        new_salary = int(current_salary * 1.15)\n",
    "        g.set_node_attribute(node_id, 'salary', new_salary)\n",
    "        changes_made['salary_bumps'] += 1\n",
    "\n",
    "# Make some employees remote\n",
    "for i in range(0, 300, 7):  # Every 7th employee becomes remote\n",
    "    if i < len(employee_ids):\n",
    "        g.set_node_attribute(employee_ids[i], 'is_remote', True)\n",
    "        changes_made['new_remote'] += 1\n",
    "\n",
    "print(f\"âœ… Changes applied:\")\n",
    "print(f\"   ğŸ“ˆ Promotions: {changes_made['promotions']}\")\n",
    "print(f\"   ğŸ’° Salary increases: {changes_made['salary_bumps']}\")\n",
    "print(f\"   ğŸ  New remote workers: {changes_made['new_remote']}\")\n",
    "\n",
    "# Commit modified state\n",
    "print(\"\\nğŸ’¾ Committing modified state...\")\n",
    "modified_hash = g.commit(\"Annual review - promotions and raises\")\n",
    "print(f\"âœ… Modified state: {modified_hash}\")\n",
    "\n",
    "# Modified state filtering\n",
    "print(\"\\nğŸ” Modified State Filtering:\")\n",
    "\n",
    "if g.use_rust:\n",
    "    # Same filters on modified state\n",
    "    managers_mod = g.filter_nodes_by_attributes({'role': 'Manager'})\n",
    "    print(f\"ğŸ“Š Managers: {len(managers_mod)}\")\n",
    "    \n",
    "    seniors_mod = g.filter_nodes_by_attributes({'role': 'Senior'})\n",
    "    print(f\"ğŸ“Š Seniors: {len(seniors_mod)}\")\n",
    "    \n",
    "    engineers_mod = g.filter_nodes_by_attributes({'department': 'Engineering'})\n",
    "    print(f\"ğŸ“Š Engineering employees: {len(engineers_mod)}\")\n",
    "    \n",
    "    remote_workers_mod = g.filter_nodes_by_attributes({'is_remote': True})\n",
    "    print(f\"ğŸ“Š Remote workers: {len(remote_workers_mod)}\")\n",
    "    \n",
    "    # Count high earners again\n",
    "    high_earners_mod = []\n",
    "    for node_id in employee_ids:\n",
    "        node = g.get_node(node_id)\n",
    "        if node and node.attributes.get('salary', 0) >= 90000:\n",
    "            high_earners_mod.append(node_id)\n",
    "    print(f\"ğŸ“Š High earners (â‰¥$90k): {len(high_earners_mod)}\")\n",
    "    \n",
    "    # Show changes\n",
    "    print(f\"\\nğŸ“ˆ Comparison:\")\n",
    "    print(f\"   ğŸ‘” Managers: {len(managers)} â†’ {len(managers_mod)} ({len(managers_mod) - len(managers):+d})\")\n",
    "    print(f\"   ğŸ“ Seniors: ? â†’ {len(seniors_mod)} (after promotions)\")\n",
    "    print(f\"   ğŸ”§ Engineers: {len(engineers)} â†’ {len(engineers_mod)} ({len(engineers_mod) - len(engineers):+d})\")\n",
    "    print(f\"   ğŸ  Remote workers: {len(remote_workers)} â†’ {len(remote_workers_mod)} ({len(remote_workers_mod) - len(remote_workers):+d})\")\n",
    "    print(f\"   ğŸ’° High earners: {len(high_earners)} â†’ {len(high_earners_mod)} ({len(high_earners_mod) - len(high_earners):+d})\")\n",
    "    \n",
    "    # Show some specific examples\n",
    "    print(f\"\\nğŸ‘‘ Sample promoted employees:\")\n",
    "    promoted_seniors = g.filter_nodes({'role': 'Senior'})\n",
    "    for i, node_id in enumerate(promoted_seniors[:5]):\n",
    "        node = g.get_node(node_id)\n",
    "        if node:\n",
    "            print(f\"   â€¢ {node.attributes.get('name')}: {node.attributes.get('role')} in {node.attributes.get('department')} (${node.attributes.get('salary', 0):,})\")\n",
    "    \n",
    "    # Storage stats\n",
    "    stats = g.get_storage_stats()\n",
    "    print(f\"\\nğŸ“Š Final storage stats: {stats}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5876c5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('node_8cdf6625',\n",
       "  Node(id='node_8cdf6625', attributes={'role': 'Senior', 'name': 'Employee_8841', 'employee_id': 8841, 'is_remote': False, 'department': 'Engineering', 'performance_score': 3.8, 'salary': 67911})),\n",
       " ('node_09783a10',\n",
       "  Node(id='node_09783a10', attributes={'performance_score': 3.5, 'employee_id': 2024, 'name': 'Employee_2024', 'salary': 84471, 'is_remote': True, 'department': 'Marketing', 'role': 'Senior'})),\n",
       " ('node_2cddfc2b',\n",
       "  Node(id='node_2cddfc2b', attributes={'department': 'Marketing', 'salary': 99905, 'name': 'Employee_14648', 'is_remote': True, 'performance_score': 4.0, 'role': 'Senior', 'employee_id': 14648})),\n",
       " ('node_96010caa',\n",
       "  Node(id='node_96010caa', attributes={'department': 'Engineering', 'salary': 60244, 'is_remote': False, 'performance_score': 3.1, 'role': 'Senior', 'name': 'Employee_25575', 'employee_id': 25575})),\n",
       " ('node_3d49635f',\n",
       "  Node(id='node_3d49635f', attributes={'is_remote': True, 'salary': 70409, 'performance_score': 4.0, 'role': 'Senior', 'department': 'Marketing', 'employee_id': 17420, 'name': 'Employee_17420'}))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.nodes.items()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea4338d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marketing employees: 10000\n",
      "Senior Engineers: 42\n",
      "\n",
      "ğŸ¢ Sample Marketing employees:\n",
      "   â€¢ Employee_2024: Senior ($84,471)\n",
      "   â€¢ Employee_14648: Senior ($99,905)\n",
      "   â€¢ Employee_17420: Senior ($70,409)\n"
     ]
    }
   ],
   "source": [
    "# Test lambda filtering - correct signature is (node_id, attributes)\n",
    "marketing_employees = g.filter_nodes(lambda node_id, attrs: attrs.get('department') == 'Marketing')\n",
    "print(f\"Marketing employees: {len(marketing_employees)}\")\n",
    "\n",
    "# Test with multiple conditions\n",
    "senior_engineers = g.filter_nodes(lambda node_id, attrs: \n",
    "                                  attrs.get('role') == 'Senior' and attrs.get('department') == 'Engineering')\n",
    "print(f\"Senior Engineers: {len(senior_engineers)}\")\n",
    "\n",
    "# Show some examples\n",
    "print(f\"\\nğŸ¢ Sample Marketing employees:\")\n",
    "for i, emp_id in enumerate(marketing_employees[:3]):\n",
    "    node = g.get_node(emp_id)\n",
    "    if node:\n",
    "        print(f\"   â€¢ {node.attributes.get('name')}: {node.attributes.get('role')} (${node.attributes.get('salary', 0):,})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82a82a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Attribute-based filtering:\n",
      "   ğŸ“Š Engineering dept: 10000\n",
      "   ğŸ  Remote workers: 7532\n",
      "\n",
      "ğŸ” Lambda-based filtering:\n",
      "   ğŸ’° High earners (â‰¥$90k): 229\n",
      "   ğŸ‘” Senior remote workers: 39\n",
      "   â­ High-performing juniors: 16416\n",
      "\n",
      "ğŸ“ˆ Performance comparison:\n",
      "   Traditional dict filter vs lambda: 10000 == 10000\n",
      "   âœ… Both methods work consistently!\n",
      "   â­ High-performing juniors: 16416\n",
      "\n",
      "ğŸ“ˆ Performance comparison:\n",
      "   Traditional dict filter vs lambda: 10000 == 10000\n",
      "   âœ… Both methods work consistently!\n"
     ]
    }
   ],
   "source": [
    "# Test both attribute-based and lambda-based filtering\n",
    "\n",
    "print(\"ğŸ” Attribute-based filtering:\")\n",
    "# Using dictionary filters (old style still works)\n",
    "engineering_dept = g.filter_nodes({'department': 'Engineering'})\n",
    "remote_workers = g.filter_nodes({'is_remote': True})\n",
    "print(f\"   ğŸ“Š Engineering dept: {len(engineering_dept)}\")\n",
    "print(f\"   ğŸ  Remote workers: {len(remote_workers)}\")\n",
    "\n",
    "print(\"\\nğŸ” Lambda-based filtering:\")\n",
    "# Using lambda functions for more complex conditions\n",
    "high_earners = g.filter_nodes(lambda node_id, attrs: attrs.get('salary', 0) >= 90000)\n",
    "senior_remote = g.filter_nodes(lambda node_id, attrs: \n",
    "                              attrs.get('role') == 'Senior' and attrs.get('is_remote') == True)\n",
    "print(f\"   ğŸ’° High earners (â‰¥$90k): {len(high_earners)}\")\n",
    "print(f\"   ğŸ‘” Senior remote workers: {len(senior_remote)}\")\n",
    "\n",
    "# Complex condition combining multiple attributes\n",
    "high_performing_juniors = g.filter_nodes(lambda node_id, attrs: \n",
    "                                        attrs.get('role') == 'Junior' and \n",
    "                                        attrs.get('performance_score', 0) >= 3.5)\n",
    "print(f\"   â­ High-performing juniors: {len(high_performing_juniors)}\")\n",
    "\n",
    "print(\"\\nğŸ“ˆ Performance comparison:\")\n",
    "print(f\"   Traditional dict filter vs lambda: {len(engineering_dept)} == {len(g.filter_nodes(lambda nid, a: a.get('department') == 'Engineering'))}\")\n",
    "print(\"   âœ… Both methods work consistently!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01f36faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š Basic state operations:\n",
      "   Current hash: ca554ab1d40bc329\n",
      "   Available saved states:\n",
      "      â€¢ initial_hash = 683eaad4aa340052\n",
      "      â€¢ modified_hash = ca554ab1d40bc329\n",
      "\n",
      "ğŸ” Current state stats:\n",
      "   ğŸ‘” Senior employees: 130\n",
      "   ğŸ  Remote workers: 7532\n",
      "\n",
      "ğŸ”§ Available state methods:\n",
      "   â€¢ auto_states\n",
      "   â€¢ branch_heads\n",
      "   â€¢ branches\n",
      "   â€¢ create_branch\n",
      "   â€¢ current_branch\n",
      "   â€¢ get_state_info\n",
      "   â€¢ load_state\n",
      "   â€¢ max_auto_states\n",
      "   â€¢ save_state\n",
      "   â€¢ states\n",
      "\n",
      "ğŸ’¾ Storage stats:\n",
      "   branches: 1\n",
      "   edge_refs_tracked: 1500\n",
      "   total_states: 3\n",
      "   node_refs_tracked: 31628\n",
      "   pooled_nodes: 31628\n",
      "   pooled_edges: 1500\n"
     ]
    }
   ],
   "source": [
    "# ğŸ•°ï¸ Working with Previous States of the Graph\n",
    "\n",
    "print(\"ğŸ“š Basic state operations:\")\n",
    "print(f\"   Current hash: {getattr(g, 'current_hash', 'None')}\")\n",
    "print(f\"   Available saved states:\")\n",
    "print(f\"      â€¢ initial_hash = {initial_hash}\")\n",
    "print(f\"      â€¢ modified_hash = {modified_hash}\")\n",
    "\n",
    "print(f\"\\nğŸ” Current state stats:\")\n",
    "current_seniors = g.filter_nodes({'role': 'Senior'})\n",
    "current_remote = g.filter_nodes({'is_remote': True})\n",
    "print(f\"   ğŸ‘” Senior employees: {len(current_seniors)}\")\n",
    "print(f\"   ğŸ  Remote workers: {len(current_remote)}\")\n",
    "\n",
    "# Let's check what state management methods are available\n",
    "print(f\"\\nğŸ”§ Available state methods:\")\n",
    "state_methods = [method for method in dir(g) if 'state' in method.lower() or 'branch' in method.lower()]\n",
    "for method in state_methods:\n",
    "    if not method.startswith('_'):\n",
    "        print(f\"   â€¢ {method}\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ Storage stats:\")\n",
    "stats = g.get_storage_stats()\n",
    "for key, value in stats.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4662ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ•°ï¸ Time travel: Loading the initial state...\n",
      "âœ… Loaded initial state: 683eaad4aa340052\n",
      "\n",
      "ğŸ” After loading initial state:\n",
      "   ğŸ‘” Senior employees: 100\n",
      "   ğŸ  Remote workers: 7500\n",
      "   ğŸ’° High earners (â‰¥$90k): 120\n",
      "\n",
      "ğŸ“Š Comparison with modified state:\n",
      "   ğŸ‘” Seniors: 100 (initial) vs 130 (modified)\n",
      "   ğŸ  Remote: 7500 (initial) vs 7532 (modified)\n",
      "   ğŸ‘” Senior employees: 100\n",
      "   ğŸ  Remote workers: 7500\n",
      "   ğŸ’° High earners (â‰¥$90k): 120\n",
      "\n",
      "ğŸ“Š Comparison with modified state:\n",
      "   ğŸ‘” Seniors: 100 (initial) vs 130 (modified)\n",
      "   ğŸ  Remote: 7500 (initial) vs 7532 (modified)\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”„ Loading Previous States\n",
    "\n",
    "print(\"ğŸ•°ï¸ Time travel: Loading the initial state...\")\n",
    "\n",
    "# Method 1: Using load_state() if available\n",
    "try:\n",
    "    # Save current state hash for later\n",
    "    current_state = modified_hash\n",
    "    \n",
    "    # Load the initial state\n",
    "    if hasattr(g, 'load_state'):\n",
    "        g.load_state(initial_hash)\n",
    "        print(f\"âœ… Loaded initial state: {initial_hash}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ load_state method not available\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error loading state: {e}\")\n",
    "\n",
    "# Check the data after loading initial state\n",
    "print(f\"\\nğŸ” After loading initial state:\")\n",
    "initial_seniors = g.filter_nodes({'role': 'Senior'})\n",
    "initial_remote = g.filter_nodes({'is_remote': True}) \n",
    "initial_high_earners = g.filter_nodes(lambda nid, attrs: attrs.get('salary', 0) >= 90000)\n",
    "\n",
    "print(f\"   ğŸ‘” Senior employees: {len(initial_seniors)}\")\n",
    "print(f\"   ğŸ  Remote workers: {len(initial_remote)}\")\n",
    "print(f\"   ğŸ’° High earners (â‰¥$90k): {len(initial_high_earners)}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Comparison with modified state:\")\n",
    "print(f\"   ğŸ‘” Seniors: {len(initial_seniors)} (initial) vs {len(current_seniors)} (modified)\")\n",
    "print(f\"   ğŸ  Remote: {len(initial_remote)} (initial) vs {len(current_remote)} (modified)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "856d0190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Demonstrating complete state loading workflow:\n",
      "\n",
      "ğŸ“Š BEFORE loading initial state:\n",
      "   ğŸ‘” Senior employees: 100\n",
      "   ğŸ  Remote workers: 7500\n",
      "   ğŸ’° High earners (â‰¥$90k): 120\n",
      "\n",
      "âª Loading initial state 683eaad4aa34...\n",
      "âœ… Successfully loaded initial state!\n",
      "\n",
      "ğŸ“Š AFTER loading initial state:\n",
      "   ğŸ‘” Senior employees: 100\n",
      "   ğŸ  Remote workers: 7500\n",
      "   ğŸ’° High earners (â‰¥$90k): 120\n",
      "\n",
      "ğŸ“ˆ State comparison:\n",
      "   ğŸ‘” Seniors: 100 â†’ 100 (+0)\n",
      "   ğŸ  Remote: 7500 â†’ 7500 (+0)\n",
      "   ğŸ’° High earners: 120 â†’ 120 (+0)\n",
      "\n",
      "ğŸ’¾ Updated storage stats:\n",
      "   pooled_nodes: 31628\n",
      "   edge_refs_tracked: 1500\n",
      "   branches: 1\n",
      "   total_states: 3\n",
      "   node_refs_tracked: 31628\n",
      "   pooled_edges: 1500\n",
      "\n",
      "ğŸ“Š AFTER loading initial state:\n",
      "   ğŸ‘” Senior employees: 100\n",
      "   ğŸ  Remote workers: 7500\n",
      "   ğŸ’° High earners (â‰¥$90k): 120\n",
      "\n",
      "ğŸ“ˆ State comparison:\n",
      "   ğŸ‘” Seniors: 100 â†’ 100 (+0)\n",
      "   ğŸ  Remote: 7500 â†’ 7500 (+0)\n",
      "   ğŸ’° High earners: 120 â†’ 120 (+0)\n",
      "\n",
      "ğŸ’¾ Updated storage stats:\n",
      "   pooled_nodes: 31628\n",
      "   edge_refs_tracked: 1500\n",
      "   branches: 1\n",
      "   total_states: 3\n",
      "   node_refs_tracked: 31628\n",
      "   pooled_edges: 1500\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¯ Complete State Management Workflow\n",
    "\n",
    "print(\"ğŸ¯ Demonstrating complete state loading workflow:\")\n",
    "\n",
    "# Store current state info\n",
    "current_seniors = len(g.filter_nodes({'role': 'Senior'}))\n",
    "current_remote = len(g.filter_nodes({'is_remote': True}))\n",
    "current_high_earners = len(g.filter_nodes(lambda nid, attrs: attrs.get('salary', 0) >= 90000))\n",
    "\n",
    "print(f\"\\nğŸ“Š BEFORE loading initial state:\")\n",
    "print(f\"   ğŸ‘” Senior employees: {current_seniors}\")\n",
    "print(f\"   ğŸ  Remote workers: {current_remote}\")\n",
    "print(f\"   ğŸ’° High earners (â‰¥$90k): {current_high_earners}\")\n",
    "\n",
    "# Try to load the initial state\n",
    "print(f\"\\nâª Loading initial state {initial_hash[:12]}...\")\n",
    "try:\n",
    "    success = g.load_state(initial_hash)\n",
    "    if success:\n",
    "        print(f\"âœ… Successfully loaded initial state!\")\n",
    "        \n",
    "        # Check the data after loading\n",
    "        loaded_seniors = len(g.filter_nodes({'role': 'Senior'}))\n",
    "        loaded_remote = len(g.filter_nodes({'is_remote': True}))\n",
    "        loaded_high_earners = len(g.filter_nodes(lambda nid, attrs: attrs.get('salary', 0) >= 90000))\n",
    "        \n",
    "        print(f\"\\nğŸ“Š AFTER loading initial state:\")\n",
    "        print(f\"   ğŸ‘” Senior employees: {loaded_seniors}\")\n",
    "        print(f\"   ğŸ  Remote workers: {loaded_remote}\")\n",
    "        print(f\"   ğŸ’° High earners (â‰¥$90k): {loaded_high_earners}\")\n",
    "        \n",
    "        print(f\"\\nğŸ“ˆ State comparison:\")\n",
    "        print(f\"   ğŸ‘” Seniors: {current_seniors} â†’ {loaded_seniors} ({loaded_seniors - current_seniors:+d})\")\n",
    "        print(f\"   ğŸ  Remote: {current_remote} â†’ {loaded_remote} ({loaded_remote - current_remote:+d})\")\n",
    "        print(f\"   ğŸ’° High earners: {current_high_earners} â†’ {loaded_high_earners} ({loaded_high_earners - current_high_earners:+d})\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"âŒ Failed to load state\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {e}\")\n",
    "\n",
    "print(f\"\\nğŸ’¾ Updated storage stats:\")\n",
    "updated_stats = g.get_storage_stats()\n",
    "for key, value in updated_stats.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d581f62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e952a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Creating fresh graph to test lazy-loaded properties:\n",
      "\n",
      "ğŸ“š fresh_g.states (lazy-loaded):\n",
      "   total_states: 1\n",
      "   pooled_nodes: 0\n",
      "   pooled_edges: 0\n",
      "   node_refs_tracked: 0\n",
      "   edge_refs_tracked: 0\n",
      "   current_hash: initial\n",
      "   state_hashes: ['initial']\n",
      "   branches_count: 1\n",
      "\n",
      "ğŸŒ¿ fresh_g.branches (lazy-loaded):\n",
      "   main: initial\n",
      "\n",
      "ğŸ’¾ Committed: b58dbf422e7ee754\n",
      "\n",
      "ğŸ” Filtering test:\n",
      "   Marketing: 1 nodes\n",
      "   Seniors: 1 nodes\n",
      "\n",
      "ğŸ“Š Final state:\n",
      "   States: 2 total states\n",
      "   Branches: {'main': 'initial', 'experiment': 'b58dbf422e7ee754'}\n",
      "\n",
      "âœ… Key improvements:\n",
      "   â€¢ g.states: lazy-loaded dict (no method calls needed)\n",
      "   â€¢ g.branches: lazy-loaded dict (replaces list_branches())\n",
      "   â€¢ Always in sync with Rust backend\n",
      "   â€¢ Properties computed on demand\n",
      "   â€¢ filter_nodes() supports both lambdas and attribute dicts\n"
     ]
    }
   ],
   "source": [
    "# ğŸš€ Testing New Lazy-Loaded Properties (FIXED!)\n",
    "\n",
    "# Note: Restart kernel to get updated Graph class\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/michaelroth/Documents/Code/gli/python')\n",
    "import gli\n",
    "\n",
    "# Create a fresh graph to test the new properties\n",
    "print(\"ğŸš€ Creating fresh graph to test lazy-loaded properties:\")\n",
    "fresh_g = gli.Graph(backend='rust')\n",
    "\n",
    "print(f\"\\nğŸ“š fresh_g.states (lazy-loaded):\")\n",
    "states = fresh_g.states\n",
    "for key, value in states.items():\n",
    "    if key != 'auto_states':  # Skip the deque for cleaner output\n",
    "        print(f\"   {key}: {value}\")\n",
    "\n",
    "print(f\"\\nğŸŒ¿ fresh_g.branches (lazy-loaded):\")\n",
    "branches = fresh_g.branches\n",
    "for name, hash_val in branches.items():\n",
    "    print(f\"   {name}: {hash_val}\")\n",
    "\n",
    "# Add some data and test again\n",
    "fresh_g.add_node('test1', department='Engineering', role='Junior')\n",
    "fresh_g.add_node('test2', department='Marketing', role='Senior')\n",
    "fresh_g.add_edge('test1', 'test2', relationship='collaborates')\n",
    "\n",
    "# Commit and create branches\n",
    "commit1 = fresh_g.commit('Initial data')\n",
    "print(f\"\\nğŸ’¾ Committed: {commit1}\")\n",
    "\n",
    "# Test filtering with new graph\n",
    "marketing_folks = fresh_g.filter_nodes({'department': 'Marketing'})\n",
    "seniors = fresh_g.filter_nodes({'role': 'Senior'})\n",
    "print(f\"\\nğŸ” Filtering test:\")\n",
    "print(f\"   Marketing: {len(marketing_folks)} nodes\")\n",
    "print(f\"   Seniors: {len(seniors)} nodes\")\n",
    "\n",
    "# Create a branch\n",
    "fresh_g.create_branch('experiment', commit1)\n",
    "\n",
    "print(f\"\\nğŸ“Š Final state:\")\n",
    "print(f\"   States: {fresh_g.states['total_states']} total states\")\n",
    "print(f\"   Branches: {fresh_g.branches}\")\n",
    "\n",
    "print(f\"\\nâœ… Key improvements:\")\n",
    "print(f\"   â€¢ g.states: lazy-loaded dict (no method calls needed)\")\n",
    "print(f\"   â€¢ g.branches: lazy-loaded dict (replaces list_branches())\")\n",
    "print(f\"   â€¢ Always in sync with Rust backend\")\n",
    "print(f\"   â€¢ Properties computed on demand\")\n",
    "print(f\"   â€¢ filter_nodes() supports both lambdas and attribute dicts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a72f8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('node_66b4a24e',\n",
       "  Node(id='node_66b4a24e', attributes={'salary': 63258, 'name': 'Employee_18968', 'is_remote': True, 'employee_id': 18968, 'department': 'Marketing', 'performance_score': 3.2, 'role': 'Junior'})),\n",
       " ('node_e3447fd0',\n",
       "  Node(id='node_e3447fd0', attributes={'salary': 71218, 'performance_score': 3.5, 'is_remote': False, 'name': 'Employee_26633', 'department': 'Marketing', 'employee_id': 26633, 'role': 'Junior'})),\n",
       " ('node_2c9b3f4a',\n",
       "  Node(id='node_2c9b3f4a', attributes={'salary': 68941, 'name': 'Employee_24589', 'department': 'Sales', 'performance_score': 3.8, 'role': 'Junior', 'employee_id': 24589, 'is_remote': False})),\n",
       " ('node_7359686d',\n",
       "  Node(id='node_7359686d', attributes={'employee_id': 24550, 'department': 'Sales', 'role': 'Junior', 'name': 'Employee_24550', 'performance_score': 3.0, 'salary': 64820, 'is_remote': False})),\n",
       " ('node_c801e277',\n",
       "  Node(id='node_c801e277', attributes={'department': 'Marketing', 'employee_id': 22397, 'role': 'Junior', 'is_remote': False, 'name': 'Employee_22397', 'salary': 67563, 'performance_score': 3.6}))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.nodes.items()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11b661ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.load_state(g.states['state_hashes'][-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de3ec0e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('node_89ce275d',\n",
       "  Node(id='node_89ce275d', attributes={'salary': 66523, 'department': 'Sales', 'employee_id': 27055, 'performance_score': 3.8, 'name': 'Employee_27055', 'role': 'Junior', 'is_remote': False})),\n",
       " ('node_1cf06c4b',\n",
       "  Node(id='node_1cf06c4b', attributes={'is_remote': False, 'performance_score': 3.9, 'role': 'Junior', 'employee_id': 526, 'department': 'Sales', 'name': 'Employee_526', 'salary': 57658})),\n",
       " ('node_ad588d9a',\n",
       "  Node(id='node_ad588d9a', attributes={'name': 'Employee_10171', 'role': 'Junior', 'salary': 60237, 'is_remote': False, 'performance_score': 3.8, 'employee_id': 10171, 'department': 'Sales'})),\n",
       " ('node_782d8338',\n",
       "  Node(id='node_782d8338', attributes={'salary': 75940, 'role': 'Junior', 'performance_score': 3.1, 'name': 'Employee_11759', 'employee_id': 11759, 'is_remote': False, 'department': 'Marketing'})),\n",
       " ('node_cf19fa0d',\n",
       "  Node(id='node_cf19fa0d', attributes={'name': 'Employee_13553', 'employee_id': 13553, 'department': 'Marketing', 'salary': 66373, 'performance_score': 3.9, 'is_remote': False, 'role': 'Junior'}))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.nodes.items()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45d181db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d9390fc131145899'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.save_state(\"Final commit after testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5102d22f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_states': 4,\n",
       " 'pooled_nodes': 31628,\n",
       " 'pooled_edges': 1500,\n",
       " 'node_refs_tracked': 31628,\n",
       " 'edge_refs_tracked': 1500,\n",
       " 'current_hash': 'd9390fc131145899',\n",
       " 'state_hashes': ['d9390fc131145899', 'ca554ab1d40bc329', '683eaad4aa340052'],\n",
       " 'auto_states': ['683eaad4aa340052', 'ca554ab1d40bc329', 'd9390fc131145899'],\n",
       " 'branches_count': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4589c94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ NEW: save_state method (more intuitive than commit)\n",
      "âœ… Saved state: 78f31ad65ee86645\n",
      "âœ… Saved state: a9bd3c955550b890\n",
      "âœ… Legacy commit: de3214257e1de298\n",
      "\n",
      "ğŸ“Š Final state overview:\n",
      "   Total states: 4\n",
      "   State hashes: ['78f31ad65ee86645', 'a9bd3c955550b890', 'de3214257e1de298']\n",
      "   Branches: {'main': 'initial'}\n",
      "\n",
      "âª Testing state loading:\n",
      "Current nodes: 3\n",
      "After loading state1: 2 nodes\n",
      "After loading state2: 3 nodes\n",
      "\n",
      "ğŸ‰ GLI API Summary:\n",
      "   â€¢ g.save_state(message) - primary state saving\n",
      "   â€¢ g.commit(message) - backward compatibility\n",
      "   â€¢ g.load_state(hash) - time travel to any state\n",
      "   â€¢ g.states - comprehensive state info + hashes\n",
      "   â€¢ g.branches - branch dictionary\n",
      "   â€¢ g.filter_nodes/edges - dual interface (dict + lambda)\n",
      "   â€¢ All properties lazy-loaded from Rust backend!\n",
      "\n",
      "âœ… GLI refactoring complete: maintainable, performant, robust!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¯ Final GLI API: save_state vs commit\n",
    "\n",
    "print(\"ğŸ¯ NEW: save_state method (more intuitive than commit)\")\n",
    "\n",
    "# Create a fresh graph to demonstrate\n",
    "demo_g = gli.Graph(backend='rust')\n",
    "demo_g.add_node('alice', role='Engineer', team='Backend')\n",
    "demo_g.add_node('bob', role='Designer', team='Frontend')\n",
    "\n",
    "# Use the new save_state method\n",
    "state1 = demo_g.save_state(\"Initial team setup\")\n",
    "print(f\"âœ… Saved state: {state1}\")\n",
    "\n",
    "# Add more data\n",
    "demo_g.add_node('charlie', role='Manager', team='Backend')\n",
    "state2 = demo_g.save_state(\"Added management layer\")\n",
    "print(f\"âœ… Saved state: {state2}\")\n",
    "\n",
    "# Test backward compatibility\n",
    "demo_g.add_edge('alice', 'charlie', relationship='reports_to')\n",
    "state3 = demo_g.commit(\"Using legacy commit method\")  # Still works!\n",
    "print(f\"âœ… Legacy commit: {state3}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Final state overview:\")\n",
    "final_states = demo_g.states\n",
    "final_branches = demo_g.branches\n",
    "print(f\"   Total states: {final_states['total_states']}\")\n",
    "print(f\"   State hashes: {final_states['state_hashes']}\")\n",
    "print(f\"   Branches: {final_branches}\")\n",
    "\n",
    "# Test state loading\n",
    "print(f\"\\nâª Testing state loading:\")\n",
    "print(f\"Current nodes: {len(demo_g.nodes)}\")\n",
    "demo_g.load_state(state1)  # Go back to first state\n",
    "print(f\"After loading state1: {len(demo_g.nodes)} nodes\")\n",
    "demo_g.load_state(state2)  # Go to second state\n",
    "print(f\"After loading state2: {len(demo_g.nodes)} nodes\")\n",
    "\n",
    "print(f\"\\nğŸ‰ GLI API Summary:\")\n",
    "print(f\"   â€¢ g.save_state(message) - primary state saving\")\n",
    "print(f\"   â€¢ g.commit(message) - backward compatibility\")\n",
    "print(f\"   â€¢ g.load_state(hash) - time travel to any state\")\n",
    "print(f\"   â€¢ g.states - comprehensive state info + hashes\")\n",
    "print(f\"   â€¢ g.branches - branch dictionary\")\n",
    "print(f\"   â€¢ g.filter_nodes/edges - dual interface (dict + lambda)\")\n",
    "print(f\"   â€¢ All properties lazy-loaded from Rust backend!\")\n",
    "\n",
    "print(f\"\\nâœ… GLI refactoring complete: maintainable, performant, robust!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1934ae4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
