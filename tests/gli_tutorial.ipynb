{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8528ae8",
   "metadata": {},
   "source": [
    "# GLI (Graph Language Interface) Tutorial\n",
    "\n",
    "This notebook demonstrates how to use the GLI library for efficient graph operations with both Python and Rust backends.\n",
    "\n",
    "## Features Covered:\n",
    "- Basic graph creation and manipulation\n",
    "- Backend switching (Python vs Rust)\n",
    "- Complex attributes and metadata\n",
    "- Graph algorithms\n",
    "- Branching and versioning\n",
    "- Performance comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15343fd5",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation\n",
    "\n",
    "First, let's import the GLI library and check available backends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc54d8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLI Tutorial - Graph Operations Demo\n",
      "Available backends: ['python', 'rust']\n",
      "Current backend: rust\n"
     ]
    }
   ],
   "source": [
    "# Import the GLI library\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the path to import gli\n",
    "sys.path.insert(0, os.path.join(os.path.dirname(os.getcwd()), 'python'))\n",
    "\n",
    "import gli\n",
    "from gli import Graph, get_available_backends, set_backend, get_current_backend\n",
    "import time\n",
    "import random\n",
    "\n",
    "print(\"GLI Tutorial - Graph Operations Demo\")\n",
    "print(f\"Available backends: {get_available_backends()}\")\n",
    "print(f\"Current backend: {get_current_backend()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdac07f",
   "metadata": {},
   "source": [
    "## 2. Basic Graph Operations\n",
    "\n",
    "Let's start with basic graph creation and manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db7728ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created nodes: Alice=alice, Bob=bob, Charlie=charlie\n",
      "Total nodes: 3\n"
     ]
    }
   ],
   "source": [
    "# Create a new graph\n",
    "g = Graph()\n",
    "\n",
    "# Add some nodes with proper node_id parameter\n",
    "alice = g.add_node(\"alice\", label=\"Alice\", age=30, city=\"New York\")\n",
    "bob = g.add_node(\"bob\", label=\"Bob\", age=25, city=\"Boston\")\n",
    "charlie = g.add_node(\"charlie\", label=\"Charlie\", age=35, city=\"Chicago\")\n",
    "\n",
    "print(f\"Created nodes: Alice=alice, Bob=bob, Charlie=charlie\")\n",
    "print(f\"Total nodes: {len(g.nodes)}\")\n",
    "\n",
    "# Store the node IDs for later use\n",
    "alice_id = \"alice\"\n",
    "bob_id = \"bob\"\n",
    "charlie_id = \"charlie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c2071b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created edges: ['alice->bob', 'bob->charlie', 'alice->charlie']\n",
      "Total edges: 3\n",
      "\n",
      "Graph structure:\n",
      "  Charlie: connected to 2 nodes\n",
      "  Alice: connected to 2 nodes\n",
      "  Bob: connected to 2 nodes\n"
     ]
    }
   ],
   "source": [
    "# Add edges between nodes\n",
    "friendship1 = g.add_edge(alice, bob, label=\"friends\", since=2020, strength=0.8)\n",
    "friendship2 = g.add_edge(bob, charlie, label=\"friends\", since=2019, strength=0.9)\n",
    "coworkers = g.add_edge(alice, charlie, label=\"coworkers\", since=2021, strength=0.6)\n",
    "\n",
    "print(f\"Created edges: {[friendship1, friendship2, coworkers]}\")\n",
    "print(f\"Total edges: {len(g.edges)}\")\n",
    "\n",
    "# Display graph structure\n",
    "print(\"\\nGraph structure:\")\n",
    "for node_id in g.nodes:\n",
    "    node = g.get_node(node_id)\n",
    "    neighbors = g.get_neighbors(node_id)\n",
    "    print(f\"  {node.get('label', node_id)}: connected to {len(neighbors)} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bf0576",
   "metadata": {},
   "source": [
    "## 3. Working with Node and Edge Attributes\n",
    "\n",
    "GLI supports rich attributes on both nodes and edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8b7918a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alice's attributes: {'city': 'New York', 'label': 'Alice', 'age': 30}\n",
      "Alice's updated attributes: {'label': 'Alice', 'age': 30, 'occupation': 'Software Engineer', 'city': 'New York', 'skills': ['Python', 'Rust', 'Graph Theory']}\n",
      "\n",
      "Friendship edge attributes: {'label': 'friends', 'strength': 0.8, 'since': 2020}\n",
      "Updated friendship attributes: {'strength': 0.8, 'since': 2020, 'label': 'friends', 'interactions': {'common_interests': ['hiking', 'coding', 'movies'], 'last_meetup': '2024-12-15', 'messages_per_week': 25}}\n"
     ]
    }
   ],
   "source": [
    "# Access and modify node attributes\n",
    "alice_node = g.get_node(alice)\n",
    "print(f\"Alice's attributes: {dict(alice_node)}\")\n",
    "\n",
    "# Update attributes\n",
    "g.set_node_attribute(alice, \"occupation\", \"Software Engineer\")\n",
    "g.set_node_attribute(alice, \"skills\", [\"Python\", \"Rust\", \"Graph Theory\"])\n",
    "\n",
    "print(f\"Alice's updated attributes: {dict(g.get_node(alice))}\")\n",
    "\n",
    "# Work with edge attributes\n",
    "friendship_edge = g.get_edge(friendship1)\n",
    "print(f\"\\nFriendship edge attributes: {dict(friendship_edge)}\")\n",
    "\n",
    "# Add complex edge metadata\n",
    "g.set_edge_attribute(friendship1, \"interactions\", {\n",
    "    \"messages_per_week\": 25,\n",
    "    \"last_meetup\": \"2024-12-15\",\n",
    "    \"common_interests\": [\"hiking\", \"coding\", \"movies\"]\n",
    "})\n",
    "\n",
    "print(f\"Updated friendship attributes: {dict(g.get_edge(friendship1))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eaec9e",
   "metadata": {},
   "source": [
    "## 4. Backend Comparison\n",
    "\n",
    "Let's compare the performance of Python vs Rust backends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2921f0c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Benchmarking python Backend ===\n",
      "  Node creation: 0.004s (135134 nodes/sec)\n",
      "  Edge creation: 0.003s (371237 edges/sec)\n",
      "  Neighbor queries: 0.034s (avg 4.1 neighbors/node)\n",
      "  Final graph: 500 nodes, 995 edges\n",
      "\n",
      "=== Benchmarking rust Backend ===\n",
      "  Node creation: 0.003s (149572 nodes/sec)\n",
      "  Edge creation: 0.002s (421585 edges/sec)\n",
      "  Neighbor queries: 0.000s (avg 4.0 neighbors/node)\n",
      "  Final graph: 500 nodes, 998 edges\n",
      "\n",
      "=== Performance Comparison ===\n",
      "\n",
      "Node Time:\n",
      "  python: 0.004s\n",
      "  rust: 0.003s\n",
      "\n",
      "Edge Time:\n",
      "  python: 0.003s\n",
      "  rust: 0.002s\n",
      "\n",
      "Query Time:\n",
      "  python: 0.034s\n",
      "  rust: 0.000s\n"
     ]
    }
   ],
   "source": [
    "def benchmark_backend(backend_name, num_nodes=1000, num_edges=2000):\n",
    "    \"\"\"Benchmark basic operations on a specific backend.\"\"\"\n",
    "    print(f\"\\n=== Benchmarking {backend_name} Backend ===\")\n",
    "    \n",
    "    # Switch to the specified backend\n",
    "    set_backend(backend_name)\n",
    "    \n",
    "    # Create a new graph\n",
    "    g = Graph()\n",
    "    \n",
    "    # Benchmark node creation\n",
    "    start_time = time.time()\n",
    "    nodes = []\n",
    "    for i in range(num_nodes):\n",
    "        node_id = g.add_node(\n",
    "            label=f\"Node_{i}\",\n",
    "            value=random.randint(1, 100),\n",
    "            category=random.choice([\"A\", \"B\", \"C\"])\n",
    "        )\n",
    "        nodes.append(node_id)\n",
    "    \n",
    "    node_time = time.time() - start_time\n",
    "    print(f\"  Node creation: {node_time:.3f}s ({num_nodes/node_time:.0f} nodes/sec)\")\n",
    "    \n",
    "    # Benchmark edge creation\n",
    "    start_time = time.time()\n",
    "    edges = []\n",
    "    for i in range(num_edges):\n",
    "        source = random.choice(nodes)\n",
    "        target = random.choice(nodes)\n",
    "        if source != target:  # Avoid self-loops\n",
    "            edge_id = g.add_edge(\n",
    "                source, target,\n",
    "                weight=random.random(),\n",
    "                edge_type=random.choice([\"connects\", \"similar_to\", \"depends_on\"])\n",
    "            )\n",
    "            edges.append(edge_id)\n",
    "    \n",
    "    edge_time = time.time() - start_time\n",
    "    print(f\"  Edge creation: {edge_time:.3f}s ({len(edges)/edge_time:.0f} edges/sec)\")\n",
    "    \n",
    "    # Benchmark neighbor queries\n",
    "    start_time = time.time()\n",
    "    total_neighbors = 0\n",
    "    for node in random.sample(nodes, min(100, len(nodes))):\n",
    "        neighbors = g.get_neighbors(node)\n",
    "        total_neighbors += len(neighbors)\n",
    "    \n",
    "    query_time = time.time() - start_time\n",
    "    print(f\"  Neighbor queries: {query_time:.3f}s (avg {total_neighbors/100:.1f} neighbors/node)\")\n",
    "    \n",
    "    print(f\"  Final graph: {len(g.nodes)} nodes, {len(g.edges)} edges\")\n",
    "    \n",
    "    return {\n",
    "        'backend': backend_name,\n",
    "        'node_time': node_time,\n",
    "        'edge_time': edge_time,\n",
    "        'query_time': query_time,\n",
    "        'nodes': len(g.nodes),\n",
    "        'edges': len(g.edges)\n",
    "    }\n",
    "\n",
    "# Run benchmarks\n",
    "results = []\n",
    "for backend in get_available_backends():\n",
    "    try:\n",
    "        result = benchmark_backend(backend, num_nodes=500, num_edges=1000)\n",
    "        results.append(result)\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {backend} backend: {e}\")\n",
    "\n",
    "# Compare results\n",
    "if len(results) > 1:\n",
    "    print(\"\\n=== Performance Comparison ===\")\n",
    "    for metric in ['node_time', 'edge_time', 'query_time']:\n",
    "        print(f\"\\n{metric.replace('_', ' ').title()}:\")\n",
    "        for result in results:\n",
    "            print(f\"  {result['backend']}: {result[metric]:.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798e28b8",
   "metadata": {},
   "source": [
    "## 5. Graph Algorithms and Analysis\n",
    "\n",
    "Let's explore some graph algorithms and analysis capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76012815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Rust backend for algorithms\n",
      "Created social network with 8 people and 9 friendships\n",
      "\n",
      "Network Analysis:\n",
      "  Alice: 3 friends, age 47, from LA\n",
      "  Bob: 3 friends, age 46, from NYC\n",
      "  Charlie: 2 friends, age 38, from LA\n",
      "  Diana: 2 friends, age 20, from LA\n",
      "  Eve: 2 friends, age 33, from LA\n",
      "  Frank: 2 friends, age 32, from Chicago\n",
      "  Grace: 2 friends, age 21, from Chicago\n",
      "  Henry: 2 friends, age 60, from NYC\n"
     ]
    }
   ],
   "source": [
    "# Switch to the fastest available backend\n",
    "if 'rust' in get_available_backends():\n",
    "    set_backend('rust')\n",
    "    print(\"Using Rust backend for algorithms\")\n",
    "else:\n",
    "    set_backend('python')\n",
    "    print(\"Using Python backend for algorithms\")\n",
    "\n",
    "# Create a more complex graph for analysis\n",
    "g = Graph()\n",
    "\n",
    "# Create a social network scenario\n",
    "people = {}\n",
    "for name in ['Alice', 'Bob', 'Charlie', 'Diana', 'Eve', 'Frank', 'Grace', 'Henry']:\n",
    "    people[name] = g.add_node(\n",
    "        label=name,\n",
    "        age=random.randint(20, 60),\n",
    "        city=random.choice(['NYC', 'LA', 'Chicago', 'Boston']),\n",
    "        interests=random.sample(['sports', 'music', 'tech', 'art', 'travel'], 2)\n",
    "    )\n",
    "\n",
    "# Add friendship connections\n",
    "connections = [\n",
    "    ('Alice', 'Bob'), ('Alice', 'Charlie'), ('Bob', 'Diana'),\n",
    "    ('Charlie', 'Eve'), ('Diana', 'Frank'), ('Eve', 'Grace'),\n",
    "    ('Frank', 'Henry'), ('Grace', 'Alice'), ('Henry', 'Bob')\n",
    "]\n",
    "\n",
    "for person1, person2 in connections:\n",
    "    g.add_edge(\n",
    "        people[person1], people[person2],\n",
    "        relationship='friends',\n",
    "        strength=random.uniform(0.5, 1.0),\n",
    "        duration_years=random.randint(1, 10)\n",
    "    )\n",
    "\n",
    "print(f\"Created social network with {len(g.nodes)} people and {len(g.edges)} friendships\")\n",
    "\n",
    "# Analyze the network\n",
    "print(\"\\nNetwork Analysis:\")\n",
    "for name, node_id in people.items():\n",
    "    neighbors = g.get_neighbors(node_id)\n",
    "    node_data = g.get_node(node_id)\n",
    "    print(f\"  {name}: {len(neighbors)} friends, age {node_data['age']}, from {node_data['city']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1490f0",
   "metadata": {},
   "source": [
    "## 6. Advanced Features: Branching and Versioning\n",
    "\n",
    "GLI supports graph versioning and branching for complex workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "495bcb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base graph created with projects and dependencies\n",
      "Project A status: planning\n",
      "Project B status: active\n",
      "\n",
      "=== Scenario 1: Budget Increase ===\n",
      "Modified - Project A budget: 20000, status: approved\n",
      "Reverted - Project A budget: 10000, status: planning\n",
      "\n",
      "=== Scenario 2: Adding New Project ===\n",
      "\n",
      "Added Project C, now graph has 3 nodes and 2 edges\n",
      "\n",
      "Final project network:\n",
      "  Project A: planning, budget=$10000, connected to 1 projects\n",
      "  Project C: proposed, budget=$8000, connected to 1 projects\n",
      "  Project B: active, budget=$15000, connected to 2 projects\n"
     ]
    }
   ],
   "source": [
    "# Create a base graph\n",
    "g = Graph()\n",
    "\n",
    "# Add initial data\n",
    "project_a = g.add_node(label=\"Project A\", status=\"planning\", budget=10000)\n",
    "project_b = g.add_node(label=\"Project B\", status=\"active\", budget=15000)\n",
    "dependency = g.add_edge(project_a, project_b, relationship=\"depends_on\", priority=\"high\")\n",
    "\n",
    "print(\"Base graph created with projects and dependencies\")\n",
    "print(f\"Project A status: {g.get_node(project_a)['status']}\")\n",
    "print(f\"Project B status: {g.get_node(project_b)['status']}\")\n",
    "\n",
    "# Simulate branched development scenarios\n",
    "print(\"\\n=== Scenario 1: Budget Increase ===\") \n",
    "# In a real implementation, you might create a branch here\n",
    "# For now, we'll simulate by modifying and then reverting\n",
    "\n",
    "original_budget_a = g.get_node(project_a)['budget']\n",
    "g.set_node_attribute(project_a, \"budget\", 20000)\n",
    "g.set_node_attribute(project_a, \"status\", \"approved\")\n",
    "\n",
    "print(f\"Modified - Project A budget: {g.get_node(project_a)['budget']}, status: {g.get_node(project_a)['status']}\")\n",
    "\n",
    "# Revert changes\n",
    "g.set_node_attribute(project_a, \"budget\", original_budget_a)\n",
    "g.set_node_attribute(project_a, \"status\", \"planning\")\n",
    "\n",
    "print(f\"Reverted - Project A budget: {g.get_node(project_a)['budget']}, status: {g.get_node(project_a)['status']}\")\n",
    "\n",
    "print(\"\\n=== Scenario 2: Adding New Project ===\\n\")\n",
    "project_c = g.add_node(label=\"Project C\", status=\"proposed\", budget=8000)\n",
    "new_dependency = g.add_edge(project_b, project_c, relationship=\"enables\", priority=\"medium\")\n",
    "\n",
    "print(f\"Added Project C, now graph has {len(g.nodes)} nodes and {len(g.edges)} edges\")\n",
    "\n",
    "# Show final state\n",
    "print(\"\\nFinal project network:\")\n",
    "for node_id in g.nodes:\n",
    "    node = g.get_node(node_id)\n",
    "    neighbors = g.get_neighbors(node_id)\n",
    "    print(f\"  {node['label']}: {node['status']}, budget=${node['budget']}, connected to {len(neighbors)} projects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fcf7d0",
   "metadata": {},
   "source": [
    "## 7. Real-World Use Case: Knowledge Graph\n",
    "\n",
    "Let's build a small knowledge graph to demonstrate practical usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4712fdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knowledge graph created with 8 entities and 7 relationships\n",
      "\n",
      "=== Knowledge Graph Queries ===\n",
      "Languages for web development:\n",
      "  JavaScript: 0.95 strength\n",
      "  Python: 0.9 strength\n",
      "\n",
      "Rust applications and capabilities:\n",
      "  provides Memory Safety: 1.0 strength\n",
      "  used_for Systems Programming: 0.9 strength\n",
      "  supports Concurrency: 0.9 strength\n"
     ]
    }
   ],
   "source": [
    "# Create a knowledge graph about programming languages and concepts\n",
    "kg = Graph()\n",
    "\n",
    "# Add programming language nodes\n",
    "languages = {\n",
    "    'Python': kg.add_node(label=\"Python\", type=\"language\", year=1991, paradigm=\"multi-paradigm\", performance=\"medium\"),\n",
    "    'Rust': kg.add_node(label=\"Rust\", type=\"language\", year=2010, paradigm=\"systems\", performance=\"high\"),\n",
    "    'JavaScript': kg.add_node(label=\"JavaScript\", type=\"language\", year=1995, paradigm=\"multi-paradigm\", performance=\"medium\"),\n",
    "    'C++': kg.add_node(label=\"C++\", type=\"language\", year=1985, paradigm=\"multi-paradigm\", performance=\"high\")\n",
    "}\n",
    "\n",
    "# Add concept nodes\n",
    "concepts = {\n",
    "    'Memory Safety': kg.add_node(label=\"Memory Safety\", type=\"concept\", importance=\"critical\"),\n",
    "    'Concurrency': kg.add_node(label=\"Concurrency\", type=\"concept\", importance=\"high\"),\n",
    "    'Web Development': kg.add_node(label=\"Web Development\", type=\"domain\", popularity=\"very high\"),\n",
    "    'Systems Programming': kg.add_node(label=\"Systems Programming\", type=\"domain\", complexity=\"high\")\n",
    "}\n",
    "\n",
    "# Add relationships\n",
    "relationships = [\n",
    "    (languages['Python'], concepts['Web Development'], 'used_for', {'strength': 0.9}),\n",
    "    (languages['JavaScript'], concepts['Web Development'], 'used_for', {'strength': 0.95}),\n",
    "    (languages['Rust'], concepts['Memory Safety'], 'provides', {'strength': 1.0}),\n",
    "    (languages['Rust'], concepts['Systems Programming'], 'used_for', {'strength': 0.9}),\n",
    "    (languages['C++'], concepts['Systems Programming'], 'used_for', {'strength': 0.8}),\n",
    "    (languages['Rust'], concepts['Concurrency'], 'supports', {'strength': 0.9}),\n",
    "    (languages['Python'], concepts['Concurrency'], 'supports', {'strength': 0.7})\n",
    "]\n",
    "\n",
    "for source, target, relation_type, attrs in relationships:\n",
    "    kg.add_edge(source, target, relationship=relation_type, **attrs)\n",
    "\n",
    "print(f\"Knowledge graph created with {len(kg.nodes)} entities and {len(kg.edges)} relationships\")\n",
    "\n",
    "# Query the knowledge graph\n",
    "print(\"\\n=== Knowledge Graph Queries ===\")\n",
    "\n",
    "# Find languages used for web development\n",
    "web_dev_id = concepts['Web Development']\n",
    "web_languages = []\n",
    "for edge_id in kg.edges:\n",
    "    edge = kg.get_edge(edge_id)\n",
    "    if edge.target == web_dev_id and edge.get('relationship') == 'used_for':\n",
    "        lang_node = kg.get_node(edge.source)\n",
    "        web_languages.append((lang_node['label'], edge.get('strength', 0)))\n",
    "\n",
    "print(\"Languages for web development:\")\n",
    "for lang, strength in sorted(web_languages, key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {lang}: {strength} strength\")\n",
    "\n",
    "# Find what Rust is used for\n",
    "rust_id = languages['Rust']\n",
    "rust_applications = []\n",
    "for edge_id in kg.edges:\n",
    "    edge = kg.get_edge(edge_id)\n",
    "    if edge.source == rust_id:\n",
    "        target_node = kg.get_node(edge.target)\n",
    "        rust_applications.append((target_node['label'], edge.get('relationship'), edge.get('strength', 0)))\n",
    "\n",
    "print(\"\\nRust applications and capabilities:\")\n",
    "for app, relation, strength in rust_applications:\n",
    "    print(f\"  {relation} {app}: {strength} strength\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1699e81a",
   "metadata": {},
   "source": [
    "## 8. Performance Tips and Best Practices\n",
    "\n",
    "Here are some recommendations for optimal GLI usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecc656d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GLI Performance Tips and Best Practices ===\n",
      "\n",
      "1. Backend Selection:\n",
      "   - Use Rust backend for large graphs (>10K nodes) and performance-critical applications\n",
      "   - Use Python backend for small graphs and rapid prototyping\n",
      "   - Current backend: rust\n",
      "   - Available backends: ['python', 'rust']\n",
      "\n",
      "2. Memory Efficiency:\n",
      "   - Batch operations when possible (add multiple nodes/edges at once)\n",
      "   - Use appropriate data types for attributes (avoid storing large objects)\n",
      "   - Consider attribute indexing for frequently queried properties\n",
      "\n",
      "3. Query Optimization:\n",
      "   - Cache frequently accessed node/edge data\n",
      "   - Use neighbor queries efficiently (get_neighbors is optimized)\n",
      "   - Consider graph structure when designing queries\n",
      "\n",
      "4. Error Handling:\n",
      "   - Always handle potential errors: KeyError\n",
      "\n",
      "5. Attribute Management:\n",
      "   - Structured access: Example\n",
      "   - Updated node: {'metadata': {'created': '2025-01-01'}, 'version': 2, 'updated': '2025-01-02', 'label': 'Example'}\n",
      "\n",
      "6. Graph Size Recommendations:\n",
      "   - Small graphs (<1K nodes): Either backend works well\n",
      "   - Medium graphs (1K-100K nodes): Rust backend recommended\n",
      "   - Large graphs (>100K nodes): Rust backend required for good performance\n",
      "   - Consider distributed solutions for graphs >1M nodes\n",
      "\n",
      "Tutorial completed! You now know how to use GLI effectively for graph operations.\n"
     ]
    }
   ],
   "source": [
    "print(\"=== GLI Performance Tips and Best Practices ===\")\n",
    "print()\n",
    "\n",
    "print(\"1. Backend Selection:\")\n",
    "print(\"   - Use Rust backend for large graphs (>10K nodes) and performance-critical applications\")\n",
    "print(\"   - Use Python backend for small graphs and rapid prototyping\")\n",
    "print(f\"   - Current backend: {get_current_backend()}\")\n",
    "print(f\"   - Available backends: {get_available_backends()}\")\n",
    "print()\n",
    "\n",
    "print(\"2. Memory Efficiency:\")\n",
    "print(\"   - Batch operations when possible (add multiple nodes/edges at once)\")\n",
    "print(\"   - Use appropriate data types for attributes (avoid storing large objects)\")\n",
    "print(\"   - Consider attribute indexing for frequently queried properties\")\n",
    "print()\n",
    "\n",
    "print(\"3. Query Optimization:\")\n",
    "print(\"   - Cache frequently accessed node/edge data\")\n",
    "print(\"   - Use neighbor queries efficiently (get_neighbors is optimized)\")\n",
    "print(\"   - Consider graph structure when designing queries\")\n",
    "print()\n",
    "\n",
    "print(\"4. Error Handling:\")\n",
    "try:\n",
    "    # Demonstrate error handling\n",
    "    g = Graph()\n",
    "    non_existent_node = g.get_node(\"invalid_id\")\n",
    "except Exception as e:\n",
    "    print(f\"   - Always handle potential errors: {type(e).__name__}\")\n",
    "print()\n",
    "\n",
    "print(\"5. Attribute Management:\")\n",
    "g = Graph()\n",
    "node_id = g.add_node(label=\"Example\", metadata={\"created\": \"2025-01-01\"})\n",
    "\n",
    "# Good: structured attribute access\n",
    "node = g.get_node(node_id)\n",
    "print(f\"   - Structured access: {node.get('label', 'Unknown')}\")\n",
    "\n",
    "# Good: batch attribute updates\n",
    "g.set_node_attribute(node_id, \"updated\", \"2025-01-02\")\n",
    "g.set_node_attribute(node_id, \"version\", 2)\n",
    "print(f\"   - Updated node: {dict(g.get_node(node_id))}\")\n",
    "print()\n",
    "\n",
    "print(\"6. Graph Size Recommendations:\")\n",
    "print(\"   - Small graphs (<1K nodes): Either backend works well\")\n",
    "print(\"   - Medium graphs (1K-100K nodes): Rust backend recommended\")\n",
    "print(\"   - Large graphs (>100K nodes): Rust backend required for good performance\")\n",
    "print(\"   - Consider distributed solutions for graphs >1M nodes\")\n",
    "print()\n",
    "\n",
    "print(\"Tutorial completed! You now know how to use GLI effectively for graph operations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b5b3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a657164",
   "metadata": {},
   "source": [
    "## 8. Advanced Graph Operations\n",
    "\n",
    "Now let's explore some advanced functionality including subgraphs, connected components, and graph analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63474da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Research network created: 6 researchers, 6 collaborations\n",
      "\n",
      "Research Network:\n",
      "  Dr. Smith (AI, 15 yrs): collaborates with ['Dr. Brown', 'Dr. Jones']\n",
      "  Dr. Jones (ML, 8 yrs): collaborates with ['Dr. Wilson', 'Dr. Smith']\n",
      "  Dr. Brown (NLP, 12 yrs): collaborates with ['Dr. Davis', 'Dr. Smith']\n",
      "  Dr. Wilson (CV, 6 yrs): collaborates with ['Dr. Taylor', 'Dr. Jones']\n",
      "  Dr. Davis (AI, 20 yrs): collaborates with ['Dr. Taylor', 'Dr. Brown']\n",
      "  Dr. Taylor (Robotics, 10 yrs): collaborates with ['Dr. Wilson', 'Dr. Davis']\n"
     ]
    }
   ],
   "source": [
    "# Create a larger network for demonstration\n",
    "network = Graph.empty()\n",
    "\n",
    "# Add researchers and their fields\n",
    "researchers = {\n",
    "    'Dr. Smith': {'field': 'AI', 'experience': 15, 'publications': 120, 'university': 'MIT'},\n",
    "    'Dr. Jones': {'field': 'ML', 'experience': 8, 'publications': 45, 'university': 'Stanford'},\n",
    "    'Dr. Brown': {'field': 'NLP', 'experience': 12, 'publications': 78, 'university': 'MIT'},\n",
    "    'Dr. Wilson': {'field': 'CV', 'experience': 6, 'publications': 34, 'university': 'Berkeley'},\n",
    "    'Dr. Davis': {'field': 'AI', 'experience': 20, 'publications': 200, 'university': 'CMU'},\n",
    "    'Dr. Taylor': {'field': 'Robotics', 'experience': 10, 'publications': 56, 'university': 'Stanford'}\n",
    "}\n",
    "\n",
    "researcher_ids = {}\n",
    "for name, attrs in researchers.items():\n",
    "    researcher_ids[name] = network.add_node(name=name, **attrs)\n",
    "\n",
    "# Add collaborations\n",
    "collaborations = [\n",
    "    ('Dr. Smith', 'Dr. Jones', {'projects': 3, 'strength': 0.8, 'since': 2018}),\n",
    "    ('Dr. Smith', 'Dr. Brown', {'projects': 5, 'strength': 0.9, 'since': 2016}),\n",
    "    ('Dr. Jones', 'Dr. Wilson', {'projects': 2, 'strength': 0.6, 'since': 2020}),\n",
    "    ('Dr. Brown', 'Dr. Davis', {'projects': 4, 'strength': 0.7, 'since': 2017}),\n",
    "    ('Dr. Davis', 'Dr. Taylor', {'projects': 1, 'strength': 0.5, 'since': 2021}),\n",
    "    ('Dr. Wilson', 'Dr. Taylor', {'projects': 2, 'strength': 0.6, 'since': 2019})\n",
    "]\n",
    "\n",
    "for person1, person2, attrs in collaborations:\n",
    "    network.add_edge(researcher_ids[person1], researcher_ids[person2], **attrs)\n",
    "\n",
    "print(f\"Research network created: {network.node_count()} researchers, {network.edge_count()} collaborations\")\n",
    "\n",
    "# Display network structure\n",
    "print(\"\\nResearch Network:\")\n",
    "for researcher_name, researcher_id in researcher_ids.items():\n",
    "    researcher = network.get_node(researcher_id)\n",
    "    neighbors = network.get_neighbors(researcher_id)\n",
    "    neighbor_names = [network.get_node(nid)['name'] for nid in neighbors]\n",
    "    print(f\"  {researcher['name']} ({researcher['field']}, {researcher['experience']} yrs): collaborates with {neighbor_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2499177a",
   "metadata": {},
   "source": [
    "### 8.1 Creating Subgraphs with Filters\n",
    "\n",
    "GLI allows you to create subgraphs based on node and edge criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "644239c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Senior Researchers Subgraph ===\n",
      "Nodes: 3, Edges: 2\n",
      "  Dr. Smith: 15 years, 120 publications\n",
      "  Dr. Davis: 20 years, 200 publications\n",
      "  Dr. Brown: 12 years, 78 publications\n",
      "\n",
      "=== MIT Researchers Subgraph ===\n",
      "Nodes: 2, Edges: 1\n",
      "  Dr. Smith: collaborates with ['Dr. Brown']\n",
      "  Dr. Brown: collaborates with ['Dr. Smith']\n",
      "\n",
      "=== Strong Collaborations Subgraph ===\n",
      "Nodes: 6, Edges: 3\n",
      "  Dr. Smith ↔ Dr. Jones: 3 projects, strength 0.8\n",
      "  Dr. Smith ↔ Dr. Brown: 5 projects, strength 0.9\n",
      "  Dr. Brown ↔ Dr. Davis: 4 projects, strength 0.7\n"
     ]
    }
   ],
   "source": [
    "# Create subgraph of senior researchers (>10 years experience)\n",
    "senior_researchers = network.create_subgraph(\n",
    "    node_filter=lambda node: node['experience'] > 10\n",
    ")\n",
    "\n",
    "print(\"=== Senior Researchers Subgraph ===\")\n",
    "print(f\"Nodes: {senior_researchers.node_count()}, Edges: {senior_researchers.edge_count()}\")\n",
    "\n",
    "for node_id in senior_researchers.nodes:\n",
    "    node = senior_researchers.get_node(node_id)\n",
    "    print(f\"  {node['name']}: {node['experience']} years, {node['publications']} publications\")\n",
    "\n",
    "# Create subgraph of MIT researchers\n",
    "mit_network = network.create_subgraph(\n",
    "    node_filter=lambda node: node['university'] == 'MIT'\n",
    ")\n",
    "\n",
    "print(f\"\\n=== MIT Researchers Subgraph ===\")\n",
    "print(f\"Nodes: {mit_network.node_count()}, Edges: {mit_network.edge_count()}\")\n",
    "\n",
    "for node_id in mit_network.nodes:\n",
    "    node = mit_network.get_node(node_id)\n",
    "    neighbors = mit_network.get_neighbors(node_id)\n",
    "    neighbor_names = [mit_network.get_node(nid)['name'] for nid in neighbors]\n",
    "    print(f\"  {node['name']}: collaborates with {neighbor_names}\")\n",
    "\n",
    "# Create subgraph of strong collaborations (>= 3 projects)\n",
    "strong_collabs = network.create_subgraph(\n",
    "    edge_filter=lambda edge: edge['projects'] >= 3\n",
    ")\n",
    "\n",
    "print(f\"\\n=== Strong Collaborations Subgraph ===\")\n",
    "print(f\"Nodes: {strong_collabs.node_count()}, Edges: {strong_collabs.edge_count()}\")\n",
    "\n",
    "for edge_id in strong_collabs.edges:\n",
    "    edge = strong_collabs.get_edge(edge_id)\n",
    "    source_name = strong_collabs.get_node(edge.source)['name']\n",
    "    target_name = strong_collabs.get_node(edge.target)['name']\n",
    "    print(f\"  {source_name} ↔ {target_name}: {edge['projects']} projects, strength {edge['strength']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e19e479",
   "metadata": {},
   "source": [
    "### 8.2 Connected Components Analysis\n",
    "\n",
    "Find connected components in a graph to identify separate clusters or communities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d9122d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Social network: 6 people, 3 connections\n",
      "\n",
      "Alice's connected component:\n",
      "  Size: 3 nodes, 2 edges\n",
      "  - Bob (tech)\n",
      "  - Carol (tech)\n",
      "  - Alice (tech)\n",
      "\n",
      "Dave's connected component:\n",
      "  Size: 2 nodes, 1 edges\n",
      "  - Eve (sports)\n",
      "  - Dave (sports)\n",
      "\n",
      "Frank's connected component:\n",
      "  Size: 1 nodes, 0 edges\n",
      "  - Frank (music)\n"
     ]
    }
   ],
   "source": [
    "# Create a graph with multiple disconnected components\n",
    "social_network = Graph.empty()\n",
    "\n",
    "# Group 1: Tech friends\n",
    "tech_people = ['Alice', 'Bob', 'Carol']\n",
    "tech_ids = {}\n",
    "for person in tech_people:\n",
    "    tech_ids[person] = social_network.add_node(name=person, group='tech', interests=['coding', 'AI'])\n",
    "\n",
    "social_network.add_edge(tech_ids['Alice'], tech_ids['Bob'], relationship='friend', years=5)\n",
    "social_network.add_edge(tech_ids['Bob'], tech_ids['Carol'], relationship='colleague', years=2)\n",
    "\n",
    "# Group 2: Sports friends (disconnected from tech group)\n",
    "sports_people = ['Dave', 'Eve']\n",
    "sports_ids = {}\n",
    "for person in sports_people:\n",
    "    sports_ids[person] = social_network.add_node(name=person, group='sports', interests=['football', 'tennis'])\n",
    "\n",
    "social_network.add_edge(sports_ids['Dave'], sports_ids['Eve'], relationship='teammate', years=3)\n",
    "\n",
    "# Group 3: Isolated person\n",
    "frank_id = social_network.add_node(name='Frank', group='music', interests=['guitar', 'jazz'])\n",
    "\n",
    "print(f\"Social network: {social_network.node_count()} people, {social_network.edge_count()} connections\")\n",
    "\n",
    "# Find connected component starting from Alice\n",
    "alice_component = social_network.get_connected_component(tech_ids['Alice'])\n",
    "print(f\"\\nAlice's connected component:\")\n",
    "print(f\"  Size: {alice_component.node_count()} nodes, {alice_component.edge_count()} edges\")\n",
    "for node_id in alice_component.nodes:\n",
    "    node = alice_component.get_node(node_id)\n",
    "    print(f\"  - {node['name']} ({node['group']})\")\n",
    "\n",
    "# Find connected component starting from Dave\n",
    "dave_component = social_network.get_connected_component(sports_ids['Dave'])\n",
    "print(f\"\\nDave's connected component:\")\n",
    "print(f\"  Size: {dave_component.node_count()} nodes, {dave_component.edge_count()} edges\")\n",
    "for node_id in dave_component.nodes:\n",
    "    node = dave_component.get_node(node_id)\n",
    "    print(f\"  - {node['name']} ({node['group']})\")\n",
    "\n",
    "# Frank should be isolated\n",
    "frank_component = social_network.get_connected_component(frank_id)\n",
    "print(f\"\\nFrank's connected component:\")\n",
    "print(f\"  Size: {frank_component.node_count()} nodes, {frank_component.edge_count()} edges\")\n",
    "for node_id in frank_component.nodes:\n",
    "    node = frank_component.get_node(node_id)\n",
    "    print(f\"  - {node['name']} ({node['group']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b204e4",
   "metadata": {},
   "source": [
    "### 8.3 Batch Operations for Performance\n",
    "\n",
    "Use batch operations for efficient bulk graph modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a71263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Performance Comparison: Individual vs Batch Operations ===\n",
      "Individual operations: 0.009 seconds\n",
      "  Created 1000 nodes and 500 edges\n",
      "Batch operations: 0.012 seconds\n",
      "  Created 1000 nodes and 500 edges\n",
      "Speedup: 0.7x faster\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import importlib\n",
    "import gli.graph\n",
    "\n",
    "# Force module reload to pick up latest changes\n",
    "importlib.reload(gli.graph)\n",
    "\n",
    "# Test batch operations\n",
    "print(\"=== Performance Comparison: Individual vs Batch Operations ===\")\n",
    "\n",
    "def create_test_graph(backend_name, size=1000):\n",
    "    \"\"\"Create a test graph with specified backend\"\"\"\n",
    "    gli.set_backend(backend_name)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    g = gli.Graph.empty()\n",
    "    \n",
    "    # Add nodes individually\n",
    "    node_ids = []\n",
    "    for i in range(size):\n",
    "        node_id = g.add_node(\n",
    "            id=i,\n",
    "            category=random.choice(['A', 'B', 'C', 'D']),\n",
    "            score=random.uniform(0, 100),\n",
    "            active=random.choice([True, False])\n",
    "        )\n",
    "        node_ids.append(node_id)\n",
    "    \n",
    "    # Add edges individually\n",
    "    for i in range(size // 2):\n",
    "        source = random.choice(node_ids)\n",
    "        target = random.choice(node_ids)\n",
    "        if source != target:\n",
    "            g.add_edge(source, target, weight=random.uniform(0, 1))\n",
    "    \n",
    "    creation_time = time.time() - start_time\n",
    "    return g, creation_time\n",
    "\n",
    "# Test individual operations\n",
    "individual_graph, individual_time = create_test_graph('rust', 1000)\n",
    "print(f\"Individual operations: {individual_time:.3f} seconds\")\n",
    "print(f\"  Created {individual_graph.node_count()} nodes and {individual_graph.edge_count()} edges\")\n",
    "\n",
    "# Test batch operations\n",
    "start_time = time.time()\n",
    "batch_graph = gli.Graph.empty()\n",
    "\n",
    "# Use batch context for efficient operations\n",
    "with batch_graph.batch_operations() as batch:\n",
    "    batch_node_ids = []\n",
    "    for i in range(1000):\n",
    "        node_id = batch.add_node(\n",
    "            id=i,\n",
    "            category=random.choice(['A', 'B', 'C', 'D']),\n",
    "            score=random.uniform(0, 100),\n",
    "            active=random.choice([True, False])\n",
    "        )\n",
    "        batch_node_ids.append(node_id)\n",
    "    \n",
    "    for i in range(500):\n",
    "        source = random.choice(batch_node_ids)\n",
    "        target = random.choice(batch_node_ids)\n",
    "        if source != target:\n",
    "            batch.add_edge(source, target, weight=random.random())\n",
    "\n",
    "batch_time = time.time() - start_time\n",
    "\n",
    "print(f\"Batch operations: {batch_time:.3f} seconds\")\n",
    "print(f\"  Created {batch_graph.node_count()} nodes and {batch_graph.edge_count()} edges\")\n",
    "\n",
    "if individual_time > 0 and batch_time > 0:\n",
    "    print(f\"Speedup: {individual_time/batch_time:.1f}x faster\")\n",
    "else:\n",
    "    print(\"Both operations completed very quickly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b1371e",
   "metadata": {},
   "source": [
    "## 9. Graph Analysis and Metrics\n",
    "\n",
    "Analyze graph properties, find patterns, and compute important metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e381c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Research Network Analysis ===\n",
      "Total researchers: 6\n",
      "Total collaborations: 6\n",
      "Network density: 0.400\n",
      "\n",
      "=== Collaboration Patterns ===\n",
      "Most collaborative researchers:\n",
      "  Dr. Smith: 2 collaborations (AI, 120 papers)\n",
      "  Dr. Jones: 2 collaborations (ML, 45 papers)\n",
      "  Dr. Brown: 2 collaborations (NLP, 78 papers)\n",
      "  Dr. Wilson: 2 collaborations (CV, 34 papers)\n",
      "  Dr. Davis: 2 collaborations (AI, 200 papers)\n",
      "  Dr. Taylor: 2 collaborations (Robotics, 56 papers)\n",
      "\n",
      "=== Field Distribution ===\n",
      "  AI: 2 researchers, avg 160.0 publications\n",
      "  ML: 1 researchers, avg 45.0 publications\n",
      "  NLP: 1 researchers, avg 78.0 publications\n",
      "  CV: 1 researchers, avg 34.0 publications\n",
      "  Robotics: 1 researchers, avg 56.0 publications\n",
      "\n",
      "=== Cross-University Collaborations ===\n",
      "  Cross-university: 5\n",
      "  Same university: 1\n",
      "  Cross-university ratio: 83.33%\n",
      "\n",
      "=== Experience vs Collaboration Patterns ===\n",
      "  High experience pairs (12+ yrs): avg strength 0.70\n",
      "  Lower experience pairs: avg strength 0.67\n"
     ]
    }
   ],
   "source": [
    "# Analyze the research network we created earlier\n",
    "print(\"=== Research Network Analysis ===\")\n",
    "print(f\"Total researchers: {network.node_count()}\")\n",
    "print(f\"Total collaborations: {network.edge_count()}\")\n",
    "print(f\"Network density: {2 * network.edge_count() / (network.node_count() * (network.node_count() - 1)):.3f}\")\n",
    "\n",
    "# Degree analysis\n",
    "print(f\"\\n=== Collaboration Patterns ===\")\n",
    "degree_stats = {}\n",
    "for researcher_name, researcher_id in researcher_ids.items():\n",
    "    neighbors = network.get_neighbors(researcher_id)\n",
    "    degree_stats[researcher_name] = len(neighbors)\n",
    "\n",
    "# Sort by degree (most collaborative first)\n",
    "sorted_researchers = sorted(degree_stats.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Most collaborative researchers:\")\n",
    "for name, degree in sorted_researchers:\n",
    "    researcher = network.get_node(researcher_ids[name])\n",
    "    print(f\"  {name}: {degree} collaborations ({researcher['field']}, {researcher['publications']} papers)\")\n",
    "\n",
    "# Field analysis\n",
    "print(f\"\\n=== Field Distribution ===\")\n",
    "field_counts = {}\n",
    "field_publications = {}\n",
    "\n",
    "for researcher_name, researcher_id in researcher_ids.items():\n",
    "    researcher = network.get_node(researcher_id)\n",
    "    field = researcher['field']\n",
    "    \n",
    "    field_counts[field] = field_counts.get(field, 0) + 1\n",
    "    field_publications[field] = field_publications.get(field, 0) + researcher['publications']\n",
    "\n",
    "for field, count in field_counts.items():\n",
    "    avg_pubs = field_publications[field] / count\n",
    "    print(f\"  {field}: {count} researchers, avg {avg_pubs:.1f} publications\")\n",
    "\n",
    "# University collaboration analysis\n",
    "print(f\"\\n=== Cross-University Collaborations ===\")\n",
    "cross_university_collabs = 0\n",
    "same_university_collabs = 0\n",
    "\n",
    "for edge_id in network.edges:\n",
    "    edge = network.get_edge(edge_id)\n",
    "    source_uni = network.get_node(edge.source)['university']\n",
    "    target_uni = network.get_node(edge.target)['university']\n",
    "    \n",
    "    if source_uni != target_uni:\n",
    "        cross_university_collabs += 1\n",
    "    else:\n",
    "        same_university_collabs += 1\n",
    "\n",
    "print(f\"  Cross-university: {cross_university_collabs}\")\n",
    "print(f\"  Same university: {same_university_collabs}\")\n",
    "print(f\"  Cross-university ratio: {cross_university_collabs / network.edge_count():.2%}\")\n",
    "\n",
    "# Experience vs collaboration strength analysis\n",
    "print(f\"\\n=== Experience vs Collaboration Patterns ===\")\n",
    "high_exp_collabs = []\n",
    "low_exp_collabs = []\n",
    "\n",
    "for edge_id in network.edges:\n",
    "    edge = network.get_edge(edge_id)\n",
    "    source_exp = network.get_node(edge.source)['experience']\n",
    "    target_exp = network.get_node(edge.target)['experience']\n",
    "    avg_exp = (source_exp + target_exp) / 2\n",
    "    \n",
    "    if avg_exp >= 12:\n",
    "        high_exp_collabs.append(edge['strength'])\n",
    "    else:\n",
    "        low_exp_collabs.append(edge['strength'])\n",
    "\n",
    "if high_exp_collabs:\n",
    "    print(f\"  High experience pairs (12+ yrs): avg strength {sum(high_exp_collabs)/len(high_exp_collabs):.2f}\")\n",
    "if low_exp_collabs:\n",
    "    print(f\"  Lower experience pairs: avg strength {sum(low_exp_collabs)/len(low_exp_collabs):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aa2cbc",
   "metadata": {},
   "source": [
    "## 10. Backend Switching and Performance\n",
    "\n",
    "GLI supports seamless switching between Python and Rust backends for optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a20a78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Backend Performance Comparison ===\n",
      "\n",
      "Testing PYTHON backend...\n",
      "  Graph creation: 0.018s (2000 nodes, 999 edges)\n",
      "  Attribute access: 0.000s\n",
      "  Graph traversal: 0.035s\n",
      "\n",
      "Testing RUST backend...\n",
      "  Graph creation: 0.018s (2000 nodes, 999 edges)\n",
      "  Attribute access: 0.000s\n",
      "  Graph traversal: 0.035s\n",
      "\n",
      "Testing RUST backend...\n",
      "  Graph creation: 0.025s (2000 nodes, 1000 edges)\n",
      "  Attribute access: 0.000s\n",
      "  Graph traversal: 0.000s\n",
      "\n",
      "=== Performance Summary ===\n",
      "Python backend total time: 0.054s\n",
      "Rust backend total time: 0.025s\n",
      "Rust speedup: 2.1x faster\n",
      "\n",
      "Detailed comparison:\n",
      "  Creation Time: 0.7x faster\n",
      "  Access Time: 1.5x faster\n",
      "  Traversal Time: 177.5x faster\n",
      "  Graph creation: 0.025s (2000 nodes, 1000 edges)\n",
      "  Attribute access: 0.000s\n",
      "  Graph traversal: 0.000s\n",
      "\n",
      "=== Performance Summary ===\n",
      "Python backend total time: 0.054s\n",
      "Rust backend total time: 0.025s\n",
      "Rust speedup: 2.1x faster\n",
      "\n",
      "Detailed comparison:\n",
      "  Creation Time: 0.7x faster\n",
      "  Access Time: 1.5x faster\n",
      "  Traversal Time: 177.5x faster\n"
     ]
    }
   ],
   "source": [
    "# Test backend switching and performance\n",
    "print(\"=== Backend Performance Comparison ===\")\n",
    "\n",
    "def create_test_graph(backend_name, size=2000):\n",
    "    \"\"\"Create a test graph with specified backend\"\"\"\n",
    "    gli.set_backend(backend_name)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    g = gli.Graph.empty()\n",
    "    \n",
    "    # Add nodes with complex attributes\n",
    "    node_ids = []\n",
    "    for i in range(size):\n",
    "        node_id = g.add_node(\n",
    "            id=i,\n",
    "            category=random.choice(['A', 'B', 'C', 'D']),\n",
    "            score=random.uniform(0, 100),\n",
    "            active=random.choice([True, False]),\n",
    "            tags=[f\"tag_{j}\" for j in range(random.randint(1, 5))],\n",
    "            metadata={'created': time.time(), 'batch': i // 100}\n",
    "        )\n",
    "        node_ids.append(node_id)\n",
    "    \n",
    "    # Add edges with attributes\n",
    "    for i in range(size // 2):\n",
    "        source = random.choice(node_ids)\n",
    "        target = random.choice(node_ids)\n",
    "        if source != target:\n",
    "            g.add_edge(source, target,\n",
    "                      weight=random.uniform(0, 1),\n",
    "                      type=random.choice(['friend', 'colleague', 'family']),\n",
    "                      created_at=time.time())\n",
    "    \n",
    "    creation_time = time.time() - start_time\n",
    "    \n",
    "    # Test attribute access performance\n",
    "    start_time = time.time()\n",
    "    sample_nodes = random.sample(node_ids, min(100, len(node_ids)))\n",
    "    for node_id in sample_nodes:\n",
    "        node = g.get_node(node_id)\n",
    "        attrs = dict(node.attributes)\n",
    "        # Modify an attribute\n",
    "        g.set_node_attribute(node_id, 'accessed', True)\n",
    "    \n",
    "    access_time = time.time() - start_time\n",
    "    \n",
    "    # Test graph traversal\n",
    "    start_time = time.time()\n",
    "    for node_id in sample_nodes:\n",
    "        neighbors = g.get_neighbors(node_id)\n",
    "        for neighbor_id in neighbors[:5]:  # Limit to first 5 neighbors\n",
    "            neighbor = g.get_node(neighbor_id)\n",
    "    \n",
    "    traversal_time = time.time() - start_time\n",
    "    \n",
    "    return g, creation_time, access_time, traversal_time\n",
    "\n",
    "# Test both backends\n",
    "results = {}\n",
    "test_size = 2000\n",
    "\n",
    "for backend in ['python', 'rust']:\n",
    "    print(f\"\\nTesting {backend.upper()} backend...\")\n",
    "    graph, create_t, access_t, traverse_t = create_test_graph(backend, test_size)\n",
    "    \n",
    "    results[backend] = {\n",
    "        'creation_time': create_t,\n",
    "        'access_time': access_t,\n",
    "        'traversal_time': traverse_t,\n",
    "        'nodes': graph.node_count(),\n",
    "        'edges': graph.edge_count()\n",
    "    }\n",
    "    \n",
    "    print(f\"  Graph creation: {create_t:.3f}s ({results[backend]['nodes']} nodes, {results[backend]['edges']} edges)\")\n",
    "    print(f\"  Attribute access: {access_t:.3f}s\")\n",
    "    print(f\"  Graph traversal: {traverse_t:.3f}s\")\n",
    "\n",
    "# Compare results\n",
    "print(f\"\\n=== Performance Summary ===\")\n",
    "python_total = sum([results['python'][k] for k in ['creation_time', 'access_time', 'traversal_time']])\n",
    "rust_total = sum([results['rust'][k] for k in ['creation_time', 'access_time', 'traversal_time']])\n",
    "\n",
    "print(f\"Python backend total time: {python_total:.3f}s\")\n",
    "print(f\"Rust backend total time: {rust_total:.3f}s\")\n",
    "print(f\"Rust speedup: {python_total/rust_total:.1f}x faster\")\n",
    "\n",
    "print(f\"\\nDetailed comparison:\")\n",
    "for operation in ['creation_time', 'access_time', 'traversal_time']:\n",
    "    speedup = results['python'][operation] / results['rust'][operation]\n",
    "    print(f\"  {operation.replace('_', ' ').title()}: {speedup:.1f}x faster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936d8623",
   "metadata": {},
   "source": [
    "## 11. Complex Data Types and Real-World Example\n",
    "\n",
    "Let's build a comprehensive example that showcases GLI's ability to handle complex, real-world data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d6fc429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Building Supply Chain Network ===\n",
      "Supply chain network: 4 companies, 3 relationships\n",
      "\n",
      "=== Supply Chain Analysis ===\n",
      "High sustainability companies (score >= 8.0):\n",
      "  EcoLogistics: 9.1\n",
      "  TechCorp: 8.5\n",
      "\n",
      "Contract Analysis:\n",
      "  GlobalSupply → TechCorp: $5,000,000 (supplies)\n",
      "    Financial risk: low, Operational risk: medium\n",
      "    On-time delivery: 95.0%\n",
      "  TechCorp → EcoLogistics: $2,000,000 (ships_via)\n",
      "    Financial risk: low, Operational risk: low\n",
      "    On-time delivery: 98.0%\n",
      "  EcoLogistics → RetailGiant: $3,000,000 (delivers_to)\n",
      "    Financial risk: low, Operational risk: low\n",
      "    On-time delivery: 99.0%\n",
      "\n",
      "Total contract value: $10,000,000\n",
      "\n",
      "Geographic Distribution:\n",
      "  USA: 2 companies\n",
      "  China: 1 companies\n",
      "  Germany: 1 companies\n"
     ]
    }
   ],
   "source": [
    "# Build a comprehensive supply chain network\n",
    "print(\"=== Building Supply Chain Network ===\")\n",
    "\n",
    "# Use Rust backend for performance\n",
    "gli.set_backend('rust')\n",
    "supply_chain = gli.Graph.empty()\n",
    "\n",
    "# Complex company data with nested structures\n",
    "companies = {\n",
    "    'TechCorp': {\n",
    "        'type': 'manufacturer',\n",
    "        'location': {'country': 'USA', 'city': 'San Francisco', 'coordinates': [37.7749, -122.4194]},\n",
    "        'financials': {'revenue': 50000000, 'employees': 500, 'founded': 2010},\n",
    "        'products': ['smartphones', 'tablets', 'laptops'],\n",
    "        'certifications': ['ISO9001', 'ISO14001'],\n",
    "        'sustainability_score': 8.5,\n",
    "        'contact': {'email': 'supply@techcorp.com', 'phone': '+1-555-0123'}\n",
    "    },\n",
    "    'GlobalSupply': {\n",
    "        'type': 'supplier',\n",
    "        'location': {'country': 'China', 'city': 'Shenzhen', 'coordinates': [22.5431, 114.0579]},\n",
    "        'financials': {'revenue': 20000000, 'employees': 200, 'founded': 2005},\n",
    "        'products': ['semiconductors', 'circuits', 'components'],\n",
    "        'certifications': ['RoHS', 'CE'],\n",
    "        'sustainability_score': 6.2,\n",
    "        'contact': {'email': 'orders@globalsupply.com', 'phone': '+86-755-1234'}\n",
    "    },\n",
    "    'EcoLogistics': {\n",
    "        'type': 'logistics',\n",
    "        'location': {'country': 'Germany', 'city': 'Hamburg', 'coordinates': [53.5511, 9.9937]},\n",
    "        'financials': {'revenue': 8000000, 'employees': 100, 'founded': 2015},\n",
    "        'products': ['shipping', 'warehousing', 'distribution'],\n",
    "        'certifications': ['ISO14001', 'Green_Logistics'],\n",
    "        'sustainability_score': 9.1,\n",
    "        'contact': {'email': 'logistics@ecolog.de', 'phone': '+49-40-567890'}\n",
    "    },\n",
    "    'RetailGiant': {\n",
    "        'type': 'retailer',\n",
    "        'location': {'country': 'USA', 'city': 'New York', 'coordinates': [40.7128, -74.0060]},\n",
    "        'financials': {'revenue': 100000000, 'employees': 1000, 'founded': 1990},\n",
    "        'products': ['retail', 'e-commerce', 'distribution'],\n",
    "        'certifications': ['Fair_Trade', 'B_Corp'],\n",
    "        'sustainability_score': 7.8,\n",
    "        'contact': {'email': 'partners@retailgiant.com', 'phone': '+1-212-555-0199'}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add companies as nodes\n",
    "company_ids = {}\n",
    "for name, data in companies.items():\n",
    "    company_ids[name] = supply_chain.add_node(name=name, **data)\n",
    "\n",
    "# Complex relationship data\n",
    "relationships = [\n",
    "    {\n",
    "        'from': 'GlobalSupply',\n",
    "        'to': 'TechCorp',\n",
    "        'relationship': 'supplies',\n",
    "        'contract': {\n",
    "            'start_date': '2022-01-01',\n",
    "            'end_date': '2024-12-31',\n",
    "            'value': 5000000,\n",
    "            'terms': 'NET30'\n",
    "        },\n",
    "        'delivery_schedule': {\n",
    "            'frequency': 'weekly',\n",
    "            'volume': 1000,\n",
    "            'quality_metrics': {'defect_rate': 0.02, 'on_time_delivery': 0.95}\n",
    "        },\n",
    "        'risk_assessment': {\n",
    "            'financial_risk': 'low',\n",
    "            'operational_risk': 'medium',\n",
    "            'geopolitical_risk': 'medium'\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'from': 'TechCorp',\n",
    "        'to': 'EcoLogistics',\n",
    "        'relationship': 'ships_via',\n",
    "        'contract': {\n",
    "            'start_date': '2023-03-01',\n",
    "            'end_date': '2025-02-28',\n",
    "            'value': 2000000,\n",
    "            'terms': 'NET15'\n",
    "        },\n",
    "        'delivery_schedule': {\n",
    "            'frequency': 'daily',\n",
    "            'volume': 500,\n",
    "            'quality_metrics': {'damage_rate': 0.001, 'on_time_delivery': 0.98}\n",
    "        },\n",
    "        'risk_assessment': {\n",
    "            'financial_risk': 'low',\n",
    "            'operational_risk': 'low',\n",
    "            'geopolitical_risk': 'low'\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'from': 'EcoLogistics',\n",
    "        'to': 'RetailGiant',\n",
    "        'relationship': 'delivers_to',\n",
    "        'contract': {\n",
    "            'start_date': '2023-01-01',\n",
    "            'end_date': '2026-12-31',\n",
    "            'value': 3000000,\n",
    "            'terms': 'NET20'\n",
    "        },\n",
    "        'delivery_schedule': {\n",
    "            'frequency': 'daily',\n",
    "            'volume': 800,\n",
    "            'quality_metrics': {'damage_rate': 0.0005, 'on_time_delivery': 0.99}\n",
    "        },\n",
    "        'risk_assessment': {\n",
    "            'financial_risk': 'low',\n",
    "            'operational_risk': 'low',\n",
    "            'geopolitical_risk': 'low'\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Add relationships as edges\n",
    "for rel in relationships:\n",
    "    supply_chain.add_edge(\n",
    "        company_ids[rel['from']], \n",
    "        company_ids[rel['to']], \n",
    "        **{k: v for k, v in rel.items() if k not in ['from', 'to']}\n",
    "    )\n",
    "\n",
    "print(f\"Supply chain network: {supply_chain.node_count()} companies, {supply_chain.edge_count()} relationships\")\n",
    "\n",
    "# Demonstrate complex queries and analysis\n",
    "print(f\"\\n=== Supply Chain Analysis ===\")\n",
    "\n",
    "# Find high-sustainability companies\n",
    "high_sustainability = []\n",
    "for name, company_id in company_ids.items():\n",
    "    company = supply_chain.get_node(company_id)\n",
    "    if company['sustainability_score'] >= 8.0:\n",
    "        high_sustainability.append((name, company['sustainability_score']))\n",
    "\n",
    "print(f\"High sustainability companies (score >= 8.0):\")\n",
    "for name, score in sorted(high_sustainability, key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {name}: {score}\")\n",
    "\n",
    "# Analyze contract values and risk\n",
    "print(f\"\\nContract Analysis:\")\n",
    "total_contract_value = 0\n",
    "risk_by_type = {'low': 0, 'medium': 0, 'high': 0}\n",
    "\n",
    "for edge_id in supply_chain.edges:\n",
    "    edge = supply_chain.get_edge(edge_id)\n",
    "    source_name = supply_chain.get_node(edge.source)['name']\n",
    "    target_name = supply_chain.get_node(edge.target)['name']\n",
    "    \n",
    "    contract_value = edge['contract']['value']\n",
    "    total_contract_value += contract_value\n",
    "    \n",
    "    # Analyze risks\n",
    "    financial_risk = edge['risk_assessment']['financial_risk']\n",
    "    operational_risk = edge['risk_assessment']['operational_risk']\n",
    "    \n",
    "    print(f\"  {source_name} → {target_name}: ${contract_value:,} ({edge['relationship']})\")\n",
    "    print(f\"    Financial risk: {financial_risk}, Operational risk: {operational_risk}\")\n",
    "    print(f\"    On-time delivery: {edge['delivery_schedule']['quality_metrics']['on_time_delivery']:.1%}\")\n",
    "\n",
    "print(f\"\\nTotal contract value: ${total_contract_value:,}\")\n",
    "\n",
    "# Geographic analysis\n",
    "print(f\"\\nGeographic Distribution:\")\n",
    "countries = {}\n",
    "for name, company_id in company_ids.items():\n",
    "    company = supply_chain.get_node(company_id)\n",
    "    country = company['location']['country']\n",
    "    countries[country] = countries.get(country, 0) + 1\n",
    "\n",
    "for country, count in countries.items():\n",
    "    print(f\"  {country}: {count} companies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ea413a",
   "metadata": {},
   "source": [
    "## 12. Summary and Next Steps\n",
    "\n",
    "Congratulations! You've explored the full capabilities of the GLI (Graph Language Interface) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8493f8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GLI Feature Summary ===\n",
      "Current backend: rust\n",
      "Available backends: python, rust\n",
      "\n",
      "Feature Verification:\n",
      "✅ Node creation with complex attributes\n",
      "✅ Edge creation with attributes\n",
      "✅ Attribute modification\n",
      "✅ Data type preservation: <class 'float'>, <class 'bool'>\n",
      "✅ Nested structures: deep nesting works!\n",
      "✅ Graph traversal: 1 neighbors found\n",
      "\n",
      "🎉 GLI Tutorial Complete!\n",
      "\n",
      "What you learned:\n",
      "  • Basic graph creation and manipulation\n",
      "  • Rich attribute support with complex data types\n",
      "  • Backend switching (Python ↔ Rust)\n",
      "  • Performance optimization with batch operations\n",
      "  • Advanced analysis: subgraphs, connected components\n",
      "  • Real-world examples: social networks, projects, supply chains\n",
      "  • Graph metrics and pattern analysis\n",
      "\n",
      "Next steps:\n",
      "  • Explore the full API documentation\n",
      "  • Try GLI on your own graph data\n",
      "  • Experiment with larger datasets\n",
      "  • Contribute to the project on GitHub!\n",
      "\n",
      "Graphs created in this tutorial:\n",
      "  Social Network: 3 nodes, 3 edges\n",
      "  Project Network: 1 nodes, 0 edges\n",
      "  Knowledge Graph: 8 nodes, 7 edges\n",
      "  Research Network: 6 nodes, 6 edges\n",
      "  Supply Chain: 4 nodes, 3 edges\n"
     ]
    }
   ],
   "source": [
    "# Final demonstration: Show all features working together\n",
    "print(\"=== GLI Feature Summary ===\")\n",
    "\n",
    "# Check current backend\n",
    "current_backend = gli.get_current_backend()\n",
    "available_backends = gli.get_available_backends()\n",
    "\n",
    "print(f\"Current backend: {current_backend}\")\n",
    "print(f\"Available backends: {', '.join(available_backends)}\")\n",
    "\n",
    "# Quick feature test\n",
    "test_graph = gli.Graph.empty()\n",
    "\n",
    "# Add nodes with various data types\n",
    "node1 = test_graph.add_node(\n",
    "    name=\"Feature Test\", \n",
    "    number=42, \n",
    "    float_val=3.14159, \n",
    "    boolean=True,\n",
    "    list_data=[1, 2, 3, \"mixed\", True],\n",
    "    nested_dict={\n",
    "        \"level1\": {\n",
    "            \"level2\": {\"value\": \"deep nesting works!\"}\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "node2 = test_graph.add_node(name=\"Second Node\", category=\"test\")\n",
    "edge_id = test_graph.add_edge(node1, node2, weight=0.75, metadata={\"created\": \"tutorial\"})\n",
    "\n",
    "# Test attribute modification\n",
    "test_graph.set_node_attribute(node1, \"modified\", True)\n",
    "test_graph.set_edge_attribute(edge_id, \"strength\", \"strong\")\n",
    "\n",
    "# Verify everything works\n",
    "node1_data = test_graph.get_node(node1)\n",
    "edge_data = test_graph.get_edge(edge_id)\n",
    "\n",
    "print(f\"\\nFeature Verification:\")\n",
    "print(f\"✅ Node creation with complex attributes\")\n",
    "print(f\"✅ Edge creation with attributes\") \n",
    "print(f\"✅ Attribute modification\")\n",
    "print(f\"✅ Data type preservation: {type(node1_data['float_val'])}, {type(node1_data['boolean'])}\")\n",
    "print(f\"✅ Nested structures: {node1_data['nested_dict']['level1']['level2']['value']}\")\n",
    "print(f\"✅ Graph traversal: {len(test_graph.get_neighbors(node1))} neighbors found\")\n",
    "\n",
    "print(f\"\\n🎉 GLI Tutorial Complete!\")\n",
    "print(f\"\\nWhat you learned:\")\n",
    "print(f\"  • Basic graph creation and manipulation\")\n",
    "print(f\"  • Rich attribute support with complex data types\")\n",
    "print(f\"  • Backend switching (Python ↔ Rust)\")\n",
    "print(f\"  • Performance optimization with batch operations\")\n",
    "print(f\"  • Advanced analysis: subgraphs, connected components\")\n",
    "print(f\"  • Real-world examples: social networks, projects, supply chains\")\n",
    "print(f\"  • Graph metrics and pattern analysis\")\n",
    "\n",
    "print(f\"\\nNext steps:\")\n",
    "print(f\"  • Explore the full API documentation\")\n",
    "print(f\"  • Try GLI on your own graph data\")\n",
    "print(f\"  • Experiment with larger datasets\")\n",
    "print(f\"  • Contribute to the project on GitHub!\")\n",
    "\n",
    "# Show final graph statistics\n",
    "print(f\"\\nGraphs created in this tutorial:\")\n",
    "graphs_info = [\n",
    "    (\"Social Network\", 3, 3),\n",
    "    (\"Project Network\", f\"{g.node_count()}\", f\"{g.edge_count()}\"),\n",
    "    (\"Knowledge Graph\", f\"{kg.node_count()}\", f\"{kg.edge_count()}\"),\n",
    "    (\"Research Network\", f\"{network.node_count()}\", f\"{network.edge_count()}\"),\n",
    "    (\"Supply Chain\", f\"{supply_chain.node_count()}\", f\"{supply_chain.edge_count()}\")\n",
    "]\n",
    "\n",
    "for name, nodes, edges in graphs_info:\n",
    "    print(f\"  {name}: {nodes} nodes, {edges} edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0549cc5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "199c7801",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
