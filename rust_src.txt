--- FILE: types.rs ---
//! Core type definitions for the graph library.
//! 
//! DESIGN PRINCIPLE: Keep types simple and focused. The Graph should be the main
//! manager that coordinates between components, not layers calling layers.

use std::hash::{Hash, Hasher};

/*
=== FUNDAMENTAL TYPES ===
These are the core primitives that everything else builds on.
Keep them simple, efficient, and well-documented.
*/

/// Node identifier - should be opaque, incrementing, and reusable after deletion
/// DESIGN: Use usize for cache-friendly indexing into arrays/vectors
pub type NodeId = usize;

/// Edge identifier - same principles as NodeId
pub type EdgeId = usize;

/// Attribute name - human-readable string key for node/edge properties
pub type AttrName = String;

/// State identifier for version control - should be globally unique and ordered
/// DESIGN: Use u64 for plenty of space and natural ordering
pub type StateId = u64;

/// Branch name for git-like workflow
pub type BranchName = String;

/*
=== GRAPH STRUCTURE TYPES ===
Fundamental graph properties that affect behavior across the entire system.
*/

/// Graph directionality - determines edge interpretation throughout the system
/// DESIGN: This affects adjacency caching, traversal algorithms, and matrix operations
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum GraphType {
    /// Directed graph - edges have direction (A→B ≠ B→A)
    /// Compatible with NetworkX DiGraph
    Directed,
    /// Undirected graph - edges are bidirectional (A↔B = B↔A) 
    /// Compatible with NetworkX Graph
    Undirected,
}

impl Default for GraphType {
    /// Default to undirected for backward compatibility
    fn default() -> Self {
        Self::Undirected
    }
}

/*
=== ATTRIBUTE VALUE SYSTEM ===
This is the heart of the flexible attribute system. Should support:
- Common data types (numbers, strings, bools)
- Vector embeddings for ML workloads  
- Efficient hashing for deduplication
- JSON-like flexibility without the performance cost
*/

/// Efficient storage for attribute values supporting multiple data types
/// DESIGN: Enum dispatch is fast, Hash implementation handles f32 properly
#[derive(Debug, Clone)]
pub enum AttrValue {
    /// 32-bit float (embeddings, coordinates, ML features)
    Float(f32),
    /// 64-bit signed integer (counts, IDs, timestamps)
    Int(i64),
    /// UTF-8 string (names, descriptions, categories)
    Text(String),
    /// Vector of floats (embeddings, coordinates, feature vectors)
    /// PERFORMANCE: Vec<f32> is more cache-friendly than Vec<AttrValue>
    FloatVec(Vec<f32>),
    /// Boolean flag (active, enabled, etc.)
    Bool(bool),
    /// Memory-optimized compact string for short text values (Memory Optimization 1)
    /// Uses inline storage for strings <= 15 bytes, avoiding heap allocation
    CompactText(CompactString),
    /// Memory-optimized small integer for values that fit in smaller types
    SmallInt(i32),
    /// Byte array for binary data (more efficient than Vec<u8> as AttrValue)
    Bytes(Vec<u8>),
    /// Compressed large text data (Memory Optimization 3)
    CompressedText(CompressedData),
    /// Compressed large float vector (Memory Optimization 3)
    CompressedFloatVec(CompressedData),
}

/// Custom PartialEq implementation that compares logical content across storage variants
/// This allows Text("hello") to equal CompactText("hello") and CompressedText("hello")
impl PartialEq for AttrValue {
    fn eq(&self, other: &Self) -> bool {
        use AttrValue::*;
        match (self, other) {
            // Exact type matches
            (Float(a), Float(b)) => a == b,
            (Int(a), Int(b)) => a == b,
            (Bool(a), Bool(b)) => a == b,
            (SmallInt(a), SmallInt(b)) => a == b,
            (FloatVec(a), FloatVec(b)) => a == b,
            (Bytes(a), Bytes(b)) => a == b,
            
            // Cross-type integer comparisons
            (Int(a), SmallInt(b)) => *a == *b as i64,
            (SmallInt(a), Int(b)) => *a as i64 == *b,
            
            // Cross-type string comparisons - compare content, not storage format
            (Text(a), Text(b)) => a == b,
            (Text(a), CompactText(b)) => a.as_str() == b.as_str(),
            (Text(a), CompressedText(b)) => {
                if let Ok(decompressed) = b.decompress_text() {
                    a.as_str() == decompressed.as_str()
                } else {
                    false
                }
            }
            (CompactText(a), Text(b)) => a.as_str() == b.as_str(),
            (CompactText(a), CompactText(b)) => a.as_str() == b.as_str(),
            (CompactText(a), CompressedText(b)) => {
                if let Ok(decompressed) = b.decompress_text() {
                    a.as_str() == decompressed.as_str()
                } else {
                    false
                }
            }
            (CompressedText(a), Text(b)) => {
                if let Ok(decompressed) = a.decompress_text() {
                    decompressed.as_str() == b.as_str()
                } else {
                    false
                }
            }
            (CompressedText(a), CompactText(b)) => {
                if let Ok(decompressed) = a.decompress_text() {
                    decompressed.as_str() == b.as_str()
                } else {
                    false
                }
            }
            (CompressedText(a), CompressedText(b)) => {
                // For compressed text, try to decompress both and compare
                match (a.decompress_text(), b.decompress_text()) {
                    (Ok(a_text), Ok(b_text)) => a_text == b_text,
                    _ => false,
                }
            }
            
            // Cross-type float vector comparisons
            (FloatVec(a), CompressedFloatVec(b)) => {
                // TODO: Implement compressed float vector decompression when needed
                let _ = (a, b);
                false
            }
            (CompressedFloatVec(a), FloatVec(b)) => {
                // TODO: Implement compressed float vector decompression when needed
                let _ = (a, b);
                false
            }
            (CompressedFloatVec(a), CompressedFloatVec(b)) => {
                // TODO: Implement compressed float vector comparison when needed
                let _ = (a, b);
                false
            }
            
            // All other combinations are not equal
            _ => false,
        }
    }
}

/// Memory-efficient string storage that avoids heap allocation for short strings
/// MEMORY OPTIMIZATION: Stores strings <= 15 bytes inline, larger ones on heap
#[derive(Debug, Clone, PartialEq)]
pub enum CompactString {
    /// Inline storage for strings up to 15 bytes (fits in 16 bytes total)
    Inline { data: [u8; 15], len: u8 },
    /// Heap storage for longer strings
    Heap(String),
}

impl CompactString {
    /// Create a new compact string from a regular string
    pub fn new(s: &str) -> Self {
        let bytes = s.as_bytes();
        if bytes.len() <= 15 {
            let mut data = [0u8; 15];
            data[..bytes.len()].copy_from_slice(bytes);
            CompactString::Inline { 
                data, 
                len: bytes.len() as u8 
            }
        } else {
            CompactString::Heap(s.to_string())
        }
    }
    
    /// Get the string content as a &str
    pub fn as_str(&self) -> &str {
        match self {
            CompactString::Inline { data, len } => {
                std::str::from_utf8(&data[..*len as usize]).unwrap()
            }
            CompactString::Heap(s) => s.as_str(),
        }
    }
    
    /// Get the memory usage in bytes
    pub fn memory_size(&self) -> usize {
        match self {
            CompactString::Inline { .. } => 16, // 15 bytes data + 1 byte length
            CompactString::Heap(s) => std::mem::size_of::<String>() + s.capacity(),
        }
    }
}

// IMPLEMENTATION NOTES:
// - Hash trait needed for deduplication in change tracking
// - Use f32.to_bits() for consistent hashing of floats
// - Sort hash inputs to ensure deterministic ordering
impl Hash for AttrValue {
    fn hash<H: Hasher>(&self, state: &mut H) {
        match self {
            AttrValue::Float(f) => {
                0u8.hash(state);  // Discriminant for Float variant
                f.to_bits().hash(state);  // Use to_bits() for consistent float hashing
            }
            AttrValue::Int(i) => {
                1u8.hash(state);  // Discriminant for Int variant
                i.hash(state);
            }
            AttrValue::Text(s) => {
                2u8.hash(state);  // Discriminant for Text variant
                s.hash(state);
            }
            AttrValue::FloatVec(v) => {
                3u8.hash(state);  // Discriminant for FloatVec variant
                v.len().hash(state);  // Hash length first
                for f in v {
                    f.to_bits().hash(state);  // Hash each float using to_bits()
                }
            }
            AttrValue::Bool(b) => {
                4u8.hash(state);  // Discriminant for Bool variant
                b.hash(state);
            }
            AttrValue::CompactText(cs) => {
                5u8.hash(state);  // Discriminant for CompactText variant
                cs.as_str().hash(state);
            }
            AttrValue::SmallInt(i) => {
                6u8.hash(state);  // Discriminant for SmallInt variant
                i.hash(state);
            }
            AttrValue::Bytes(bytes) => {
                7u8.hash(state);  // Discriminant for Bytes variant
                bytes.hash(state);
            }
            AttrValue::CompressedText(cd) => {
                8u8.hash(state);  // Discriminant for CompressedText variant
                cd.data.hash(state);
                cd.original_size.hash(state);
            }
            AttrValue::CompressedFloatVec(cd) => {
                9u8.hash(state);  // Discriminant for CompressedFloatVec variant
                cd.data.hash(state);
                cd.original_size.hash(state);
            }
        }
    }
}

// Manual Eq implementation to handle f32 comparison
impl Eq for AttrValue {}

/// Compressed data storage for large values (Memory Optimization 3)
/// Uses simple run-length encoding and basic compression
#[derive(Debug, Clone, PartialEq)]
pub struct CompressedData {
    /// Compressed bytes
    pub data: Vec<u8>,
    /// Original size before compression
    original_size: usize,
    /// Compression algorithm used
    algorithm: CompressionAlgorithm,
}

#[derive(Debug, Clone, PartialEq)]
pub enum CompressionAlgorithm {
    /// No compression (passthrough)
    None,
    /// Simple run-length encoding for repetitive data
    RunLength,
    /// Basic LZ77-style compression for text
    Basic,
}

impl CompressedData {
    /// Compress text data
    pub fn compress_text(text: &str) -> Self {
        let bytes = text.as_bytes();
        
        // For small text, don't compress
        if bytes.len() < 100 {
            return Self {
                data: bytes.to_vec(),
                original_size: bytes.len(),
                algorithm: CompressionAlgorithm::None,
            };
        }
        
        // Simple run-length encoding for repetitive text
        let compressed = Self::run_length_encode(bytes);
        
        // Only use compression if it actually saves space
        if compressed.len() < bytes.len() {
            Self {
                data: compressed,
                original_size: bytes.len(),
                algorithm: CompressionAlgorithm::RunLength,
            }
        } else {
            Self {
                data: bytes.to_vec(),
                original_size: bytes.len(),
                algorithm: CompressionAlgorithm::None,
            }
        }
    }
    
    /// Compress float vector data
    pub fn compress_float_vec(vec: &[f32]) -> Self {
        let bytes = unsafe {
            std::slice::from_raw_parts(
                vec.as_ptr() as *const u8,
                vec.len() * std::mem::size_of::<f32>()
            )
        };
        
        // For small vectors, don't compress
        if vec.len() < 25 {
            return Self {
                data: bytes.to_vec(),
                original_size: bytes.len(),
                algorithm: CompressionAlgorithm::None,
            };
        }
        
        // Run-length encoding can work well for sparse vectors
        let compressed = Self::run_length_encode(bytes);
        
        if compressed.len() < bytes.len() {
            Self {
                data: compressed,
                original_size: bytes.len(),
                algorithm: CompressionAlgorithm::RunLength,
            }
        } else {
            Self {
                data: bytes.to_vec(),
                original_size: bytes.len(),
                algorithm: CompressionAlgorithm::None,
            }
        }
    }
    
    /// Decompress to text
    pub fn decompress_text(&self) -> Result<String, &'static str> {
        let bytes = match self.algorithm {
            CompressionAlgorithm::None => self.data.clone(),
            CompressionAlgorithm::RunLength => Self::run_length_decode(&self.data)?,
            CompressionAlgorithm::Basic => return Err("Basic compression not implemented"),
        };
        
        String::from_utf8(bytes).map_err(|_| "Invalid UTF-8")
    }
    
    /// Decompress to float vector
    pub fn decompress_float_vec(&self) -> Result<Vec<f32>, &'static str> {
        let bytes = match self.algorithm {
            CompressionAlgorithm::None => self.data.clone(),
            CompressionAlgorithm::RunLength => Self::run_length_decode(&self.data)?,
            CompressionAlgorithm::Basic => return Err("Basic compression not implemented"),
        };
        
        if bytes.len() % std::mem::size_of::<f32>() != 0 {
            return Err("Invalid float vector data");
        }
        
        let float_count = bytes.len() / std::mem::size_of::<f32>();
        let mut result = Vec::with_capacity(float_count);
        
        unsafe {
            let float_ptr = bytes.as_ptr() as *const f32;
            for i in 0..float_count {
                result.push(*float_ptr.add(i));
            }
        }
        
        Ok(result)
    }
    
    /// Simple run-length encoding
    fn run_length_encode(input: &[u8]) -> Vec<u8> {
        if input.is_empty() {
            return Vec::new();
        }
        
        let mut result = Vec::new();
        let mut current_byte = input[0];
        let mut count = 1u8;
        
        for &byte in &input[1..] {
            if byte == current_byte && count < 255 {
                count += 1;
            } else {
                result.push(count);
                result.push(current_byte);
                current_byte = byte;
                count = 1;
            }
        }
        
        // Add final run
        result.push(count);
        result.push(current_byte);
        
        result
    }
    
    /// Decode run-length encoded data
    fn run_length_decode(input: &[u8]) -> Result<Vec<u8>, &'static str> {
        if input.len() % 2 != 0 {
            return Err("Invalid run-length encoded data");
        }
        
        let mut result = Vec::new();
        
        for chunk in input.chunks_exact(2) {
            let count = chunk[0];
            let byte = chunk[1];
            
            for _ in 0..count {
                result.push(byte);
            }
        }
        
        Ok(result)
    }
    
    /// Get compression ratio (compressed_size / original_size)
    pub fn compression_ratio(&self) -> f32 {
        if self.original_size == 0 {
            return 1.0;
        }
        self.data.len() as f32 / self.original_size as f32
    }
    
    /// Get memory usage in bytes
    pub fn memory_size(&self) -> usize {
        std::mem::size_of::<Self>() + self.data.capacity()
    }
}

impl Hash for CompactString {
    fn hash<H: Hasher>(&self, state: &mut H) {
        self.as_str().hash(state);
    }
}

impl AttrValue {
    /// Get runtime type information as string
    pub fn type_name(&self) -> &'static str {
        match self {
            AttrValue::Float(_) => "Float",
            AttrValue::Int(_) => "Int", 
            AttrValue::Text(_) => "Text",
            AttrValue::FloatVec(_) => "FloatVec",
            AttrValue::Bool(_) => "Bool",
            AttrValue::CompactText(_) => "CompactText",
            AttrValue::SmallInt(_) => "SmallInt",
            AttrValue::Bytes(_) => "Bytes",
            AttrValue::CompressedText(_) => "CompressedText",
            AttrValue::CompressedFloatVec(_) => "CompressedFloatVec",
        }
    }
    
    /// Calculate memory usage in bytes (Memory Optimization 1)
    pub fn memory_size(&self) -> usize {
        match self {
            AttrValue::Float(_) => std::mem::size_of::<f32>(),
            AttrValue::Int(_) => std::mem::size_of::<i64>(),
            AttrValue::Text(s) => std::mem::size_of::<String>() + s.capacity(),
            AttrValue::FloatVec(v) => std::mem::size_of::<Vec<f32>>() + v.capacity() * std::mem::size_of::<f32>(),
            AttrValue::Bool(_) => std::mem::size_of::<bool>(),
            AttrValue::CompactText(cs) => cs.memory_size(),
            AttrValue::SmallInt(_) => std::mem::size_of::<i32>(),
            AttrValue::Bytes(b) => std::mem::size_of::<Vec<u8>>() + b.capacity(),
            AttrValue::CompressedText(cd) => cd.memory_size(),
            AttrValue::CompressedFloatVec(cd) => cd.memory_size(),
        }
    }
    
    /// Check if this value can be stored more efficiently as a compact variant
    pub fn can_optimize(&self) -> bool {
        match self {
            AttrValue::Text(s) if s.len() <= 15 => true,
            AttrValue::Text(s) if s.len() > 100 => true, // Can compress large text
            AttrValue::Int(i) if *i >= i32::MIN as i64 && *i <= i32::MAX as i64 => true,
            AttrValue::FloatVec(v) if v.len() > 25 => true, // Can compress large vectors
            _ => false,
        }
    }
    
    /// Convert to a more memory-efficient variant if possible (Memory Optimization 1 & 3)
    pub fn optimize(self) -> Self {
        match self {
            AttrValue::Text(s) if s.len() <= 15 => {
                AttrValue::CompactText(CompactString::new(&s))
            }
            AttrValue::Text(s) if s.len() > 100 => {
                AttrValue::CompressedText(CompressedData::compress_text(&s))
            }
            AttrValue::Int(i) if i >= i32::MIN as i64 && i <= i32::MAX as i64 => {
                AttrValue::SmallInt(i as i32)
            }
            AttrValue::FloatVec(v) if v.len() > 25 => {
                AttrValue::CompressedFloatVec(CompressedData::compress_float_vec(&v))
            }
            other => other,
        }
    }
    
    /// Try to convert to specific type with error handling
    pub fn as_float(&self) -> Option<f32> {
        match self {
            AttrValue::Float(f) => Some(*f),
            _ => None,
        }
    }
    
    pub fn as_int(&self) -> Option<i64> {
        match self {
            AttrValue::Int(i) => Some(*i),
            AttrValue::SmallInt(i) => Some(*i as i64),
            _ => None,
        }
    }
    
    pub fn as_text(&self) -> Option<&str> {
        match self {
            AttrValue::Text(s) => Some(s),
            AttrValue::CompactText(cs) => Some(cs.as_str()),
            // Note: Compressed text requires decompression, so we can't return &str
            _ => None,
        }
    }
    
    /// Get text content, decompressing if necessary
    pub fn get_text(&self) -> Option<String> {
        match self {
            AttrValue::Text(s) => Some(s.clone()),
            AttrValue::CompactText(cs) => Some(cs.as_str().to_string()),
            AttrValue::CompressedText(cd) => cd.decompress_text().ok(),
            _ => None,
        }
    }
    
    pub fn as_float_vec(&self) -> Option<&[f32]> {
        match self {
            AttrValue::FloatVec(v) => Some(v),
            // Note: Compressed vectors require decompression, so we can't return &[f32]
            _ => None,
        }
    }
    
    /// Get float vector content, decompressing if necessary
    pub fn get_float_vec(&self) -> Option<Vec<f32>> {
        match self {
            AttrValue::FloatVec(v) => Some(v.clone()),
            AttrValue::CompressedFloatVec(cd) => cd.decompress_float_vec().ok(),
            _ => None,
        }
    }
    
    pub fn as_bool(&self) -> Option<bool> {
        match self {
            AttrValue::Bool(b) => Some(*b),
            _ => None,
        }
    }
    
    pub fn as_bytes(&self) -> Option<&[u8]> {
        match self {
            AttrValue::Bytes(b) => Some(b),
            _ => None,
        }
    }
}

/// Memory usage statistics (Memory Optimization 4)
#[derive(Debug, Clone)]
pub struct MemoryStatistics {
    /// Pool memory usage in bytes
    pub pool_memory_bytes: usize,
    /// Space memory usage in bytes
    pub space_memory_bytes: usize,
    /// History memory usage in bytes
    pub history_memory_bytes: usize,
    /// Change tracker memory usage in bytes
    pub change_tracker_memory_bytes: usize,
    /// Total memory usage in bytes
    pub total_memory_bytes: usize,
    /// Total memory usage in megabytes
    pub total_memory_mb: f64,
    /// Memory efficiency metrics
    pub memory_efficiency: MemoryEfficiency,
    /// Compression statistics
    pub compression_stats: CompressionStatistics,
}

/// Memory efficiency metrics
#[derive(Debug, Clone)]
pub struct MemoryEfficiency {
    /// Average bytes per node
    pub bytes_per_node: f64,
    /// Average bytes per edge
    pub bytes_per_edge: f64,
    /// Average bytes per entity (node or edge)
    pub bytes_per_entity: f64,
    /// Memory overhead ratio
    pub overhead_ratio: f64,
    /// Cache efficiency (0.0 to 1.0)
    pub cache_efficiency: f64,
}

/// Data compression statistics
#[derive(Debug, Clone)]
pub struct CompressionStatistics {
    /// Number of compressed attributes
    pub compressed_attributes: usize,
    /// Total number of attributes
    pub total_attributes: usize,
    /// Average compression ratio
    pub average_compression_ratio: f32,
    /// Memory saved through compression in bytes
    pub memory_saved_bytes: usize,
    /// Memory saved as percentage
    pub memory_saved_percentage: f64,
}


--- FILE: util.rs ---
//! Utility Functions and Helpers - Common operations used across modules.
//!
//! ARCHITECTURE ROLE:
//! This module provides shared functionality that's used by multiple 
//! components throughout the system. It contains performance-critical
//! operations and commonly needed data structure manipulations.
//!
//! DESIGN PHILOSOPHY:
//! - Pure functions with no side effects
//! - Performance-optimized implementations
//! - Well-tested building blocks
//! - Zero-allocation where possible

/*
=== UTILITY MODULE OVERVIEW ===

This module provides fundamental operations that are used throughout
the codebase. Categories include:

1. HASHING: Content addressing and deduplication
2. SORTING: Efficient operations on sorted data structures  
3. TIME: Timestamp generation and manipulation
4. VALIDATION: Data consistency checks
5. CONVERSION: Type conversions and data transformations

KEY DESIGN DECISIONS:
- Favor performance over generality (these are hot paths)
- Use const generics and zero-cost abstractions where possible
- Provide both safe and unsafe variants for performance-critical code
- Extensive testing for correctness
*/

use std::collections::hash_map::DefaultHasher;
use std::hash::{Hash, Hasher};
use crate::types::AttrValue;

/*
=== CONTENT ADDRESSING AND HASHING ===
Functions for generating content hashes and deduplication
*/

/// Generate a 256-bit content hash for deduplication and verification
/// 
/// ALGORITHM:
/// 1. Use DefaultHasher to generate u64 hash of input data
/// 2. Expand to 256-bit by repeating the 64-bit hash
/// 3. This provides good distribution while being fast
/// 
/// PERFORMANCE: O(size of data), very fast hashing
/// COLLISION RESISTANCE: Good for practical purposes, not cryptographic
pub fn content_hash<T: Hash>(data: &T) -> [u8; 32] {
    let mut hasher = DefaultHasher::new();
    data.hash(&mut hasher);
    let hash_u64 = hasher.finish();
    
    // Expand 64-bit hash to 256-bit for better distribution
    let mut result = [0u8; 32];
    let bytes = hash_u64.to_le_bytes();
    
    // Repeat the 8-byte pattern 4 times
    for chunk in result.chunks_mut(8) {
        chunk.copy_from_slice(&bytes);
    }
    
    result
}

/// Fast hash function optimized specifically for attribute values
/// 
/// OPTIMIZATION: This can be faster than generic hashing because
/// we know the structure of AttrValue and can optimize accordingly
pub fn attr_value_hash(value: &AttrValue) -> u64 {
    match value {
        AttrValue::Int(i) => {
            // Fast path for integers - just use the value directly
            *i as u64
        },
        AttrValue::Float(f) => {
            // Convert float to bits for consistent hashing
            f.to_bits() as u64
        },
        AttrValue::Bool(b) => {
            // Simple hash for booleans
            if *b { 1 } else { 0 }
        },
        AttrValue::Text(s) => {
            // Use standard string hashing
            let mut hasher = DefaultHasher::new();
            s.hash(&mut hasher);
            hasher.finish()
        },
        AttrValue::FloatVec(v) => {
            // Hash vector by combining element hashes
            let mut hasher = DefaultHasher::new();
            for &element in v {
                element.to_bits().hash(&mut hasher);
            }
            hasher.finish()
        },
        AttrValue::CompactText(cs) => {
            // Hash compact string using its string content
            let mut hasher = DefaultHasher::new();
            cs.as_str().hash(&mut hasher);
            hasher.finish()
        },
        AttrValue::SmallInt(i) => {
            // Fast path for small integers
            *i as u64
        },
        AttrValue::Bytes(b) => {
            // Hash byte array
            let mut hasher = DefaultHasher::new();
            b.hash(&mut hasher);
            hasher.finish()
        },
        AttrValue::CompressedText(cd) => {
            // Hash compressed data
            let mut hasher = DefaultHasher::new();
            cd.data.hash(&mut hasher);
            hasher.finish()
        },
        AttrValue::CompressedFloatVec(cd) => {
            // Hash compressed vector data
            let mut hasher = DefaultHasher::new();
            cd.data.hash(&mut hasher);
            hasher.finish()
        },
    }
}

/// Merge two sorted vectors while maintaining order and removing duplicates
/// 
/// ALGORITHM:
/// 1. Two-pointer technique to merge in O(n + m) time
/// 2. Skip duplicates during merge to ensure uniqueness
/// 3. Pre-allocate result vector for efficiency
/// 
/// PERFORMANCE: O(n + m) time, O(n + m) space
/// USE CASES: Merging index lists, combining sorted query results
pub fn merge_sorted_indices(a: &[usize], b: &[usize]) -> Vec<usize> {
    let mut result = Vec::with_capacity(a.len() + b.len());
    let mut i = 0;
    let mut j = 0;
    
    while i < a.len() && j < b.len() {
        if a[i] < b[j] {
            result.push(a[i]);
            i += 1;
        } else if a[i] > b[j] {
            result.push(b[j]);
            j += 1;
        } else {
            // Equal values - only add once
            result.push(a[i]);
            i += 1;
            j += 1;
        }
    }
    
    // Add remaining elements
    result.extend_from_slice(&a[i..]);
    result.extend_from_slice(&b[j..]);
    
    result
}

/// Find insertion point in sorted vector using binary search
/// 
/// RETURNS: Index where value should be inserted to maintain sorted order
/// If value already exists, returns the index of the existing element
pub fn binary_search_insert_point(vec: &[usize], value: usize) -> usize {
    match vec.binary_search(&value) {
        Ok(pos) => pos,      // Found - return existing position
        Err(pos) => pos,     // Not found - return insertion position
    }
}

/// Check if two attribute values are type-compatible
/// 
/// USAGE: Before updating an attribute, check if the new value
/// is compatible with the existing type
pub fn validate_attr_compatibility(existing: &AttrValue, new: &AttrValue) -> bool {
    // Use discriminant comparison to check if they're the same variant
    std::mem::discriminant(existing) == std::mem::discriminant(new)
}

/// Generate a Unix timestamp for the current time
/// 
/// PRECISION: Seconds since Unix epoch
/// FALLBACK: Returns 0 if system time is unavailable
pub fn timestamp_now() -> u64 {
    std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .map(|d| d.as_secs())
        .unwrap_or(0)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_merge_sorted_indices() {
        let a = vec![1, 3, 5];
        let b = vec![2, 4, 6];
        let result = merge_sorted_indices(&a, &b);
        assert_eq!(result, vec![1, 2, 3, 4, 5, 6]);
    }

    #[test]
    fn test_merge_with_duplicates() {
        let a = vec![1, 3, 5];
        let b = vec![3, 4, 5];
        let result = merge_sorted_indices(&a, &b);
        assert_eq!(result, vec![1, 3, 4, 5]);
    }
}


--- FILE: config.rs ---
//! Configuration Management System - Central settings and performance tuning.
//!
//! ARCHITECTURE ROLE:
//! This module provides centralized configuration for all system components.
//! It handles performance tuning, memory management, and feature toggles.
//!
//! DESIGN PHILOSOPHY:
//! - Single source of truth for all configuration
//! - Environment-aware defaults (production vs development)
//! - Runtime configuration validation
//! - Performance profile presets for common use cases

/*
=== CONFIGURATION SYSTEM OVERVIEW ===

The configuration system provides:
1. PERFORMANCE TUNING: Memory limits, cache sizes, optimization levels
2. FEATURE TOGGLES: Enable/disable optional features
3. OPERATIONAL SETTINGS: Logging levels, monitoring, debugging
4. STORAGE CONFIGURATION: Persistence, compression, backup settings

KEY DESIGN DECISIONS:
- Immutable configuration objects (changes require restart)
- Validation at creation time to catch errors early
- Profile-based presets for common scenarios
- Environment variable overrides for deployment flexibility
*/

use crate::core::strategies::StorageStrategyType;
use crate::types::GraphType;

/// The main configuration structure for the entire graph system
/// 
/// RESPONSIBILITIES:
/// - Define all configurable parameters in one place
/// - Provide validation for configuration values
/// - Support different performance profiles
/// - Enable/disable features consistently across components
/// 
/// CONFIGURATION CATEGORIES:
/// - Temporal Storage: Strategy selection for different workloads
/// - Memory Management: Limits, garbage collection thresholds
/// - Performance Tuning: Cache sizes, optimization levels
/// - History System: Snapshot frequency, retention policies
/// - Query Engine: Cache settings, timeout limits
/// - Storage: Compression, persistence, backup settings
#[derive(Debug, Clone)]
pub struct GraphConfig {
    /*
    === GRAPH STRUCTURE ===
    Fundamental graph properties that affect the entire system
    */
    
    /// Graph directionality - affects adjacency, traversal, and matrix operations
    /// DESIGN: This is the most fundamental property and affects all other operations
    pub graph_type: GraphType,
    
    /*
    === MEMORY MANAGEMENT ===
    Control memory usage across all components
    */
    
    /// Maximum total memory usage before triggering cleanup (bytes)
    /// When this limit is approached, the system will:
    /// 1. Clear query caches
    /// 2. Trigger garbage collection
    /// 3. Compress old history data
    pub max_memory_usage: usize,
    
    /// Memory threshold for starting proactive cleanup (percentage of max)
    /// Example: 80 means start cleanup when at 80% of max_memory_usage
    pub memory_pressure_threshold: u8,
    
    /// Enable automatic garbage collection of unreachable history
    pub enable_auto_gc: bool,
    
    /// How often to run garbage collection (in commits)
    pub gc_frequency: u32,
    
    /*
    === TEMPORAL STORAGE STRATEGY ===
    Configuration for different temporal storage approaches
    */
    
    /// Which temporal storage strategy to use
    /// Different strategies optimize for different workloads:
    /// - IndexDeltas: Efficient for frequent small changes (default)
    /// - Future: FullSnapshots, Hybrid, Compressed, etc.
    pub temporal_storage_strategy: StorageStrategyType,
    
    /*
    === HISTORY SYSTEM CONFIGURATION ===
    Settings for version control and state management
    */
    
    /// How often to create full snapshots instead of deltas (every N commits)
    /// Snapshots speed up state reconstruction but use more memory
    /// Trade-off: Lower values = faster access, higher memory usage
    pub snapshot_frequency: u32,
    
    /// Maximum length of delta chains before forcing a snapshot
    /// Long chains slow down state reconstruction
    /// This provides a hard limit even if snapshot_frequency hasn't been reached
    pub max_delta_chain: u32,
    
    /// Maximum number of states to keep in history
    /// Older states beyond this limit will be garbage collected
    /// None = unlimited history
    pub max_history_size: Option<usize>,
    
    /// Enable content-based deduplication of deltas
    /// Identical changes across different commits will share storage
    /// Trade-off: Saves memory but adds computational overhead
    pub enable_deduplication: bool,
    
    /*
    === QUERY ENGINE CONFIGURATION ===
    Settings for read-only operations and caching
    */
    
    /// Enable query result caching
    /// Repeated queries will return cached results
    pub enable_query_cache: bool,
    
    /// Maximum memory to use for query result cache (bytes)
    pub query_cache_size: usize,
    
    /// Query timeout in milliseconds
    /// Queries taking longer than this will be cancelled
    pub query_timeout_ms: u64,
    
    /// Maximum number of results to return from a single query
    /// Prevents accidentally loading huge result sets
    pub max_query_results: usize,
    
    /*
    === STORAGE AND PERSISTENCE ===
    Settings for data storage and compression
    */
    
    /// Enable compression of historical deltas
    /// Reduces storage size but adds CPU overhead
    pub enable_compression: bool,
    
    /// Compression level (1-9, higher = better compression, slower)
    pub compression_level: u8,
    
    /// Enable automatic backup of critical data
    pub enable_auto_backup: bool,
    
    /// How often to create backups (in commits)
    pub backup_frequency: u32,
    
    /*
    === PERFORMANCE OPTIMIZATION ===
    Settings for various performance optimizations
    */
    
    /// Enable adjacency list caching for fast neighbor lookups
    /// Trade-off: Faster queries but more memory usage
    pub enable_adjacency_cache: bool,
    
    /// Enable attribute indexing for faster filtered queries
    /// Trade-off: Faster attribute-based queries but more memory
    pub enable_attribute_indexing: bool,
    
    /// Number of worker threads for parallel operations
    /// 0 = auto-detect based on CPU cores
    pub worker_threads: usize,
    
    /// Enable parallel processing where possible
    pub enable_parallel_processing: bool,
    
    /*
    === DEBUGGING AND MONITORING ===
    Settings for development and troubleshooting
    */
    
    /// Enable detailed performance metrics collection
    pub enable_metrics: bool,
    
    /// Enable debug logging (warning: very verbose)
    pub enable_debug_logging: bool,
    
    /// Enable validation checks (slower but catches bugs)
    pub enable_validation: bool,
    
    /// Enable crash recovery mechanisms
    pub enable_crash_recovery: bool,
}

impl GraphConfig {
    /// Create a new configuration with reasonable defaults
    pub fn new() -> Self {
        // TODO: Initialize all other fields with balanced default values
        // For now, create a minimal config with the default strategy
        Self {
            graph_type: GraphType::default(),
            temporal_storage_strategy: StorageStrategyType::default(),
            // TODO: Initialize remaining fields with reasonable defaults
            max_memory_usage: 1024 * 1024 * 1024, // 1GB placeholder
            memory_pressure_threshold: 80,
            enable_auto_gc: true,
            gc_frequency: 100,
            snapshot_frequency: 100,
            max_delta_chain: 50,
            max_history_size: None,
            enable_deduplication: true,
            enable_query_cache: true,
            query_cache_size: 64 * 1024 * 1024, // 64MB
            query_timeout_ms: 30000, // 30 seconds
            max_query_results: 100000,
            enable_compression: false,
            compression_level: 6,
            enable_auto_backup: false,
            backup_frequency: 1000,
            enable_adjacency_cache: true,
            enable_attribute_indexing: true,
            worker_threads: 0, // auto-detect
            enable_parallel_processing: true,
            enable_metrics: false,
            enable_debug_logging: false,
            enable_validation: false,
            enable_crash_recovery: true,
        }
    }
    
    /// Create a configuration optimized for low memory usage
    /// 
    /// USE CASE: Embedded systems, resource-constrained environments
    /// OPTIMIZATIONS:
    /// - Index-based deltas (minimal memory overhead)
    /// - Aggressive garbage collection
    /// - Minimal caching
    /// - High compression
    /// - Frequent snapshots to keep delta chains short
    pub fn memory_optimized() -> Self {
        // TODO: Implement with all fields
        let mut config = Self::new();
        config.temporal_storage_strategy = StorageStrategyType::IndexDeltas; // Most memory efficient
        config
    }
    
    /// Create a configuration optimized for maximum performance
    /// 
    /// USE CASE: High-performance computing, real-time applications
    /// OPTIMIZATIONS:
    /// - Index-based deltas (fastest commits)
    /// - Large memory buffers
    /// - Extensive caching
    /// - No compression
    /// - Parallel processing
    /// - Minimal garbage collection
    pub fn performance_optimized() -> Self {
        // TODO: Implement with all fields
        let mut config = Self::new();
        config.temporal_storage_strategy = StorageStrategyType::IndexDeltas; // Fastest commits
        config
    }
    
    /// Create a configuration optimized for development/debugging
    /// 
    /// USE CASE: Development, testing, debugging
    /// FEATURES:
    /// - Extensive validation
    /// - Debug logging
    /// - Crash recovery
    /// - Metrics collection
    /// - Conservative resource usage
    pub fn development_optimized() -> Self {
        GraphConfig {
            max_memory_usage: 1024 * 1024 * 512, // 512MB
            memory_pressure_threshold: 80,
            enable_auto_gc: true,
            gc_frequency: 100,
            enable_query_cache: true,
            query_cache_size: 1024 * 1024, // 1MB for query cache
            enable_debug_logging: true,
            enable_validation: true,
            enable_metrics: true,
            worker_threads: 2,
            ..Self::default()
        }
    }
    
    /// Create a configuration for production deployment
    /// 
    /// USE CASE: Production systems, stable deployments
    /// FEATURES:
    /// - Index-based deltas (proven and stable)
    /// - Balanced performance and reliability
    /// - Automatic backup and recovery
    /// - Moderate resource usage
    /// - Error handling without debug overhead
    pub fn production_optimized() -> Self {
        // TODO: Implement with all fields
        let mut config = Self::new();
        config.temporal_storage_strategy = StorageStrategyType::IndexDeltas; // Proven and stable
        config
    }
    
    /*
    === CONFIGURATION VALIDATION ===
    Ensure configuration values are reasonable
    */
    
    /// Validate the configuration and return errors if invalid
    pub fn validate(&self) -> Result<(), ConfigError> {
        // Basic validation of critical settings
        if self.max_memory_usage == 0 {
            return Err(ConfigError::InvalidConfiguration {
                setting: "max_memory_usage".to_string(),
                value: "0".to_string(),
                reason: "Memory limit must be greater than 0".to_string(),
                valid_values: vec!["Any positive integer".to_string()],
            });
        }
        
        if self.query_cache_size == 0 && self.enable_query_cache {
            return Err(ConfigError::InvalidConfiguration {
                setting: "query_cache_size".to_string(),
                value: "0".to_string(),
                reason: "Query cache size must be greater than 0 when caching is enabled".to_string(),
                valid_values: vec!["Any positive integer".to_string()],
            });
        }
        
        Ok(())
    }
    
    /// Get the effective number of worker threads
    /// (resolves 0 to actual CPU count)
    pub fn effective_worker_threads(&self) -> usize {
        if self.worker_threads == 0 {
            std::thread::available_parallelism()
                .map(|n| n.get())
                .unwrap_or(1)
        } else {
            self.worker_threads
        }
    }
    
    /// Calculate the memory threshold for triggering cleanup
    pub fn memory_cleanup_threshold(&self) -> usize {
        (self.max_memory_usage * self.memory_pressure_threshold as usize) / 100
    }
    
    /*
    === CONFIGURATION UPDATES ===
    Methods for modifying configuration (returns new instance)
    */
    
    /// Create a new configuration with updated memory limit
    pub fn with_memory_limit(mut self, limit: usize) -> Self {
        self.max_memory_usage = limit;
        self
    }
    
    /// Create a new configuration with updated cache settings
    pub fn with_cache_settings(mut self, enable_query_cache: bool, cache_size: usize) -> Self {
        self.enable_query_cache = enable_query_cache;
        self.query_cache_size = cache_size;
        self
    }
    
    /// Create a new configuration with updated worker thread count
    pub fn with_worker_threads(mut self, threads: usize) -> Self {
        self.worker_threads = threads;
        self
    }
    
    /// Create a new configuration with specific temporal storage strategy
    pub fn with_storage_strategy(mut self, strategy: StorageStrategyType) -> Self {
        self.temporal_storage_strategy = strategy;
        self
    }
    
    /*
    === ENVIRONMENT INTEGRATION ===
    Load configuration from environment variables
    */
    
    /// Load configuration overrides from environment variables
    /// 
    /// SUPPORTED VARIABLES:
    /// - GROGGY_MAX_MEMORY: Maximum memory usage in bytes
    /// - GROGGY_WORKER_THREADS: Number of worker threads
    /// - GROGGY_ENABLE_DEBUG: Enable debug logging (true/false)
    /// - GROGGY_COMPRESSION_LEVEL: Compression level (1-9)
    pub fn from_environment(mut self) -> Self {
        if let Ok(memory) = std::env::var("GROGGY_MAX_MEMORY") {
            if let Ok(bytes) = memory.parse::<usize>() {
                self.max_memory_usage = bytes;
            }
        }
        
        if let Ok(threads) = std::env::var("GROGGY_WORKER_THREADS") {
            if let Ok(count) = threads.parse::<usize>() {
                self.worker_threads = count;
            }
        }
        
        if let Ok(debug) = std::env::var("GROGGY_ENABLE_DEBUG") {
            self.enable_debug_logging = debug.to_lowercase() == "true";
        }
        
        if let Ok(level) = std::env::var("GROGGY_COMPRESSION_LEVEL") {
            if let Ok(compression) = level.parse::<u8>() {
                if compression >= 1 && compression <= 9 {
                    self.compression_level = compression;
                }
            }
        }
        
        self
    }
    
    /// Save current configuration to environment variables
    pub fn to_environment(&self) {
        // TODO: Set environment variables based on current config
        // Useful for passing configuration to child processes
    }
}

impl Default for GraphConfig {
    fn default() -> Self {
        Self::new()
    }
}

/// Errors that can occur during configuration validation
#[derive(Debug, Clone)]
pub enum ConfigError {
    /// Invalid memory limit (too low or too high)
    InvalidMemoryLimit { provided: usize, min: usize, max: usize },
    
    /// Invalid compression level
    InvalidCompressionLevel { provided: u8, min: u8, max: u8 },
    
    /// Invalid thread count
    InvalidThreadCount { provided: usize, max_supported: usize },
    
    /// Invalid percentage value
    InvalidPercentage { field: String, provided: u8 },
    
    /// Incompatible configuration options
    IncompatibleOptions { option1: String, option2: String, reason: String },
    
    /// Invalid configuration setting
    InvalidConfiguration { setting: String, value: String, reason: String, valid_values: Vec<String> },
}

impl std::fmt::Display for ConfigError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            ConfigError::InvalidMemoryLimit { provided, min, max } => {
                write!(f, "Invalid memory limit: {} bytes (must be between {} and {} bytes)", 
                       provided, min, max)
            },
            ConfigError::InvalidCompressionLevel { provided, min, max } => {
                write!(f, "Invalid compression level: {} (must be between {} and {})", 
                       provided, min, max)
            },
            ConfigError::InvalidThreadCount { provided, max_supported } => {
                write!(f, "Invalid thread count: {} (maximum supported: {})", 
                       provided, max_supported)
            },
            ConfigError::InvalidPercentage { field, provided } => {
                write!(f, "Invalid percentage for {}: {}% (must be between 0% and 100%)", 
                       field, provided)
            },
            ConfigError::IncompatibleOptions { option1, option2, reason } => {
                write!(f, "Incompatible configuration: {} and {} cannot both be enabled ({})", 
                       option1, option2, reason)
            },
            ConfigError::InvalidConfiguration { setting, value, reason, valid_values } => {
                write!(f, "Invalid configuration for {}: '{}' - {} (valid values: {})", 
                       setting, value, reason, valid_values.join(", "))
            },
        }
    }
}

impl std::error::Error for ConfigError {}

/*
=== IMPLEMENTATION NOTES ===

CONFIGURATION PHILOSOPHY:
- Immutable configuration objects prevent runtime surprises
- Validation at creation time catches problems early
- Profile-based presets make common configurations easy
- Environment variable overrides support deployment flexibility

PERFORMANCE CONSIDERATIONS:
- Configuration validation should be fast (done once at startup)
- Environment variable reading should be cached
- Profile methods should be const-time operations

EXTENSIBILITY:
- New configuration options can be added without breaking existing code
- Profile methods can be customized for specific deployment scenarios
- Validation can be extended with custom rules

INTEGRATION WITH COMPONENTS:
- All system components should accept &GraphConfig in their constructors
- Components should validate config options they care about
- Components should respect memory limits and other constraints

TESTING STRATEGY:
- Test all profile methods produce valid configurations
- Test environment variable parsing handles edge cases
- Test validation catches all invalid combinations
- Test configuration serialization/deserialization
*/


--- FILE: lib.rs ---
//! Groggy - A Modular Graph Library with Git-like Version Control
//!
//! LIBRARY OVERVIEW:
//! This library provides a comprehensive system for managing graphs with full 
//! history tracking, branching, and versioning capabilities. Think "Git for graphs" 
//! with high-performance columnar storage and advanced query capabilities.
//!
//! CORE ARCHITECTURE:
//! ```text
//!     ┌─────────────────────────────────────────────────────────┐
//!     │                    Graph (Main API)                    │
//!     │              Smart Coordinator & Facade                │
//!     └─────────────────────┬───────────────────────────────────┘
//!                           │
//!           ┌───────────────┼───────────────┐
//!           │               │               │
//!     ┌─────▼─────┐  ┌─────▼─────┐  ┌─────▼─────┐
//!     │GraphStore │  │ History   │  │  Query    │
//!     │(Storage)  │  │ System    │  │ Engine    │
//!     │           │  │(Git-like) │  │(Analysis) │
//!     └───────────┘  └───────────┘  └───────────┘
//! ```
//!
//! KEY DESIGN PRINCIPLES:
//! - **Immutable History**: All changes are preserved, enabling time-travel
//! - **Columnar Storage**: Efficient bulk operations for ML/analytics workloads
//! - **Content Addressing**: Automatic deduplication of identical changes
//! - **Smart Coordination**: Graph facade manages component interactions intelligently
//! - **Zero-Copy Views**: Read historical states without materializing full copies
//!
//! PERFORMANCE CHARACTERISTICS:
//! - Node/Edge Operations: O(1) amortized
//! - Attribute Access: O(1) with columnar storage
//! - History Operations: O(log n) with content addressing
//! - Query Operations: O(n) with optimizations for common patterns
//! - Memory Usage: Delta-compressed with configurable limits
//!
//! USAGE EXAMPLES:
//!
//! ```rust,no_run
//! use groggy::{Graph, AttrValue, GraphConfig};
//!
//! // Create a graph with custom configuration
//! let config = GraphConfig::performance_optimized();
//! let mut graph = Graph::with_config(config);
//!
//! // Build the graph structure
//! let alice = graph.add_node();
//! let bob = graph.add_node();
//! let friendship = graph.add_edge(alice, bob).unwrap();
//!
//! // Set rich attributes
//! graph.set_node_attr(alice, "name", AttrValue::Text("Alice".into())).unwrap();
//! graph.set_node_attr(alice, "age", AttrValue::Int(28)).unwrap();
//! graph.set_edge_attr(friendship, "strength", AttrValue::Float(0.9)).unwrap();
//!
//! // Commit to history with metadata
//! let commit1 = graph.commit("Initial social network", "data_team").unwrap();
//!
//! // Work with branches like Git
//! graph.create_branch("experiment").unwrap();
//! graph.checkout_branch("experiment").unwrap();
//!
//! // Make experimental changes
//! let charlie = graph.add_node();
//! graph.set_node_attr(charlie, "name", AttrValue::Text("Charlie".into())).unwrap();
//!
//! // Advanced querying
//! let adults = graph.find_nodes(|
//!     NodeFilter::Attribute("age", AttributeFilter::GreaterThan(AttrValue::Int(18)))
//! ).unwrap();
//!
//! // Time travel - view the graph at any point in history
//! let historical_view = graph.view_at_commit(commit1).unwrap();
//! assert_eq!(historical_view.node_count(), 2); // Before Charlie was added
//!
//! // Merge branches with conflict resolution
//! graph.checkout_branch("main").unwrap();
//! graph.merge_branch("experiment", "data_team").unwrap();
//! ```
//!
//! ADVANCED FEATURES:
//!
//! ```rust,no_run
//! use groggy::{Graph, GraphQuery, AggregationType};
//!
//! let mut graph = Graph::new();
//! // ... build graph ...
//!
//! // Complex analytical queries
//! let query = GraphQuery::builder()
//!     .find_nodes(NodeFilter::Attribute("type", AttributeFilter::Equals("person")))
//!     .aggregate("age", AggregationType::Average)
//!     .group_by("department")
//!     .limit(100)
//!     .build();
//!
//! let results = graph.execute_query(query).unwrap();
//!
//! // Bulk operations for performance
//! let node_ids = graph.add_nodes(1000); // Add 1000 nodes efficiently
//! graph.set_node_attrs_bulk("initialized", 
//!     node_ids.iter().map(|&id| (id, AttrValue::Bool(true))).collect()
//! ).unwrap();
//!
//! // Graph analytics
//! let degree_dist = graph.degree_distribution().unwrap();
//! let communities = graph.detect_communities().unwrap();
//! let centrality = graph.compute_centrality(CentralityType::Betweenness).unwrap();
//! ```

// Core type definitions
pub mod types;
pub mod config;
pub mod errors;
pub mod util;

// Core graph data structures and components
pub mod core {
    pub mod array;
    pub mod delta;
    pub mod change_tracker;
    pub mod pool;
    pub mod space;
    pub mod query;
    pub mod traversal;
    pub mod history;
    pub mod state;
    pub mod ref_manager;
    pub mod strategies;
    pub mod subgraph;
    pub mod adjacency;
}

// Display formatting
pub mod display;

// Public API
pub mod api {
    pub mod graph;
}

// Re-export commonly used types and the main API
pub use types::{NodeId, EdgeId, AttrName, AttrValue, StateId, BranchName};
pub use config::GraphConfig;
pub use errors::{GraphError, GraphResult};
pub use api::graph::Graph;
pub use core::history::{HistoricalView, ViewSummary, HistoryForest};
// pub use core::query::{
//     AttributeFilter, NumericComparison, StringComparison, MultiCriteria, Criterion,
//     filter_nodes_by_attributes, filter_edges_by_attributes,
//     filter_by_numeric_comparison, filter_by_string_comparison, filter_by_multi_criteria,
// };
pub use core::ref_manager::{RefManager, Branch, BranchInfo, TagInfo};
pub use core::state::{StateObject, StateMetadata};

// Re-export core types for advanced usage
pub use core::delta::{ColumnDelta, DeltaObject};
pub use core::change_tracker::ChangeTracker;
pub use core::pool::GraphPool;
pub use core::space::GraphSpace;
pub use core::adjacency::{AdjacencyMatrix, GraphMatrix, SparseGraphMatrix, MatrixFormat, MatrixType, IndexMapping};
pub use core::array::{GraphArray, StatsSummary};

/// Library version
pub const VERSION: &str = env!("CARGO_PKG_VERSION");

/// Library name
pub const NAME: &str = env!("CARGO_PKG_NAME");

/// Get library information
pub fn info() -> LibraryInfo {
    LibraryInfo {
        name: NAME.to_string(),
        version: VERSION.to_string(),
        description: "A modular graph and history management library".to_string(),
    }
}

/// Library information
#[derive(Debug, Clone)]
pub struct LibraryInfo {
    pub name: String,
    pub version: String,
    pub description: String,
}

impl LibraryInfo {
    /// Get a formatted string representation
    pub fn banner(&self) -> String {
        format!("{} v{} - {}", self.name, self.version, self.description)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_library_info() {
        let info = info();
        assert_eq!(info.name, NAME);
        assert_eq!(info.version, VERSION);
        assert!(!info.banner().is_empty());
    }

    #[test]
    fn test_basic_integration() {
        // Test that all the main components work together
        let mut graph = Graph::new();
        
        // Basic graph operations
        let node1 = graph.add_node();
        let node2 = graph.add_node();
        let edge = graph.add_edge(node1, node2).unwrap();
        
        // Attributes
        graph.set_node_attribute(node1, "name".to_string(), AttrValue::Text("Alice".to_string())).unwrap();
        graph.set_edge_attribute(edge, "weight".to_string(), AttrValue::Float(1.5)).unwrap();
        
        // History
        let state1 = graph.commit("Initial commit".to_string(), "test_user".to_string()).unwrap();
        
        // Branching
        graph.create_branch("test_branch".to_string(), Some("Test branch".to_string())).unwrap();
        graph.checkout_branch(&"test_branch".to_string()).unwrap();
        
        // More changes
        let node3 = graph.add_node();
        graph.set_node_attribute(node3, "value".to_string(), AttrValue::Int(42)).unwrap();
        let state2 = graph.commit("Add node3".to_string(), "test_user".to_string()).unwrap();
        
        // Views
        let view = graph.view_at_state(state1).unwrap();
        assert_eq!(view.state_id(), state1);
        
        // Stats
        let stats = graph.stats();
        assert_eq!(stats.node_count, 3);
        assert_eq!(stats.edge_count, 1);
        assert_eq!(stats.current_branch, "test_branch".to_string());
        
        // Filtering
        use std::collections::HashMap;
        use crate::core::query::AttributeFilter;
        let mut filters = HashMap::new();
        filters.insert("name".to_string(), AttributeFilter::Equals(AttrValue::Text("Alice".to_string())));
        let filtered = graph.filter_nodes(&filters).unwrap();
        assert_eq!(filtered.len(), 1);
        assert_eq!(filtered[0], node1);
        
        // Tags
        graph.create_tag("v1.0".to_string(), Some(state2)).unwrap();
        let tags = graph.list_tags();
        assert_eq!(tags.len(), 1);
        assert_eq!(tags[0].name, "v1.0");
        assert_eq!(tags[0].state_id, state2);
    }

    #[test]
    fn test_error_handling() {
        let mut graph = Graph::new();
        
        // Test invalid operations
        let result = graph.add_edge(999, 1000);
        assert!(result.is_err());
        
        let result = graph.get_node_attribute(999, &"nonexistent".to_string());
        assert!(result.is_err());
        
        let result = graph.checkout_branch(&"nonexistent_branch".to_string());
        assert!(result.is_err());
    }

    #[test]
    fn test_configuration() {
        let config = GraphConfig::default();
        let graph = Graph::with_config(config.clone());
        
        assert_eq!(graph.config().max_states, config.max_states);
        assert_eq!(graph.config().enable_gc, config.enable_gc);
    }
}


--- FILE: errors.rs ---
//! Error handling system for the graph library.
//!
//! DESIGN PHILOSOPHY:
//! - Comprehensive error types that provide actionable information
//! - Context-rich errors that help with debugging
//! - Performance-aware (errors should be cheap to create)
//! - Extensible for future error scenarios

/*
=== ERROR HANDLING STRATEGY ===

This module defines all the ways operations can fail in the graph system.
Good error handling is critical for:

1. Debugging - Users need to understand what went wrong
2. Recovery - Some errors can be handled programmatically
3. User Experience - Clear error messages improve usability
4. System Reliability - Proper error handling prevents crashes

DESIGN DECISIONS:
- Use Result<T, GraphError> for all fallible operations
- Provide detailed context in error messages
- Include suggested recovery actions where possible
- Separate user errors from system/internal errors
*/

use std::collections::HashMap;
use crate::types::{NodeId, EdgeId, StateId, BranchName, AttrName};

/// The main error type for all graph operations
/// 
/// DESIGN: Use an enum to represent all possible error conditions.
/// Each variant includes relevant context and should provide actionable information.
#[derive(Debug, Clone, PartialEq)]
pub enum GraphError {
    /*
    === ENTITY NOT FOUND ERRORS ===
    The most common errors - trying to operate on non-existent entities
    */
    
    /// Attempted to operate on a node that doesn't exist
    NodeNotFound {
        node_id: NodeId,
        operation: String,
        suggestion: String,
    },
    
    /// Attempted to operate on an edge that doesn't exist
    EdgeNotFound {
        edge_id: EdgeId,
        operation: String,
        suggestion: String,
    },
    
    /// Attempted to operate on a state that doesn't exist in history
    StateNotFound {
        state_id: StateId,
        operation: String,
        available_states: Vec<StateId>,
    },
    
    /// Attempted to operate on a branch that doesn't exist
    BranchNotFound {
        branch_name: BranchName,
        operation: String,
        available_branches: Vec<BranchName>,
    },
    
    /*
    === INVALID OPERATION ERRORS ===
    Operations that are syntactically valid but semantically invalid
    */
    
    /// Attempted to create an edge with invalid endpoints
    InvalidEdgeEndpoints {
        source: NodeId,
        target: NodeId,
        reason: String,
    },
    
    /// Attempted to perform an operation that requires no uncommitted changes
    UncommittedChanges {
        operation: String,
        change_count: usize,
        suggestion: String,
    },
    
    /// Attempted to create a branch that already exists
    BranchAlreadyExists {
        branch_name: BranchName,
        existing_head: StateId,
    },
    
    /// Attempted to delete a branch that is currently checked out
    CannotDeleteCurrentBranch {
        branch_name: BranchName,
    },
    
    /// Attempted an operation on an empty graph that requires data
    EmptyGraph {
        operation: String,
    },
    
    /*
    === ATTRIBUTE ERRORS ===
    Problems with attribute operations
    */
    
    /// Attempted to access an attribute that doesn't exist
    AttributeNotFound {
        entity_type: EntityType,
        entity_id: u64,
        attribute_name: AttrName,
        available_attributes: Vec<AttrName>,
    },
    
    /// Attempted to set an attribute with an incompatible type
    AttributeTypeMismatch {
        entity_type: EntityType,
        entity_id: u64,
        attribute_name: AttrName,
        expected_type: String,
        provided_type: String,
        provided_value: String,
    },
    
    /// Attribute name is invalid (empty, too long, contains invalid characters)
    InvalidAttributeName {
        attribute_name: String,
        reason: String,
    },
    
    /*
    === HISTORY/VERSION CONTROL ERRORS ===
    Problems with commits, branches, and version control
    */
    
    /// Attempted to commit when there are no changes
    NoChangesToCommit,
    
    /// History operation failed due to corrupted state
    CorruptedHistory {
        state_id: StateId,
        corruption_type: String,
        recovery_suggestion: String,
    },
    
    /// Merge operation failed due to conflicts
    MergeConflict {
        conflicts: Vec<MergeConflictDetail>,
        resolution_suggestions: Vec<String>,
    },
    
    /// Attempted to access a state that exists but is unreachable
    UnreachableState {
        state_id: StateId,
        reason: String,
    },
    
    /*
    === CAPACITY/RESOURCE ERRORS ===
    System limits exceeded
    */
    
    /// Too many nodes/edges (implementation limit exceeded)
    CapacityExceeded {
        resource_type: String,
        current_count: usize,
        maximum_allowed: usize,
    },
    
    /// Operation would use too much memory
    MemoryExhausted {
        requested_bytes: usize,
        available_bytes: usize,
        operation: String,
    },
    
    /// History has grown too large
    HistoryTooLarge {
        current_size: usize,
        maximum_size: usize,
        suggestion: String,
    },
    
    /*
    === CONCURRENCY ERRORS ===
    Problems with concurrent access (future use)
    */
    
    /// Another operation is already in progress
    OperationInProgress {
        conflicting_operation: String,
        estimated_completion: Option<u64>,
    },
    
    /// Lock acquisition failed
    LockContentionError {
        resource: String,
        timeout_ms: u64,
    },
    
    /*
    === I/O AND PERSISTENCE ERRORS ===
    File system and serialization problems
    */
    
    /// Failed to read from or write to disk
    IoError {
        operation: String,
        path: String,
        underlying_error: String,
    },
    
    /// Failed to serialize or deserialize data
    SerializationError {
        data_type: String,
        operation: String, // "serialize" or "deserialize"
        underlying_error: String,
    },
    
    /// File format is not supported or corrupted
    InvalidFileFormat {
        path: String,
        expected_format: String,
        detected_format: Option<String>,
    },
    
    /*
    === QUERY ERRORS ===
    Problems with filtering and query operations
    */
    
    /// Query syntax is invalid
    InvalidQuery {
        query: String,
        error_position: Option<usize>,
        error_message: String,
        suggestion: String,
    },
    
    /// Query is valid but cannot be executed efficiently
    QueryTooComplex {
        query: String,
        complexity_score: f64,
        maximum_allowed: f64,
        suggestion: String,
    },
    
    /// Query timed out
    QueryTimeout {
        query: String,
        timeout_ms: u64,
        partial_results: Option<usize>,
    },
    
    /*
    === CONFIGURATION ERRORS ===
    Problems with settings and configuration
    */
    
    /// Configuration value is invalid
    InvalidConfiguration {
        setting: String,
        value: String,
        reason: String,
        valid_values: Vec<String>,
    },
    
    /// General invalid input error  
    InvalidInput(String),
    
    /// Required configuration is missing
    MissingConfiguration {
        setting: String,
        description: String,
    },
    
    /*
    === INTERNAL/SYSTEM ERRORS ===
    Unexpected conditions that indicate bugs
    */
    
    /// An internal invariant was violated (this indicates a bug)
    InternalError {
        message: String,
        location: String,
        context: HashMap<String, String>,
    },
    
    /// Operation not yet implemented
    NotImplemented {
        feature: String,
        tracking_issue: Option<String>,
    },
    
    /// Unexpected state that should never occur
    UnexpectedState {
        expected: String,
        actual: String,
        operation: String,
    },
}

impl GraphError {
    /*
    === ERROR CONSTRUCTION HELPERS ===
    Convenience methods for creating common errors with good context
    */
    
    /// Create a NodeNotFound error with helpful context
    pub fn node_not_found(node_id: NodeId, operation: &str) -> Self {
        Self::NodeNotFound {
            node_id,
            operation: operation.to_string(),
            suggestion: format!("Check that node {} exists before trying to {}", node_id, operation),
        }
    }
    
    /// Create an EdgeNotFound error with helpful context
    pub fn edge_not_found(edge_id: EdgeId, operation: &str) -> Self {
        Self::EdgeNotFound {
            edge_id,
            operation: operation.to_string(),
            suggestion: format!("Check that edge {} exists before trying to {}", edge_id, operation),
        }
    }
    
    /// Create a StateNotFound error with available alternatives
    pub fn state_not_found(state_id: StateId, operation: &str, available: Vec<StateId>) -> Self {
        Self::StateNotFound {
            state_id,
            operation: operation.to_string(),
            available_states: available,
        }
    }
    
    /// Create a BranchNotFound error with available alternatives
    pub fn branch_not_found(branch_name: BranchName, operation: &str, available: Vec<BranchName>) -> Self {
        Self::BranchNotFound {
            branch_name,
            operation: operation.to_string(),
            available_branches: available,
        }
    }
    
    /// Create an UncommittedChanges error with helpful context
    pub fn uncommitted_changes(operation: &str, change_count: usize) -> Self {
        Self::UncommittedChanges {
            operation: operation.to_string(),
            change_count,
            suggestion: "Commit your changes with graph.commit() or reset them with graph.reset_hard()".to_string(),
        }
    }
    
    /// Create an AttributeNotFound error with available alternatives
    pub fn attribute_not_found(
        entity_type: EntityType,
        entity_id: u64,
        attr_name: AttrName,
        available: Vec<AttrName>
    ) -> Self {
        Self::AttributeNotFound {
            entity_type,
            entity_id,
            attribute_name: attr_name,
            available_attributes: available,
        }
    }
    
    /// Create an InternalError for unexpected conditions
    pub fn internal(message: &str, location: &str) -> Self {
        Self::InternalError {
            message: message.to_string(),
            location: location.to_string(),
            context: HashMap::new(),
        }
    }
    
    /// Create an InternalError with additional context
    pub fn internal_with_context(
        message: &str,
        location: &str,
        context: HashMap<String, String>
    ) -> Self {
        Self::InternalError {
            message: message.to_string(),
            location: location.to_string(),
            context,
        }
    }
    
    /*
    === ERROR ANALYSIS METHODS ===
    Methods to help understand and categorize errors
    */
    
    /// Check if this error indicates a user mistake (vs system problem)
    pub fn is_user_error(&self) -> bool {
        match self {
            // User errors - user provided invalid input or tried invalid operation
            GraphError::NodeNotFound { .. } |
            GraphError::EdgeNotFound { .. } |
            GraphError::StateNotFound { .. } |
            GraphError::BranchNotFound { .. } |
            GraphError::InvalidEdgeEndpoints { .. } |
            GraphError::UncommittedChanges { .. } |
            GraphError::BranchAlreadyExists { .. } |
            GraphError::AttributeNotFound { .. } |
            GraphError::AttributeTypeMismatch { .. } |
            GraphError::InvalidAttributeName { .. } |
            GraphError::NoChangesToCommit |
            GraphError::EmptyGraph { .. } |
            GraphError::InvalidQuery { .. } |
            GraphError::InvalidConfiguration { .. } |
            GraphError::InvalidInput(_) => true,
            
            // System errors - something went wrong internally
            GraphError::CorruptedHistory { .. } |
            GraphError::MemoryExhausted { .. } |
            GraphError::IoError { .. } |
            GraphError::SerializationError { .. } |
            GraphError::InternalError { .. } |
            GraphError::UnexpectedState { .. } => false,
            
            // Ambiguous cases - could be either
            _ => false,
        }
    }
    
    /// Check if this error might be recoverable
    pub fn is_recoverable(&self) -> bool {
        match self {
            // Definitely recoverable - user can fix and retry
            GraphError::NodeNotFound { .. } |
            GraphError::EdgeNotFound { .. } |
            GraphError::UncommittedChanges { .. } |
            GraphError::AttributeNotFound { .. } |
            GraphError::NoChangesToCommit |
            GraphError::InvalidQuery { .. } => true,
            
            // Definitely not recoverable - system is in bad state
            GraphError::CorruptedHistory { .. } |
            GraphError::MemoryExhausted { .. } |
            GraphError::InternalError { .. } => false,
            
            // Might be recoverable depending on circumstances
            _ => false,
        }
    }
    
    /// Get the error category for grouping similar errors
    pub fn category(&self) -> ErrorCategory {
        match self {
            GraphError::NodeNotFound { .. } |
            GraphError::EdgeNotFound { .. } |
            GraphError::StateNotFound { .. } |
            GraphError::BranchNotFound { .. } |
            GraphError::AttributeNotFound { .. } => ErrorCategory::NotFound,
            
            GraphError::InvalidEdgeEndpoints { .. } |
            GraphError::InvalidAttributeName { .. } |
            GraphError::InvalidQuery { .. } |
            GraphError::InvalidConfiguration { .. } |
            GraphError::InvalidInput(_) => ErrorCategory::InvalidInput,
            
            GraphError::UncommittedChanges { .. } |
            GraphError::BranchAlreadyExists { .. } |
            GraphError::CannotDeleteCurrentBranch { .. } |
            GraphError::NoChangesToCommit => ErrorCategory::InvalidOperation,
            
            GraphError::CorruptedHistory { .. } |
            GraphError::UnreachableState { .. } => ErrorCategory::DataCorruption,
            
            GraphError::CapacityExceeded { .. } |
            GraphError::MemoryExhausted { .. } |
            GraphError::HistoryTooLarge { .. } => ErrorCategory::ResourceExhausted,
            
            GraphError::IoError { .. } |
            GraphError::SerializationError { .. } |
            GraphError::InvalidFileFormat { .. } => ErrorCategory::Persistence,
            
            GraphError::QueryTimeout { .. } |
            GraphError::QueryTooComplex { .. } => ErrorCategory::Query,
            
            GraphError::OperationInProgress { .. } |
            GraphError::LockContentionError { .. } => ErrorCategory::Concurrency,
            
            GraphError::InternalError { .. } |
            GraphError::UnexpectedState { .. } |
            GraphError::NotImplemented { .. } => ErrorCategory::Internal,
            
            _ => ErrorCategory::Other,
        }
    }
    
    /// Get a short description suitable for logging
    pub fn short_description(&self) -> String {
        match self {
            GraphError::NodeNotFound { node_id, operation, .. } => 
                format!("Node {} not found during {}", node_id, operation),
            GraphError::EdgeNotFound { edge_id, operation, .. } => 
                format!("Edge {} not found during {}", edge_id, operation),
            GraphError::UncommittedChanges { change_count, .. } => 
                format!("{} uncommitted changes", change_count),
            GraphError::InternalError { message, .. } => 
                format!("Internal error: {}", message),
            // TODO: Add cases for other error types
            _ => format!("{:?}", self),
        }
    }
    
    /// Get actionable suggestions for resolving this error
    pub fn suggestions(&self) -> Vec<String> {
        match self {
            GraphError::NodeNotFound { suggestion, .. } |
            GraphError::EdgeNotFound { suggestion, .. } |
            GraphError::UncommittedChanges { suggestion, .. } => vec![suggestion.clone()],
            
            GraphError::StateNotFound { available_states, .. } => {
                if available_states.is_empty() {
                    vec!["No states available in history".to_string()]
                } else {
                    vec![format!("Available states: {:?}", available_states)]
                }
            },
            
            GraphError::BranchNotFound { available_branches, .. } => {
                if available_branches.is_empty() {
                    vec!["No branches available".to_string()]
                } else {
                    vec![format!("Available branches: {:?}", available_branches)]
                }
            },
            
            GraphError::MergeConflict { resolution_suggestions, .. } => 
                resolution_suggestions.clone(),
            
            // TODO: Add suggestions for other error types
            _ => vec![],
        }
    }
}

/*
=== SUPPORTING TYPES ===
*/

/// Categories for grouping similar errors
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum ErrorCategory {
    NotFound,
    InvalidInput,
    InvalidOperation,
    DataCorruption,
    ResourceExhausted,
    Persistence,
    Query,
    Concurrency,
    Internal,
    Other,
}

/// Entity types for error reporting
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum EntityType {
    Node,
    Edge,
    State,
    Branch,
    Attribute,
}

impl std::fmt::Display for EntityType {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            EntityType::Node => write!(f, "node"),
            EntityType::Edge => write!(f, "edge"),
            EntityType::State => write!(f, "state"),
            EntityType::Branch => write!(f, "branch"),
            EntityType::Attribute => write!(f, "attribute"),
        }
    }
}

/// Detailed information about a merge conflict
#[derive(Debug, Clone, PartialEq)]
pub struct MergeConflictDetail {
    pub entity_type: EntityType,
    pub entity_id: u64,
    pub attribute: Option<AttrName>,
    pub our_value: String,
    pub their_value: String,
    pub common_ancestor_value: Option<String>,
}

/*
=== RESULT TYPE ALIAS ===
*/

/// Standard result type for graph operations
/// This saves typing and ensures consistency across the codebase
pub type GraphResult<T> = Result<T, GraphError>;

/*
=== ERROR FORMATTING ===
*/

impl std::fmt::Display for GraphError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            GraphError::NodeNotFound { node_id, operation, suggestion } => {
                write!(f, "Node {} not found while attempting to {}. {}", node_id, operation, suggestion)
            },
            
            GraphError::EdgeNotFound { edge_id, operation, suggestion } => {
                write!(f, "Edge {} not found while attempting to {}. {}", edge_id, operation, suggestion)
            },
            
            GraphError::StateNotFound { state_id, operation, available_states } => {
                write!(f, "State {} not found while attempting to {}. Available states: {:?}", 
                       state_id, operation, available_states)
            },
            
            GraphError::BranchNotFound { branch_name, operation, available_branches } => {
                write!(f, "Branch '{}' not found while attempting to {}. Available branches: {:?}", 
                       branch_name, operation, available_branches)
            },
            
            GraphError::UncommittedChanges { operation, change_count, suggestion } => {
                write!(f, "Cannot {} with {} uncommitted changes. {}", 
                       operation, change_count, suggestion)
            },
            
            GraphError::BranchAlreadyExists { branch_name, existing_head } => {
                write!(f, "Branch '{}' already exists (currently points to state {})", 
                       branch_name, existing_head)
            },
            
            GraphError::AttributeNotFound { entity_type, entity_id, attribute_name, available_attributes } => {
                write!(f, "Attribute '{}' not found on {} {}. Available attributes: {:?}", 
                       attribute_name, entity_type, entity_id, available_attributes)
            },
            
            GraphError::NoChangesToCommit => {
                write!(f, "No changes to commit. Make some modifications first.")
            },
            
            GraphError::InternalError { message, location, context } => {
                write!(f, "Internal error at {}: {}. Context: {:?}", location, message, context)
            },
            
            // TODO: Add display implementations for all error variants
            _ => write!(f, "{:?}", self),
        }
    }
}

impl std::error::Error for GraphError {
    fn source(&self) -> Option<&(dyn std::error::Error + 'static)> {
        // TODO: For errors that wrap other errors (like IoError), return the underlying error
        None
    }
}

/*
=== UTILITY FUNCTIONS ===
*/

/// Convert a standard I/O error to a GraphError
pub fn io_error_to_graph_error(err: std::io::Error, operation: &str, path: &str) -> GraphError {
    GraphError::IoError {
        operation: operation.to_string(),
        path: path.to_string(),
        underlying_error: err.to_string(),
    }
}

/// Create an internal error with file and line information
/// Usage: internal_error!("Something unexpected happened")
#[macro_export]
macro_rules! internal_error {
    ($message:expr) => {
        GraphError::internal($message, &format!("{}:{}", file!(), line!()))
    };
    ($message:expr, $($context_key:expr => $context_value:expr),+) => {
        {
            let mut context = std::collections::HashMap::new();
            $(
                context.insert($context_key.to_string(), $context_value.to_string());
            )+
            GraphError::internal_with_context($message, &format!("{}:{}", file!(), line!()), context)
        }
    };
}

/// Create a user-friendly error result
/// Usage: user_error!(NodeNotFound, node_id, "get neighbors")
#[macro_export]
macro_rules! user_error {
    (NodeNotFound, $node_id:expr, $operation:expr) => {
        Err(GraphError::node_not_found($node_id, $operation))
    };
    (EdgeNotFound, $edge_id:expr, $operation:expr) => {
        Err(GraphError::edge_not_found($edge_id, $operation))
    };
    // TODO: Add macros for other common error types
}

/*
=== IMPLEMENTATION NOTES ===

ERROR DESIGN PRINCIPLES:
1. Every error should provide actionable information
2. Include context about what operation was being attempted
3. Suggest concrete steps for resolution when possible
4. Distinguish between user errors and system errors
5. Make errors easy to match on for programmatic handling

PERFORMANCE CONSIDERATIONS:
- Errors should be cheap to create (avoid expensive string formatting until display)
- Use Cow<str> for strings that might be static
- Consider boxing large error variants to keep Result size small

EXTENSIBILITY:
- Easy to add new error variants without breaking existing code
- Context fields allow adding information without new variants
- Error categories help with high-level error handling

INTEGRATION POINTS:
- All Result types in the codebase should use GraphResult<T>
- Error creation should use the convenience methods when possible
- Logging systems should use short_description() for structured logs
- User interfaces should use Display trait for error messages

TESTING STRATEGY:
- Test that errors contain expected information
- Test error categorization and recovery hints
- Test error formatting for user-friendliness
- Test that internal errors include sufficient debugging context
*/

--- FILE: core/traversal.rs ---
//! Graph Traversal Algorithms - Efficient pathfinding and connectivity analysis.
//!
//! ARCHITECTURE ROLE:
//! This module provides high-performance graph traversal algorithms that leverage
//! the columnar storage and parallel processing capabilities of the graph system.
//!
//! DESIGN PHILOSOPHY:
//! - Performance-first: Use columnar topology access and parallel processing
//! - Memory-efficient: Reuse data structures and avoid unnecessary allocations
//! - Modular: Each algorithm implements common traits for consistency
//! - Configurable: Support filtering, early termination, and custom constraints

use std::collections::{HashMap, HashSet, VecDeque, BinaryHeap};
use std::cmp::Ordering;
use crate::types::{NodeId, EdgeId, AttrName, AttrValue};
use crate::core::pool::GraphPool;
use crate::core::space::GraphSpace;
use crate::core::query::{NodeFilter, EdgeFilter, QueryEngine};
use crate::errors::GraphResult;
// use rayon::prelude::*; // TODO: Re-enable when parallel traversal is implemented

/// High-performance graph traversal engine
/// 
/// RESPONSIBILITIES:
/// - Execute BFS, DFS, and shortest path algorithms
/// - Find connected components and analyze connectivity
/// - Support filtered traversals and early termination
/// - Provide parallel implementations for large graphs
/// 
/// NOT RESPONSIBLE FOR:
/// - Graph modification (read-only operations)
/// - Query result caching (that's QueryEngine's job)
/// - Attribute management (that's GraphPool's job)
#[derive(Debug)]
pub struct TraversalEngine {
    /// Reusable state to avoid allocations
    state_pool: TraversalStatePool,
    
    /// Performance configuration
    #[allow(dead_code)] // TODO: Implement configuration system
    config: TraversalConfig,
    
    /// Statistics tracking
    stats: TraversalStats,
    
    /// Query engine for bulk filtering operations
    query_engine: QueryEngine,
}

/// Adjacency list cache for fast neighbor lookups
#[derive(Debug, Clone)]
pub struct AdjacencyCache {
    /// Map from node_id to list of (neighbor, edge_id)
    adjacency_map: HashMap<NodeId, Vec<(NodeId, EdgeId)>>,
    /// Whether the cache is valid
    is_valid: bool,
    /// Cache generation (for invalidation)
    generation: usize,
}

impl AdjacencyCache {
    pub fn new() -> Self {
        Self {
            adjacency_map: HashMap::new(),
            is_valid: false,
            generation: 0,
        }
    }
    
    /// Build adjacency cache from columnar topology
    pub fn rebuild(&mut self, edge_ids: &[EdgeId], sources: &[NodeId], targets: &[NodeId], topology_generation: usize) {
        self.adjacency_map.clear();
        
        for i in 0..sources.len() {
            let source = sources[i];
            let target = targets[i];
            let edge_id = edge_ids[i];
            
            // Add both directions for undirected edges
            self.adjacency_map.entry(source)
                .or_insert_with(Vec::new)
                .push((target, edge_id));
                
            self.adjacency_map.entry(target)
                .or_insert_with(Vec::new)
                .push((source, edge_id));
        }
        
        self.is_valid = true;
        self.generation = topology_generation;  // Set to current topology generation
    }
    
    /// Get neighbors for a node using the cache
    pub fn get_neighbors(&self, node_id: NodeId) -> Option<&Vec<(NodeId, EdgeId)>> {
        if self.is_valid {
            self.adjacency_map.get(&node_id)
        } else {
            None
        }
    }
    
    /// Check if cache is up to date with topology generation
    pub fn is_up_to_date(&self, topology_generation: usize) -> bool {
        self.is_valid && self.generation == topology_generation
    }
    
    /// Invalidate the cache
    pub fn invalidate(&mut self) {
        self.is_valid = false;
    }
}

/// Filter result cache for avoiding repeated evaluations
#[derive(Debug)]
pub struct FilterCache {
    cache: HashMap<(NodeId, String), bool>,
    max_size: usize,
}

impl FilterCache {
    pub fn new(max_size: usize) -> Self {
        Self {
            cache: HashMap::with_capacity(max_size),
            max_size,
        }
    }
    
    pub fn get(&self, node_id: NodeId, filter_key: &str) -> Option<bool> {
        self.cache.get(&(node_id, filter_key.to_string())).copied()
    }
    
    pub fn insert(&mut self, node_id: NodeId, filter_key: String, result: bool) {
        if self.cache.len() >= self.max_size {
            // Simple LRU: clear half the cache
            let to_remove: Vec<_> = self.cache.keys().take(self.max_size / 2).cloned().collect();
            for key in to_remove {
                self.cache.remove(&key);
            }
        }
        
        self.cache.insert((node_id, filter_key), result);
    }
    
    pub fn clear(&mut self) {
        self.cache.clear();
    }
}

impl TraversalEngine {
    /// Create a new traversal engine with default configuration
    pub fn new() -> Self {
        Self {
            state_pool: TraversalStatePool::new(),
            config: TraversalConfig::default(),
            stats: TraversalStats::new(),
            query_engine: QueryEngine::new(),
        }
    }
    
    /// Create traversal engine with custom configuration
    pub fn with_config(config: TraversalConfig) -> Self {
        Self {
            state_pool: TraversalStatePool::new(),
            config,
            stats: TraversalStats::new(),
            query_engine: QueryEngine::new(),
        }
    }
    
    /*
    === BASIC TRAVERSAL ALGORITHMS ===
    Core BFS and DFS implementations with filtering support
    */
    
    /// Breadth-First Search from a starting node
    /// 
    /// PERFORMANCE: O(V + E) with cached adjacency map - FAST!
    /// FEATURES: Early termination, filtering, minimal overhead
    pub fn bfs(
        &mut self,
        pool: &GraphPool,
        space: &GraphSpace, // Changed to &GraphSpace (no longer mutable)
        start: NodeId,
        options: TraversalOptions
    ) -> GraphResult<TraversalResult> {
        let start_time = std::time::Instant::now();
        
        // Get fresh snapshot with guaranteed consistent adjacency data
        let (_, _, _, neighbors) = space.snapshot(pool);
        
        // 🚀 PERFORMANCE: Use Arc reference directly - no O(E) clone needed!
        // The Arc allows zero-copy sharing of the adjacency map
        
        // 🚀 PERFORMANCE: Skip bulk pre-filtering - filter nodes individually during traversal
        // This is much faster for sparse traversals that only visit a small subset of nodes
        
        let mut visited = HashSet::new();
        let mut queue = VecDeque::new();
        let mut result_nodes = Vec::new();
        let mut result_edges = Vec::new();
        let mut levels = HashMap::new();
        
        // Initialize BFS
        queue.push_back((start, 0)); // (node_id, level)
        visited.insert(start);
        levels.insert(start, 0);
        
        let mut max_depth = 0;
        
        while let Some((current_node, level)) = queue.pop_front() {
            // Check termination conditions - skip nodes beyond max depth
            if let Some(max_depth_limit) = options.max_depth {
                if level > max_depth_limit {
                    continue;
                }
            }
            
            if let Some(max_nodes) = options.max_nodes {
                if result_nodes.len() >= max_nodes {
                    break;
                }
            }
            
            result_nodes.push(current_node);
            max_depth = max_depth.max(level);
            
            // Find neighbors using fresh adjacency map - O(1) lookup, O(degree) iteration - FAST!
            if let Some(node_neighbors) = neighbors.get(&current_node) {
                // Check if we can still explore deeper before processing neighbors
                let next_level = level + 1;
                let can_explore_deeper = match options.max_depth {
                    Some(max_depth_limit) => next_level <= max_depth_limit,
                    None => true,
                };
                
                if can_explore_deeper {
                    for &(neighbor, edge_id) in node_neighbors {
                        if !visited.contains(&neighbor) {
                            // 🚀 FAST: Individual node filtering - only check nodes we actually encounter
                            if self.should_visit_node(pool, space, neighbor, &options)? {
                                visited.insert(neighbor);
                                queue.push_back((neighbor, next_level));
                                result_edges.push(edge_id);
                                levels.insert(neighbor, next_level);
                            }
                        }
                    }
                }
            }
        }
        
        let duration = start_time.elapsed();
        self.stats.record_traversal("bfs".to_string(), result_nodes.len(), duration);
        
        Ok(TraversalResult {
            algorithm: TraversalAlgorithm::BFS,
            nodes: result_nodes,
            edges: result_edges,
            paths: Vec::new(),
            metadata: TraversalMetadata {
                start_node: Some(start),
                end_node: None,
                max_depth,
                nodes_visited: visited.len(),
                execution_time: duration,
                levels: Some(levels),
                discovery_order: None,
            },
        })
    }
    
    /// Depth-First Search from a starting node
    /// 
    /// PERFORMANCE: O(V + E) with cached adjacency map - FAST!
    /// FEATURES: Iterative implementation, minimal overhead
    pub fn dfs(
        &mut self,
        pool: &GraphPool,
        space: &GraphSpace, // Changed to &GraphSpace (no longer mutable)
        start: NodeId,
        options: TraversalOptions
    ) -> GraphResult<TraversalResult> {
        let start_time = std::time::Instant::now();
        
        // Get fresh snapshot with guaranteed consistent adjacency data
        let (_, _, _, neighbors) = space.snapshot(pool);
        
        // 🚀 PERFORMANCE: Use Arc reference directly - no O(E) clone needed!
        // The Arc allows zero-copy sharing of the adjacency map
        
        // 🚀 PERFORMANCE: Skip bulk pre-filtering - filter nodes individually during traversal
        // This is much faster for sparse traversals that only visit a small subset of nodes
        
        let mut visited = HashSet::new();
        let mut stack = Vec::new();
        let mut result_nodes = Vec::new();
        let mut result_edges = Vec::new();
        let mut edge_set = HashSet::new(); // O(1) duplicate check instead of O(n)
        let mut discovery_order = HashMap::new();
        let mut discovery_count = 0;
        
        // Initialize DFS with depth tracking
        stack.push((start, 0)); // (node, depth)
        
        while let Some((current_node, depth)) = stack.pop() {
            if !visited.contains(&current_node) {
                // Check depth limit before processing
                if let Some(max_depth_limit) = options.max_depth {
                    if depth > max_depth_limit {
                        continue;
                    }
                }
                
                // 🚀 FAST: Individual node filtering - only check nodes we actually encounter
                if self.should_visit_node(pool, space, current_node, &options)? {
                    visited.insert(current_node);
                    result_nodes.push(current_node);
                    discovery_order.insert(current_node, discovery_count);
                    discovery_count += 1;
                    
                    // Check termination conditions
                    if let Some(max_nodes) = options.max_nodes {
                        if result_nodes.len() >= max_nodes {
                            break;
                        }
                    }
                    
                    // Get neighbors from fresh adjacency map - O(1) lookup - FAST!
                    if let Some(node_neighbors) = neighbors.get(&current_node) {
                        // Check if we can explore deeper
                        let next_depth = depth + 1;
                        let can_explore_deeper = match options.max_depth {
                            Some(max_depth_limit) => next_depth <= max_depth_limit,
                            None => true,
                        };
                        
                        if can_explore_deeper {
                            // Add in reverse order for consistent DFS traversal
                            for &(neighbor, edge_id) in node_neighbors.iter().rev() {
                                if !visited.contains(&neighbor) {
                                    stack.push((neighbor, next_depth));
                                    if edge_set.insert(edge_id) { // O(1) check + insert
                                        result_edges.push(edge_id);
                                    }
                                }
                            }
                        }
                    }
                }
            }
        }
        
        let duration = start_time.elapsed();
        self.stats.record_traversal("dfs".to_string(), result_nodes.len(), duration);
        
        Ok(TraversalResult {
            algorithm: TraversalAlgorithm::DFS,
            nodes: result_nodes,
            edges: result_edges,
            paths: Vec::new(),
            metadata: TraversalMetadata {
                start_node: Some(start),
                end_node: None,
                max_depth: 0, // DFS doesn't track depth easily
                nodes_visited: discovery_count,
                execution_time: duration,
                levels: None,
                discovery_order: Some(discovery_order),
            },
        })
    }
    
    /*
    === PATH FINDING ALGORITHMS ===
    Shortest path and path enumeration algorithms
    */
    
    /// Find shortest path between two nodes using Dijkstra's algorithm
    /// 
    /// PERFORMANCE: O((V + E) log V) with binary heap optimization
    /// FEATURES: Supports edge weights, early termination at target
    pub fn shortest_path(
        &mut self,
        pool: &GraphPool,
        space: &GraphSpace, // Changed to &GraphSpace (no longer mutable)
        start: NodeId,
        end: NodeId,
        options: PathFindingOptions
    ) -> GraphResult<Option<Path>> {
        let start_time = std::time::Instant::now();
        
        let mut state = self.state_pool.get_state();
        state.distances.clear();
        state.predecessors.clear();
        state.visited.clear();
        
        // Priority queue for Dijkstra's algorithm
        let mut heap = BinaryHeap::new();
        
        // Initialize
        state.distances.insert(start, 0.0);
        heap.push(DijkstraNode { id: start, distance: 0.0 });
        
        // Get columnar topology with cache maintenance (make owned copies)
        let (edge_ids_ref, sources_ref, targets_ref, _) = space.snapshot(pool);
        let edge_ids: Vec<EdgeId> = edge_ids_ref.as_ref().clone();
        let sources: Vec<NodeId> = sources_ref.as_ref().clone();
        let targets: Vec<NodeId> = targets_ref.as_ref().clone();
        
        while let Some(DijkstraNode { id: current, distance }) = heap.pop() {
            // Early termination if we reached the target
            if current == end {
                let path = self.reconstruct_path(&state.predecessors, start, end, pool, space)?;
                self.state_pool.return_state(state);
                
                let duration = start_time.elapsed();
                self.stats.record_traversal("shortest_path".to_string(), path.nodes.len(), duration);
                
                return Ok(Some(path));
            }
            
            // Skip if we've found a better path to this node
            if let Some(&current_distance) = state.distances.get(&current) {
                if distance > current_distance {
                    continue;
                }
            }
            
            state.visited.insert(current);
            
            // Explore neighbors directly from topology
            for i in 0..sources.len() {
                let (neighbor, edge_id) = if sources[i] == current {
                    (targets[i], edge_ids[i])
                } else if targets[i] == current {
                    (sources[i], edge_ids[i])
                } else {
                    continue;
                };
                
                if state.visited.contains(&neighbor) {
                    continue;
                }
                
                // Calculate edge weight
                let edge_weight = self.get_edge_weight(pool, space, edge_id, &options.weight_attribute);
                let new_distance = distance + edge_weight;
                
                // Update if we found a shorter path
                if !state.distances.contains_key(&neighbor) || new_distance < state.distances[&neighbor] {
                    state.distances.insert(neighbor, new_distance);
                    state.predecessors.insert(neighbor, current);
                    heap.push(DijkstraNode { id: neighbor, distance: new_distance });
                }
            }
        }
        
        // No path found
        self.state_pool.return_state(state);
        let duration = start_time.elapsed();
        self.stats.record_traversal("shortest_path".to_string(), 0, duration);
        
        Ok(None)
    }
    
    /// Find all simple paths between two nodes (up to maximum length)
    /// 
    /// WARNING: Can be expensive for large graphs or long paths
    pub fn all_paths(
        &mut self,
        pool: &GraphPool,
        space: &GraphSpace, // Changed to &GraphSpace (no longer mutable)
        start: NodeId,
        end: NodeId,
        max_length: usize
    ) -> GraphResult<Vec<Path>> {
        let start_time = std::time::Instant::now();
        
        let mut all_paths = Vec::new();
        let mut current_path = Vec::new();
        let mut visited = HashSet::new();
        
        self.find_all_paths_recursive(
            pool, space, start, end, max_length,
            &mut current_path, &mut visited, &mut all_paths
        )?;
        
        let duration = start_time.elapsed();
        self.stats.record_traversal("all_paths".to_string(), all_paths.len(), duration);
        
        Ok(all_paths)
    }
    
    /*
    === CONNECTIVITY ALGORITHMS ===
    Connected components and connectivity analysis
    */
    
    /// Find all connected components in the graph
    /// 
    /// PERFORMANCE: O(V + E) using optimized BFS with adjacency map
    pub fn connected_components(
        &mut self,
        pool: &GraphPool,
        space: &GraphSpace, // Changed to &GraphSpace (no longer mutable)
        options: TraversalOptions
    ) -> GraphResult<ConnectedComponentsResult> {
        let start_time = std::time::Instant::now();
        
        // 📊 TIMING: Step 1 - Get active nodes
        let step1_start = std::time::Instant::now();
        let active_nodes: Vec<NodeId> = space.get_active_nodes().iter().copied().collect();
        let step1_duration = step1_start.elapsed();
        
        // 📊 TIMING: Step 2 - Build adjacency snapshot
        let step2_start = std::time::Instant::now();
        let (_, _, _, neighbors) = space.snapshot(pool);
        let step2_duration = step2_start.elapsed();
        
        // 🚀 PERFORMANCE: Use Arc reference directly - no O(E) clone needed!
        // The Arc allows zero-copy sharing of the adjacency map
        
        // 📊 TIMING: Step 3 - Initialize data structures
        let step3_start = std::time::Instant::now();
        let mut visited = HashSet::new();
        let mut components = Vec::new();
        let step3_duration = step3_start.elapsed();
        
        // 📊 TIMING: Step 4 - Main component finding loop
        let step4_start = std::time::Instant::now();
        let mut bfs_time = std::time::Duration::ZERO;
        let mut edge_computation_time = std::time::Duration::ZERO;
        let mut component_count = 0;
        
        // 🚀 OPTIMIZATION: Pre-mark nodes with component IDs for O(1) edge validation
        let mut node_component_id: HashMap<NodeId, usize> = HashMap::new();
        
        // BFS for each unvisited node - O(V + E) total
        for &start_node in &active_nodes {
            if !visited.contains(&start_node) {
                // 🚀 FAST: Individual node filtering - only check nodes we actually encounter
                if !self.should_visit_node(pool, space, start_node, &options)? {
                    continue;
                }
                
                // 📊 TIMING: BFS to find component
                let bfs_start = std::time::Instant::now();
                let mut component_nodes = Vec::new();
                let mut queue = VecDeque::new();
                
                queue.push_back(start_node);
                visited.insert(start_node);
                node_component_id.insert(start_node, component_count); // Mark with component ID
                
                while let Some(current) = queue.pop_front() {
                    component_nodes.push(current);
                    
                    // Use fresh adjacency for optimal performance - get (neighbor, edge_id) pairs
                    if let Some(current_neighbors) = neighbors.get(&current) {
                        for &(neighbor, _edge_id) in current_neighbors {
                            if !visited.contains(&neighbor) {
                                // 🚀 FAST: Individual node filtering - only check nodes we actually encounter
                                if self.should_visit_node(pool, space, neighbor, &options)? {
                                    visited.insert(neighbor);
                                    node_component_id.insert(neighbor, component_count); // Mark with component ID
                                    queue.push_back(neighbor);
                                }
                            }
                        }
                    }
                }
                bfs_time += bfs_start.elapsed();
                
                if !component_nodes.is_empty() {
                    // 📊 TIMING: Calculate induced edges for this component
                    let edges_start = std::time::Instant::now();
                    let mut component_edges = Vec::new();
                    let mut edge_set = HashSet::new(); // O(1) duplicate check instead of O(n)
                    
                    // 🚀 OPTIMIZATION: Use O(1) component ID checks instead of O(log n) HashSet lookups
                    // For each node in the component, check its edges
                    for &node in &component_nodes {
                        if let Some(node_neighbors) = neighbors.get(&node) {
                            for &(neighbor, edge_id) in node_neighbors {
                                // Only include edge if both endpoints are in the SAME component
                                // and we haven't already added this edge (avoid duplicates)
                                if let Some(&neighbor_comp_id) = node_component_id.get(&neighbor) {
                                    if neighbor_comp_id == component_count // O(1) check instead of O(log n)
                                        && node < neighbor // Avoid adding same edge twice
                                        && edge_set.insert(edge_id) { // O(1) check + insert
                                        component_edges.push(edge_id);
                                    }
                                }
                            }
                        }
                    }
                    edge_computation_time += edges_start.elapsed();
                    component_count += 1;
                    
                    components.push(ConnectedComponent {
                        nodes: component_nodes.clone(),
                        edges: component_edges,
                        size: component_nodes.len(),
                        root: start_node,
                    });
                }
            }
        }
        
        let step4_duration = step4_start.elapsed();
    
        // 📊 TIMING: Step 5 - Sort components by size
        let step5_start = std::time::Instant::now();
        components.sort_unstable_by(|a, b| b.size.cmp(&a.size));
        let step5_duration = step5_start.elapsed();
        
        let duration = start_time.elapsed();
        self.stats.record_traversal("connected_components".to_string(), components.len(), duration);
        
        let total_components = components.len();
        let largest_component_size = components.iter().map(|c| c.size).max().unwrap_or(0);
        
        Ok(ConnectedComponentsResult {
            components,
            total_components,
            largest_component_size,
            execution_time: duration,
        })
    }
    
    /*
    === HELPER METHODS ===
    Internal utility methods for traversal algorithms
    */

    /// Check if a node should be visited based on traversal options (FAST: individual filtering)
    /// This is much faster than bulk pre-filtering for sparse traversals
    fn should_visit_node(
        &self,
        pool: &GraphPool,
        space: &GraphSpace,
        node_id: NodeId,
        options: &TraversalOptions
    ) -> GraphResult<bool> {
        if let Some(ref filter) = options.node_filter {
            self.should_visit_node_inline(pool, space, node_id, filter)
        } else {
            Ok(true)
        }
    }
    
    /// Inline node filter matching for maximum performance
    fn should_visit_node_inline(
        &self,
        pool: &GraphPool,
        space: &GraphSpace,
        node_id: NodeId,
        filter: &NodeFilter
    ) -> GraphResult<bool> {
        match filter {
            NodeFilter::HasAttribute { name } => {
                Ok(space.get_node_attr_index(node_id, name).is_some())
            }
            NodeFilter::AttributeEquals { name, value } => {
                if let Some(index) = space.get_node_attr_index(node_id, name) {
                    if let Some(attr_value) = pool.get_attr_by_index(name, index, true) {
                        return Ok(attr_value == value);
                    }
                }
                Ok(false)
            }
            NodeFilter::AttributeFilter { name, filter } => {
                if let Some(index) = space.get_node_attr_index(node_id, name) {
                    if let Some(attr_value) = pool.get_attr_by_index(name, index, true) {
                        return Ok(filter.matches(attr_value));
                    }
                }
                Ok(false)
            }
            NodeFilter::And(filters) => {
                for f in filters {
                    if !self.should_visit_node_inline(pool, space, node_id, f)? {
                        return Ok(false);
                    }
                }
                Ok(true)
            }
            NodeFilter::Or(filters) => {
                for f in filters {
                    if self.should_visit_node_inline(pool, space, node_id, f)? {
                        return Ok(true);
                    }
                }
                Ok(false)
            }
            NodeFilter::Not(filter) => {
                Ok(!self.should_visit_node_inline(pool, space, node_id, filter)?)
            }
            _ => Ok(true), // Accept other filter types for now
        }
    }
    
    /// Pre-filter nodes using bulk operations for O(n) performance instead of O(n²)
    /// NOTE: This is slower for sparse traversals - kept for compatibility
    fn get_eligible_nodes(
        &mut self,
        pool: &GraphPool,
        space: &GraphSpace, // Changed to &GraphSpace (no longer mutable)
        candidate_nodes: &[NodeId],
        options: &TraversalOptions
    ) -> GraphResult<HashSet<NodeId>> {
        if let Some(ref filter) = options.node_filter {
            // Use bulk filtering - O(n) instead of O(n²)
            let filtered_nodes = self.query_engine.find_nodes_by_filter_with_space(pool, space, filter)?;
            // Return intersection with candidate nodes - convert filtered to HashSet for O(1) lookups
            let filtered_set: HashSet<NodeId> = filtered_nodes.into_iter().collect();
            Ok(candidate_nodes.iter().copied().filter(|node| filtered_set.contains(node)).collect())
        } else {
            // No filter - all candidates are eligible, direct conversion is faster
            Ok(candidate_nodes.iter().copied().collect())
        }
    }
  
    
    /// Get edge weight for pathfinding algorithms
    fn get_edge_weight(&self, pool: &GraphPool, space: &GraphSpace, edge_id: EdgeId, weight_attr: &Option<AttrName>) -> f64 {
        if let Some(attr_name) = weight_attr {
            // Try to get edge attribute value (using space since pool doesn't have this method)
            if let Some(index) = space.get_edge_attr_index(edge_id, attr_name) {
                if let Some(attr_value) = pool.get_attr_by_index(attr_name, index, false) {
                    match attr_value {
                        AttrValue::Float(f) => *f as f64,
                        AttrValue::Int(i) => *i as f64,
                        _ => 1.0, // Default weight
                    }
                } else {
                    1.0
                }
            } else {
                1.0
            }
        } else {
            1.0 // Default unit weight
        }
    }
    
    /// Reconstruct path from predecessor information
    fn reconstruct_path(
        &self,
        predecessors: &HashMap<NodeId, NodeId>,
        start: NodeId,
        end: NodeId,
        pool: &GraphPool,
        space: &GraphSpace // Changed to &GraphSpace (no longer mutable)
    ) -> GraphResult<Path> {
        let mut path_nodes = Vec::new();
        let mut path_edges = Vec::new();
        let mut current = end;
        let mut total_weight = 0.0;
        
        // Build path backwards
        path_nodes.push(current);
        
        while current != start {
            if let Some(&predecessor) = predecessors.get(&current) {
                path_nodes.push(predecessor);
                
                // Find the edge between predecessor and current
                if let Some(edge_id) = self.find_edge_between(pool, space, predecessor, current)? {
                    path_edges.push(edge_id);
                    total_weight += self.get_edge_weight(pool, space, edge_id, &None);
                }
                
                current = predecessor;
            } else {
                return Err(crate::errors::GraphError::InternalError {
                    message: "Path reconstruction failed - missing predecessor".to_string(),
                    location: "reconstruct_path".to_string(),
                    context: std::collections::HashMap::new(),
                });
            }
        }
        
        // Reverse to get correct order
        path_nodes.reverse();
        path_edges.reverse();
        
        let path_length = path_nodes.len().saturating_sub(1);
        
        Ok(Path {
            nodes: path_nodes,
            edges: path_edges,
            total_weight,
            metadata: PathMetadata {
                algorithm: "shortest_path".to_string(),
                is_simple: true,
                length: path_length,
            },
        })
    }
    
    /// Find edge between two nodes (helper for path reconstruction)
    fn find_edge_between(&self, pool: &GraphPool, space: &GraphSpace, node1: NodeId, node2: NodeId) -> GraphResult<Option<EdgeId>> {
        let (edge_ids, sources, targets, _) = space.snapshot(pool);
        
        for i in 0..sources.len() {
            if (sources[i] == node1 && targets[i] == node2) || 
               (sources[i] == node2 && targets[i] == node1) {
                return Ok(Some(edge_ids[i]));
            }
        }
        
        Ok(None)
    }
    
    /// Recursive helper for finding all paths
    fn find_all_paths_recursive(
        &mut self,
        pool: &GraphPool,
        space: &GraphSpace, // Changed to &GraphSpace (no longer mutable)
        current: NodeId,
        target: NodeId,
        max_length: usize,
        path: &mut Vec<NodeId>,
        visited: &mut HashSet<NodeId>,
        all_paths: &mut Vec<Path>
    ) -> GraphResult<()> {
        if path.len() >= max_length {
            return Ok(());
        }
        
        path.push(current);
        visited.insert(current);
        
        if current == target {
            // Found a path - convert to Path structure
            let path_nodes = path.clone();
            let mut path_edges = Vec::new();
            let mut total_weight = 0.0;
            
            for i in 0..path_nodes.len() - 1 {
                if let Some(edge_id) = self.find_edge_between(pool, space, path_nodes[i], path_nodes[i + 1])? {
                    path_edges.push(edge_id);
                    total_weight += self.get_edge_weight(pool, space, edge_id, &None);
                }
            }
            
            all_paths.push(Path {
                nodes: path_nodes,
                edges: path_edges,
                total_weight,
                metadata: PathMetadata {
                    algorithm: "all_paths".to_string(),
                    is_simple: true,
                    length: path.len() - 1,
                },
            });
        } else {
            // Continue exploring - get topology data
            let (_edge_ids, sources, targets, _) = space.snapshot(pool);
            
            // Collect neighbors first to avoid borrowing conflicts
            let mut neighbors = Vec::new();
            for i in 0..sources.len() {
                if sources[i] == current {
                    neighbors.push(targets[i]);
                } else if targets[i] == current {
                    neighbors.push(sources[i]);
                }
            }
            
            for neighbor in neighbors {
                if !visited.contains(&neighbor) {
                    self.find_all_paths_recursive(pool, space, neighbor, target, max_length, path, visited, all_paths)?;
                }
            }
        }
        
        path.pop();
        visited.remove(&current);
        Ok(())
    }
    
    /// Get traversal statistics
    pub fn statistics(&self) -> &TraversalStats {
        &self.stats
    }
    
    /// Clear performance statistics
    pub fn clear_stats(&mut self) {
        self.stats.clear();
    }
}

/*
=== SUPPORTING DATA STRUCTURES ===
*/

/// Node for Dijkstra's algorithm priority queue
#[derive(Debug, Clone)]
struct DijkstraNode {
    id: NodeId,
    distance: f64,
}

impl PartialEq for DijkstraNode {
    fn eq(&self, other: &Self) -> bool {
        self.distance == other.distance
    }
}

impl Eq for DijkstraNode {}

impl PartialOrd for DijkstraNode {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}

impl Ord for DijkstraNode {
    fn cmp(&self, other: &Self) -> Ordering {
        // Reverse ordering for min-heap behavior
        other.distance.partial_cmp(&self.distance).unwrap_or(Ordering::Equal)
    }
}

/// Reusable state pool to avoid allocations
#[derive(Debug)]
struct TraversalStatePool {
    available_states: Vec<TraversalState>,
}

impl TraversalStatePool {
    fn new() -> Self {
        Self {
            available_states: Vec::new(),
        }
    }
    
    fn get_state(&mut self) -> TraversalState {
        self.available_states.pop().unwrap_or_else(|| TraversalState {
            visited: HashSet::new(),
            queue: VecDeque::new(),
            distances: HashMap::new(),
            predecessors: HashMap::new(),
        })
    }
    
    fn return_state(&mut self, state: TraversalState) {
        self.available_states.push(state);
    }
}

/// Reusable traversal state
#[derive(Debug)]
struct TraversalState {
    visited: HashSet<NodeId>,
    #[allow(dead_code)] // TODO: Implement queue-based traversal
    queue: VecDeque<NodeId>,
    distances: HashMap<NodeId, f64>,
    predecessors: HashMap<NodeId, NodeId>,
}

/// Configuration for traversal algorithms
#[derive(Debug, Clone)]
pub struct TraversalConfig {
    /// Use parallel processing when nodes/edges exceed this threshold
    pub parallel_threshold: usize,
    /// Maximum memory to use for state (bytes)
    pub max_memory: usize,
    /// Enable performance tracking
    pub track_performance: bool,
}

impl Default for TraversalConfig {
    fn default() -> Self {
        Self {
            parallel_threshold: 1000,
            max_memory: 64 * 1024 * 1024, // 64MB
            track_performance: true,
        }
    }
}

/// Options for controlling traversal behavior
#[derive(Debug, Clone)]
pub struct TraversalOptions {
    /// Filter nodes during traversal
    pub node_filter: Option<NodeFilter>,
    /// Filter edges during traversal  
    pub edge_filter: Option<EdgeFilter>,
    /// Maximum depth to traverse
    pub max_depth: Option<usize>,
    /// Maximum number of nodes to visit
    pub max_nodes: Option<usize>,
    /// Early termination condition
    pub target_node: Option<NodeId>,
}

impl Default for TraversalOptions {
    fn default() -> Self {
        Self {
            node_filter: None,
            edge_filter: None,
            max_depth: None,
            max_nodes: None,
            target_node: None,
        }
    }
}

/// Options for pathfinding algorithms
#[derive(Debug, Clone)]
pub struct PathFindingOptions {
    /// Attribute name to use as edge weight
    pub weight_attribute: Option<AttrName>,
    /// Maximum path length to consider
    pub max_path_length: Option<usize>,
    /// Heuristic function for A* (future)
    pub heuristic: Option<String>,
}

impl Default for PathFindingOptions {
    fn default() -> Self {
        Self {
            weight_attribute: None,
            max_path_length: None,
            heuristic: None,
        }
    }
}

/// Result of a traversal operation
#[derive(Debug, Clone)]
pub struct TraversalResult {
    pub algorithm: TraversalAlgorithm,
    pub nodes: Vec<NodeId>,
    pub edges: Vec<EdgeId>,
    pub paths: Vec<Path>,
    pub metadata: TraversalMetadata,
}

/// Type of traversal algorithm
#[derive(Debug, Clone, PartialEq)]
pub enum TraversalAlgorithm {
    BFS,
    DFS,
    ShortestPath,
    AllPaths,
    ConnectedComponents,
}

/// Metadata about traversal execution
#[derive(Debug, Clone)]
pub struct TraversalMetadata {
    pub start_node: Option<NodeId>,
    pub end_node: Option<NodeId>,
    pub max_depth: usize,
    pub nodes_visited: usize,
    pub execution_time: std::time::Duration,
    pub levels: Option<HashMap<NodeId, usize>>, // For BFS
    pub discovery_order: Option<HashMap<NodeId, usize>>, // For DFS
}

/// A path through the graph
#[derive(Debug, Clone)]
pub struct Path {
    pub nodes: Vec<NodeId>,
    pub edges: Vec<EdgeId>,
    pub total_weight: f64,
    pub metadata: PathMetadata,
}

/// Metadata about a path
#[derive(Debug, Clone)]
pub struct PathMetadata {
    pub algorithm: String,
    pub is_simple: bool,
    pub length: usize,
}

/// Result of connected components analysis
#[derive(Debug, Clone)]
pub struct ConnectedComponentsResult {
    pub components: Vec<ConnectedComponent>,
    pub total_components: usize,
    pub largest_component_size: usize,
    pub execution_time: std::time::Duration,
}

/// A connected component
#[derive(Debug, Clone)]
pub struct ConnectedComponent {
    pub nodes: Vec<NodeId>,
    pub edges: Vec<EdgeId>, // Induced edges within this component
    pub size: usize,
    pub root: NodeId, // Representative node
}

/// Performance statistics for traversal operations
#[derive(Debug, Clone)]
pub struct TraversalStats {
    pub total_traversals: usize,
    pub total_nodes_visited: usize,
    pub total_time: std::time::Duration,
    pub algorithm_counts: HashMap<String, usize>,
    pub algorithm_times: HashMap<String, std::time::Duration>,
}

impl TraversalStats {
    fn new() -> Self {
        Self {
            total_traversals: 0,
            total_nodes_visited: 0,
            total_time: std::time::Duration::new(0, 0),
            algorithm_counts: HashMap::new(),
            algorithm_times: HashMap::new(),
        }
    }
    
    fn record_traversal(&mut self, algorithm: String, nodes_visited: usize, duration: std::time::Duration) {
        self.total_traversals += 1;
        self.total_nodes_visited += nodes_visited;
        self.total_time += duration;
        
        *self.algorithm_counts.entry(algorithm.clone()).or_insert(0) += 1;
        *self.algorithm_times.entry(algorithm).or_insert(std::time::Duration::new(0, 0)) += duration;
    }
    
    fn clear(&mut self) {
        *self = Self::new();
    }
    
    pub fn average_time_per_traversal(&self) -> f64 {
        if self.total_traversals > 0 {
            self.total_time.as_secs_f64() / self.total_traversals as f64
        } else {
            0.0
        }
    }
    
    pub fn average_nodes_per_traversal(&self) -> f64 {
        if self.total_traversals > 0 {
            self.total_nodes_visited as f64 / self.total_traversals as f64
        } else {
            0.0
        }
    }
}

impl Default for TraversalEngine {
    fn default() -> Self {
        Self::new()
    }
}

/*
=== IMPLEMENTATION NOTES ===

PERFORMANCE OPTIMIZATIONS:
1. Columnar topology access for cache-friendly iteration
2. Parallel processing for large graphs using Rayon
3. State pooling to avoid allocations
4. Early termination conditions
5. Efficient data structures (BinaryHeap for Dijkstra)

MEMORY EFFICIENCY:
1. Reusable state objects
2. In-place operations where possible
3. Configurable memory limits
4. Lazy evaluation for expensive operations

ALGORITHM IMPLEMENTATIONS:
1. BFS: Level-by-level with parallel processing per level
2. DFS: Iterative to avoid stack overflow
3. Shortest Path: Dijkstra with early termination
4. Connected Components: Union-find approach with BFS

EXTENSIBILITY:
1. Common TraversalOptions for all algorithms
2. Pluggable filtering during traversal
3. Configurable performance vs memory trade-offs
4. Statistics tracking for optimization

INTEGRATION:
1. Uses existing NodeFilter/EdgeFilter from query engine
2. Leverages GraphSpace's columnar topology
3. Compatible with GraphPool's attribute system
4. Consistent error handling with rest of system
*/

--- FILE: core/strategies.rs ---
//! Temporal Storage Strategies - Pluggable approaches for storing graph changes over time
//!
//! This module contains both the trait definition and all concrete implementations
//! of different temporal storage strategies.

use std::collections::HashMap;
use crate::types::{NodeId, EdgeId, AttrName, AttrValue};
use crate::core::change_tracker::ChangeSet;
use crate::core::delta::DeltaObject;

/*
=== TEMPORAL STRATEGY OVERVIEW ===

Different workloads benefit from different temporal storage approaches:

1. INDEX DELTAS (current implementation):
   - Best for: Frequent small changes, analytical workloads
   - Trade-off: Small storage + fast commits vs. reconstruction cost
   - Use case: Real-time graph updates, attribute-heavy workloads

2. FULL SNAPSHOTS (future):
   - Best for: Infrequent large changes, time-travel heavy workloads
   - Trade-off: Large storage vs. instant recall
   - Use case: Versioned datasets, audit trails

3. HYBRID APPROACHES (future):
   - Best for: Mixed workloads with both patterns
   - Trade-off: Balanced storage vs. balanced performance
   - Use case: Production systems with varied access patterns

The strategy pattern allows runtime selection based on workload characteristics.
*/

/// Core trait for temporal storage strategies
/// 
/// DESIGN: Each strategy implements a different approach to storing and reconstructing
/// temporal graph states. The trait provides a common interface that ChangeTracker
/// and History systems can work with regardless of the underlying storage strategy.
pub trait TemporalStorageStrategy: std::fmt::Debug {
    /*
    === CHANGE RECORDING ===
    How this strategy tracks modifications
    */
    
    /// Record that a node was added to the graph
    fn record_node_addition(&mut self, node_id: NodeId);
    
    /// Record that a node was removed from the graph
    fn record_node_removal(&mut self, node_id: NodeId);
    
    /// Record that an edge was added to the graph
    fn record_edge_addition(&mut self, edge_id: EdgeId, source: NodeId, target: NodeId);
    
    /// Record that an edge was removed from the graph
    fn record_edge_removal(&mut self, edge_id: EdgeId);
    
    /// Record that a node attribute changed (index-based)
    /// All strategies now work with indices for consistency and efficiency
    fn record_node_attr_change(
        &mut self,
        node_id: NodeId,
        attr_name: AttrName,
        old_index: Option<usize>,
        new_index: usize,
    );
    
    /// Record that an edge attribute changed (index-based)
    fn record_edge_attr_change(
        &mut self,
        edge_id: EdgeId,
        attr_name: AttrName,
        old_index: Option<usize>,
        new_index: usize,
    );
    
    /*
    === DELTA CREATION ===
    Convert tracked changes into committable deltas
    */
    
    /// Create a delta object representing all current changes
    /// This is used when committing to history
    fn create_delta(&self) -> DeltaObject;
    
    /// Create a change set that can be passed to HistoryForest
    fn create_change_set(&self) -> ChangeSet;
    
    /*
    === CHANGE MANAGEMENT ===
    State management for the tracking system
    */
    
    /// Check if there are any uncommitted changes
    fn has_changes(&self) -> bool;
    
    /// Get the total number of changes recorded
    fn change_count(&self) -> usize;
    
    /// Clear all recorded changes (after successful commit)
    fn clear_changes(&mut self);
    
    /*
    === STRATEGY METADATA ===
    Information about this storage strategy
    */
    
    /// Get the name of this strategy
    fn strategy_name(&self) -> &'static str;
    
    /// Get performance characteristics of this strategy
    fn storage_characteristics(&self) -> StorageCharacteristics;
    
    /// Support for downcasting to specific strategy types
    /// This allows access to strategy-specific methods
    fn as_any(&mut self) -> &mut dyn std::any::Any;
}

/// Performance and storage characteristics of a temporal strategy
/// 
/// DESIGN: This allows the system to choose strategies based on workload requirements
/// and provides transparency about trade-offs between different approaches.
#[derive(Debug, Clone)]
pub struct StorageCharacteristics {
    /// Typical storage overhead per change (relative scale 1-10)
    pub storage_overhead: u8,
    
    /// Typical commit performance (relative scale 1-10, higher = faster)
    pub commit_speed: u8,
    
    /// Typical reconstruction performance (relative scale 1-10, higher = faster)
    pub reconstruction_speed: u8,
    
    /// Whether this strategy supports efficient partial reconstruction
    pub supports_partial_reconstruction: bool,
    
    /// Whether this strategy benefits from frequent commits
    pub prefers_frequent_commits: bool,
    
    /// Human-readable description of the strategy's trade-offs
    pub description: &'static str,
}

/// Enumeration of available storage strategies
/// 
/// DESIGN: This enum allows configuration-driven strategy selection
/// and provides a type-safe way to specify which strategy to use.
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum StorageStrategyType {
    /// Index-based deltas (current implementation)
    /// Stores attribute changes as column index mappings
    IndexDeltas,
    
    // Future strategies:
    // /// Full snapshots at each commit
    // FullSnapshots,
    // 
    // /// Hybrid: snapshots + deltas
    // Hybrid,
    // 
    // /// Compressed snapshots
    // CompressedSnapshots,
}

impl StorageStrategyType {
    /// Get a human-readable name for this strategy
    pub fn name(&self) -> &'static str {
        match self {
            StorageStrategyType::IndexDeltas => "Index-Based Deltas",
        }
    }
    
    /// Get a description of this strategy
    pub fn description(&self) -> &'static str {
        match self {
            StorageStrategyType::IndexDeltas => 
                "Efficient delta storage using column indices for temporal graph versioning",
        }
    }
}

impl Default for StorageStrategyType {
    fn default() -> Self {
        StorageStrategyType::IndexDeltas
    }
}

/// Factory function to create a strategy instance
/// 
/// DESIGN: This factory pattern allows the system to create strategy instances
/// based on configuration without tight coupling to specific implementations.
pub fn create_strategy(strategy_type: StorageStrategyType) -> Box<dyn TemporalStorageStrategy> {
    match strategy_type {
        StorageStrategyType::IndexDeltas => {
            Box::new(IndexDeltaStrategy::new())
        }
        // Future strategies would be added here
    }
}

/*
=== INDEX DELTA STRATEGY IMPLEMENTATION ===
*/

use crate::core::delta::ColumnIndexDelta;

/// Index-based delta storage strategy
/// 
/// DESIGN: This strategy tracks attribute changes using column indices instead of values.
/// When an attribute changes, it stores the old and new column indices rather than the
/// actual values. This enables efficient temporal versioning where multiple graph states
/// can share the same columnar data.
/// 
/// PERFORMANCE CHARACTERISTICS:
/// - Storage: Very efficient (only stores indices)
/// - Commits: Fast (no value copying)
/// - Reconstruction: Moderate (requires index resolution)
/// - Best for: Frequent changes, analytical workloads
#[derive(Debug)]
pub struct IndexDeltaStrategy {
    /// Nodes that have been added since last commit
    nodes_added: Vec<NodeId>,
    
    /// Nodes that have been removed since last commit
    nodes_removed: Vec<NodeId>,
    
    /// Edges that have been added since last commit
    /// Format: (edge_id, source_node, target_node)
    edges_added: Vec<(EdgeId, NodeId, NodeId)>,
    
    /// Edges that have been removed since last commit
    edges_removed: Vec<EdgeId>,
    
    /// Node attribute changes since last commit
    /// Format: (node_id, attr_name, old_index, new_index)
    /// old_index = None means attribute was newly set
    node_attr_index_changes: Vec<(NodeId, AttrName, Option<usize>, usize)>,
    
    /// Edge attribute changes since last commit
    /// Same format as node_attr_index_changes
    edge_attr_index_changes: Vec<(EdgeId, AttrName, Option<usize>, usize)>,
    
    /// When the first change was made (for timing statistics)
    first_change_timestamp: Option<u64>,
    
    /// Total number of changes recorded
    total_changes: usize,
}

impl IndexDeltaStrategy {
    /// Create a new empty index delta strategy
    pub fn new() -> Self {
        Self {
            nodes_added: Vec::new(),
            nodes_removed: Vec::new(),
            edges_added: Vec::new(),
            edges_removed: Vec::new(),
            node_attr_index_changes: Vec::new(),
            edge_attr_index_changes: Vec::new(),
            first_change_timestamp: None,
            total_changes: 0,
        }
    }
    
    /// Record node attribute change with indices (strategy-specific API)
    /// This is the index-specific version that stores column indices
    pub fn record_node_attr_index_change(
        &mut self,
        node_id: NodeId,
        attr_name: AttrName,
        old_index: Option<usize>,
        new_index: usize,
    ) {
        // Look for existing change for this node/attribute
        if let Some(existing) = self.node_attr_index_changes.iter_mut()
            .find(|(id, name, _, _)| *id == node_id && name == &attr_name) {
            // Update the new index, keep the original old index
            existing.3 = new_index;
        } else {
            // New change
            self.node_attr_index_changes.push((node_id, attr_name, old_index, new_index));
        }
        
        self.update_change_metadata();
    }
    
    /// Record edge attribute change with indices (strategy-specific API)
    pub fn record_edge_attr_index_change(
        &mut self,
        edge_id: EdgeId,
        attr_name: AttrName,
        old_index: Option<usize>,
        new_index: usize,
    ) {
        // Same pattern as node attributes but for edges
        if let Some(existing) = self.edge_attr_index_changes.iter_mut()
            .find(|(id, name, _, _)| *id == edge_id && name == &attr_name) {
            existing.3 = new_index;
        } else {
            self.edge_attr_index_changes.push((edge_id, attr_name, old_index, new_index));
        }
        
        self.update_change_metadata();
    }
    
    /// Helper method to update change metadata
    fn update_change_metadata(&mut self) {
        self.total_changes += 1;
        if self.first_change_timestamp.is_none() {
            self.first_change_timestamp = Some(self.current_timestamp());
        }
    }
    
    /// Get current timestamp
    fn current_timestamp(&self) -> u64 {
        std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap_or_default()
            .as_secs()
    }
}

impl TemporalStorageStrategy for IndexDeltaStrategy {
    fn record_node_addition(&mut self, node_id: NodeId) {
        self.nodes_added.push(node_id);
        self.update_change_metadata();
    }
    
    fn record_node_removal(&mut self, node_id: NodeId) {
        self.nodes_removed.push(node_id);
        // Remove any attribute changes for this node since it's being deleted
        self.node_attr_index_changes.retain(|(id, _, _, _)| *id != node_id);
        self.update_change_metadata();
    }
    
    fn record_edge_addition(&mut self, edge_id: EdgeId, source: NodeId, target: NodeId) {
        self.edges_added.push((edge_id, source, target));
        self.update_change_metadata();
    }
    
    fn record_edge_removal(&mut self, edge_id: EdgeId) {
        self.edges_removed.push(edge_id);
        // Remove any attribute changes for this edge since it's being deleted
        self.edge_attr_index_changes.retain(|(id, _, _, _)| *id != edge_id);
        self.update_change_metadata();
    }
    
    fn record_node_attr_change(
        &mut self,
        node_id: NodeId,
        attr_name: AttrName,
        old_index: Option<usize>,
        new_index: usize,
    ) {
        // Now the trait method directly receives indices - much cleaner!
        self.record_node_attr_index_change(node_id, attr_name, old_index, new_index);
    }
    
    fn record_edge_attr_change(
        &mut self,
        edge_id: EdgeId,
        attr_name: AttrName,
        old_index: Option<usize>,
        new_index: usize,
    ) {
        // Same clean delegation to index-specific method
        self.record_edge_attr_index_change(edge_id, attr_name, old_index, new_index);
    }
    
    fn create_delta(&self) -> DeltaObject {
        let mut node_attr_indices = HashMap::new();
        
        // Group node attribute index changes by attribute name
        for (node_id, attr_name, old_index, new_index) in &self.node_attr_index_changes {
            let column_delta = node_attr_indices.entry(attr_name.clone())
                .or_insert_with(ColumnIndexDelta::new);
            
            column_delta.add_index_change(*node_id as usize, *old_index, *new_index);
        }
        
        // Similar for edge attributes
        let mut edge_attr_indices = HashMap::new();
        for (edge_id, attr_name, old_index, new_index) in &self.edge_attr_index_changes {
            let column_delta = edge_attr_indices.entry(attr_name.clone())
                .or_insert_with(ColumnIndexDelta::new);
            
            column_delta.add_index_change(*edge_id as usize, *old_index, *new_index);
        }
        
        // Create delta with index-based changes
        DeltaObject::new_with_indices(
            node_attr_indices,
            edge_attr_indices,
            self.nodes_added.clone(),
            self.nodes_removed.clone(),
            self.edges_added.clone(),
            self.edges_removed.clone(),
        )
    }
    
    fn create_change_set(&self) -> ChangeSet {
        // Convert index-based changes to ChangeSet format for HistoryForest
        let mut node_attr_changes = Vec::new();
        for (node_id, attr_name, _old_index, _new_index) in &self.node_attr_index_changes {
            // For now, we don't have the actual values, so we use placeholder values
            // In a full implementation, we would resolve the indices to actual values
            node_attr_changes.push((
                *node_id,
                attr_name.clone(),
                None, // old_value - would need to resolve from old_index
                AttrValue::Text(format!("index_{}", _new_index)) // placeholder new value
            ));
        }
        
        let mut edge_attr_changes = Vec::new();
        for (edge_id, attr_name, _old_index, _new_index) in &self.edge_attr_index_changes {
            edge_attr_changes.push((
                *edge_id,
                attr_name.clone(),
                None, // old_value
                AttrValue::Text(format!("index_{}", _new_index)) // placeholder new value
            ));
        }
        
        ChangeSet {
            nodes_added: self.nodes_added.clone(),
            nodes_removed: self.nodes_removed.clone(),
            edges_added: self.edges_added.clone(),
            edges_removed: self.edges_removed.clone(),
            node_attr_changes,
            edge_attr_changes,
        }
    }
    
    fn has_changes(&self) -> bool {
        !self.nodes_added.is_empty() ||
        !self.nodes_removed.is_empty() ||
        !self.edges_added.is_empty() ||
        !self.edges_removed.is_empty() ||
        !self.node_attr_index_changes.is_empty() ||
        !self.edge_attr_index_changes.is_empty()
    }
    
    fn change_count(&self) -> usize {
        self.total_changes
    }
    
    fn clear_changes(&mut self) {
        self.nodes_added.clear();
        self.nodes_removed.clear();
        self.edges_added.clear();
        self.edges_removed.clear();
        self.node_attr_index_changes.clear();
        self.edge_attr_index_changes.clear();
        self.first_change_timestamp = None;
        self.total_changes = 0;
    }
    
    fn strategy_name(&self) -> &'static str {
        "Index Delta Strategy"
    }
    
    fn storage_characteristics(&self) -> StorageCharacteristics {
        StorageCharacteristics {
            storage_overhead: 2,  // Very low (only indices)
            commit_speed: 9,      // Very fast (no value copying)
            reconstruction_speed: 6,  // Moderate (requires index resolution)
            supports_partial_reconstruction: true,
            prefers_frequent_commits: true,
            description: "Efficient temporal storage using column indices. \
                         Best for frequent changes and analytical workloads.",
        }
    }
    
    fn as_any(&mut self) -> &mut dyn std::any::Any {
        self
    }
}

impl Default for IndexDeltaStrategy {
    fn default() -> Self {
        Self::new()
    }
}

--- FILE: core/query.rs ---
//! Query Engine - Core filtering operations for graph data.

use crate::types::{NodeId, EdgeId, AttrName, AttrValue};
use crate::core::pool::GraphPool;
use crate::core::space::GraphSpace;
use crate::errors::GraphResult;
use rayon::prelude::*; // Re-enabled - RefCell eliminated, now safe for parallel processing
use std::collections::HashSet;

/// The main query engine for filtering operations
#[derive(Debug)]
pub struct QueryEngine {}

impl QueryEngine {
    /// Create a new query engine
    pub fn new() -> Self {
        Self {}
    }

    /// Find nodes using active space information (called from Graph API)
    pub fn find_nodes_by_filter_with_space(
        &mut self,
        pool: &GraphPool,
        space: &GraphSpace, // Changed from &mut to &
        filter: &NodeFilter
    ) -> GraphResult<Vec<NodeId>> {
        self.filter_nodes(pool, space, filter)
    }

    /// Find nodes with filtering - PERFORMANCE OPTIMIZED using bulk columnar operations
    pub fn filter_nodes(
        &mut self,
        pool: &GraphPool,
        space: &GraphSpace, // Changed from &mut to &
        filter: &NodeFilter
    ) -> GraphResult<Vec<NodeId>> {
        let active_nodes: Vec<NodeId> = space.node_ids(); // Direct call, no RefCell clone
        
        // Use bulk columnar filtering for maximum performance
        self.filter_nodes_columnar(&active_nodes, pool, space, filter)
    }

    /// Columnar filtering on any subset of nodes - THE CORE METHOD (ULTRA-OPTIMIZED)
    fn filter_nodes_columnar(
        &self,
        nodes: &[NodeId],
        pool: &GraphPool,
        space: &GraphSpace, // Changed from &mut to &
        filter: &NodeFilter
    ) -> GraphResult<Vec<NodeId>> {
        let start_time = std::time::Instant::now();
        
        match filter {
            NodeFilter::AttributeFilter { name, filter } => {
                // OPTIMIZED: Pre-allocate result vector to avoid multiple allocations
                let mut matching_nodes = Vec::with_capacity(nodes.len() / 4); // estimate 25% match rate
                let attr_start = std::time::Instant::now();
                let node_attr_pairs = space.get_attributes_for_nodes(pool, name, nodes);
                let attr_time = attr_start.elapsed();
                
                // ULTRA-OPTIMIZED: Parallel iterator processing with minimal allocations
                let parallel_results: Vec<NodeId> = if node_attr_pairs.len() > 1000 {
                    // Use parallel processing for large datasets
                    node_attr_pairs
                        .into_par_iter()
                        .filter_map(|(node_id, attr_opt)| {
                            attr_opt.and_then(|attr_value| {
                                if filter.matches(attr_value) {
                                    Some(node_id)
                                } else {
                                    None
                                }
                            })
                        })
                        .collect()
                } else {
                    // Use sequential processing for small datasets to avoid overhead
                    node_attr_pairs
                        .into_iter()
                        .filter_map(|(node_id, attr_opt)| {
                            attr_opt.and_then(|attr_value| {
                                if filter.matches(attr_value) {
                                    Some(node_id)
                                } else {
                                    None
                                }
                            })
                        })
                        .collect()
                };
                matching_nodes.extend(parallel_results);
                let total_time = start_time.elapsed();
                Ok(matching_nodes)
            }
            
            NodeFilter::AttributeEquals { name, value } => {
                // OPTIMIZED: Pre-allocate and avoid iterator chain
                let mut matching_nodes = Vec::with_capacity(nodes.len() / 4);
                let attr_start = std::time::Instant::now();
                let node_attr_pairs = space.get_attributes_for_nodes(pool, name, nodes);
                let attr_time = attr_start.elapsed();
                
                // PARALLEL: Use parallel processing for large datasets
                let parallel_results: Vec<NodeId> = if node_attr_pairs.len() > 1000 {
                    node_attr_pairs
                        .into_par_iter()
                        .filter_map(|(node_id, attr_opt)| {
                            if let Some(attr_value) = attr_opt {
                                if *attr_value == *value {
                                    Some(node_id)
                                } else {
                                    None
                                }
                            } else {
                                None
                            }
                        })
                        .collect()
                } else {
                    node_attr_pairs
                        .into_iter()
                        .filter_map(|(node_id, attr_opt)| {
                            if let Some(attr_value) = attr_opt {
                                if *attr_value == *value {
                                    Some(node_id)
                                } else {
                                    None
                                }
                            } else {
                                None
                            }
                        })
                        .collect()
                };
                matching_nodes.extend(parallel_results);
                let total_time = start_time.elapsed();
                Ok(matching_nodes)
            }
            
            NodeFilter::HasAttribute { name } => {
                // OPTIMIZED: Use bulk attribute lookup with parallel processing
                let node_attr_pairs = space.get_attributes_for_nodes(pool, name, nodes);
                
                let results: Vec<NodeId> = if node_attr_pairs.len() > 1000 {
                    node_attr_pairs
                        .into_par_iter()
                        .filter_map(|(node_id, attr_opt)| {
                            if attr_opt.is_some() {
                                Some(node_id)
                            } else {
                                None
                            }
                        })
                        .collect()
                } else {
                    node_attr_pairs
                        .into_iter()
                        .filter_map(|(node_id, attr_opt)| {
                            if attr_opt.is_some() {
                                Some(node_id)
                            } else {
                                None
                            }
                        })
                        .collect()
                };
                
                Ok(results)
            }
            
            NodeFilter::And(filters) => {
                if filters.is_empty() {
                    return Ok(Vec::new());
                }
                
                let mut result_set: HashSet<NodeId> = 
                    self.filter_nodes_columnar(nodes, pool, space, &filters[0])?
                        .into_iter()
                        .collect();
                
                for sub_filter in &filters[1..] {
                    if result_set.is_empty() {
                        break;
                    }
                    let candidates: Vec<NodeId> = result_set.iter().copied().collect();
                    let filter_result: HashSet<NodeId> = 
                        self.filter_nodes_columnar(&candidates, pool, space, sub_filter)?
                            .into_iter()
                            .collect();
                    result_set = result_set.intersection(&filter_result).copied().collect();
                }
                Ok(result_set.into_iter().collect())
            }
            
            NodeFilter::DegreeRange { min, max } => {
                // OPTIMIZED: Bulk degree calculation using columnar topology
                let (_, sources, targets, _) = space.snapshot(pool);
                let mut matching_nodes = Vec::with_capacity(nodes.len() / 4);
                
                // Count degrees for all nodes at once using columnar scan
                for &node_id in nodes {
                    let mut degree = 0;
                    for i in 0..sources.len() {
                        if sources[i] == node_id || targets[i] == node_id {
                            degree += 1;
                        }
                    }
                    if degree >= *min && degree <= *max {
                        matching_nodes.push(node_id);
                    }
                }
                Ok(matching_nodes)
            }
            
            NodeFilter::HasNeighbor { neighbor_id } => {
                // OPTIMIZED: Bulk neighbor check using columnar topology
                let (_, sources, targets, _) = space.snapshot(pool);
                let mut matching_nodes = Vec::with_capacity(nodes.len() / 4);
                
                // Check neighbor relationships for all nodes at once using columnar scan
                for &node_id in nodes {
                    let mut has_neighbor = false;
                    for i in 0..sources.len() {
                        if (sources[i] == node_id && targets[i] == *neighbor_id) ||
                           (sources[i] == *neighbor_id && targets[i] == node_id) {
                            has_neighbor = true;
                            break;
                        }
                    }
                    if has_neighbor {
                        matching_nodes.push(node_id);
                    }
                }
                Ok(matching_nodes)
            }
            
            NodeFilter::Or(filters) => {
                if filters.is_empty() {
                    return Ok(Vec::new());
                }
                
                let mut result_set = HashSet::new();
                for sub_filter in filters {
                    let filter_results = self.filter_nodes_columnar(nodes, pool, space, sub_filter)?;
                    result_set.extend(filter_results);
                }
                Ok(result_set.into_iter().collect())
            }
            
            NodeFilter::Not(filter) => {
                let matching_nodes: HashSet<NodeId> = self.filter_nodes_columnar(nodes, pool, space, filter)?
                    .into_iter()
                    .collect();
                let non_matching: Vec<NodeId> = nodes
                    .iter()
                    .copied()
                    .filter(|node_id| !matching_nodes.contains(node_id))
                    .collect();
                Ok(non_matching)
            }
        }
    }

    /// Check if a node matches the given filter with pre-fetched topology
    fn node_matches_filter_with_topology(
        &self,
        node_id: NodeId,
        pool: &GraphPool,
        space: &GraphSpace,
        filter: &NodeFilter,
        topology_data: &Option<(Vec<EdgeId>, Vec<NodeId>, Vec<NodeId>)>
    ) -> bool {
        match filter {
            NodeFilter::HasAttribute { name } => {
                space.get_node_attr_index(node_id, name).is_some()
            }
            NodeFilter::AttributeEquals { name, value } => {
                if let Some(index) = space.get_node_attr_index(node_id, name) {
                    if let Some(attr_value) = pool.get_attr_by_index(name, index, true) {
                        return attr_value == value;
                    }
                }
                false
            }
            NodeFilter::AttributeFilter { name, filter } => {
                if let Some(index) = space.get_node_attr_index(node_id, name) {
                    if let Some(attr_value) = pool.get_attr_by_index(name, index, true) {
                        return filter.matches(attr_value);
                    }
                }
                false
            }
            NodeFilter::DegreeRange { min, max } => {
                if let Some((_, sources, targets)) = topology_data {
                    let mut degree = 0;
                    for i in 0..sources.len() {
                        if sources[i] == node_id || targets[i] == node_id {
                            degree += 1;
                        }
                    }
                    degree >= *min && degree <= *max
                } else {
                    false
                }
            }
            NodeFilter::HasNeighbor { neighbor_id } => {
                if let Some((_, sources, targets)) = topology_data {
                    for i in 0..sources.len() {
                        if (sources[i] == node_id && targets[i] == *neighbor_id) ||
                           (sources[i] == *neighbor_id && targets[i] == node_id) {
                            return true;
                        }
                    }
                }
                false
            }
            NodeFilter::And(filters) => {
                filters.iter().all(|f| self.node_matches_filter_with_topology(node_id, pool, space, f, topology_data))
            }
            NodeFilter::Or(filters) => {
                filters.iter().any(|f| self.node_matches_filter_with_topology(node_id, pool, space, f, topology_data))
            }
            NodeFilter::Not(filter) => {
                !self.node_matches_filter_with_topology(node_id, pool, space, filter, topology_data)
            }
        }
    }

    /// Check if a node matches the given filter (legacy method)
    fn node_matches_filter(
        &self,
        node_id: NodeId,
        pool: &GraphPool,
        space: &mut GraphSpace,
        filter: &NodeFilter
    ) -> bool {
        // Get topology if needed
        let topology_data = match filter {
            NodeFilter::DegreeRange { .. } | NodeFilter::HasNeighbor { .. } => {
                let (edge_ids, sources, targets, _) = space.snapshot(pool);
                Some((edge_ids.as_ref().clone(), sources.as_ref().clone(), targets.as_ref().clone()))
            },
            _ => None
        };
        
        self.node_matches_filter_with_topology(node_id, pool, space, filter, &topology_data)
    }

    /// Check if an edge matches the given filter
    fn edge_matches_filter(
        &self,
        edge_id: EdgeId,
        pool: &GraphPool,
        space: &GraphSpace,
        filter: &EdgeFilter
    ) -> bool {
        self.edge_matches_filter_impl(edge_id, pool, space, filter)
    }
    
    /// Implementation of edge filter matching
    fn edge_matches_filter_impl(
        &self,
        edge_id: EdgeId,
        pool: &GraphPool,
        space: &GraphSpace,
        filter: &EdgeFilter
    ) -> bool {
        match filter {
            EdgeFilter::HasAttribute { name } => {
                space.get_edge_attr_index(edge_id, name).is_some()
            }
            EdgeFilter::AttributeEquals { name, value } => {
                if let Some(index) = space.get_edge_attr_index(edge_id, name) {
                    if let Some(attr_value) = pool.get_attr_by_index(name, index, false) {
                        return attr_value == value;
                    }
                }
                false
            }
            EdgeFilter::AttributeFilter { name, filter } => {
                if let Some(index) = space.get_edge_attr_index(edge_id, name) {
                    if let Some(attr_value) = pool.get_attr_by_index(name, index, false) {
                        return filter.matches(attr_value);
                    }
                }
                false
            }
            EdgeFilter::ConnectsNodes { source, target } => {
                if let Some((edge_source, edge_target)) = pool.get_edge_endpoints(edge_id) {
                    (edge_source == *source && edge_target == *target) ||
                    (edge_source == *target && edge_target == *source)
                } else {
                    false
                }
            }
            EdgeFilter::ConnectsAny(node_ids) => {
                if let Some((source, target)) = pool.get_edge_endpoints(edge_id) {
                    node_ids.contains(&source) || node_ids.contains(&target)
                } else {
                    false
                }
            }
            EdgeFilter::And(filters) => {
                filters.iter().all(|f| self.edge_matches_filter(edge_id, pool, space, f))
            }
            EdgeFilter::Or(filters) => {
                filters.iter().any(|f| self.edge_matches_filter(edge_id, pool, space, f))
            }
            EdgeFilter::Not(filter) => {
                !self.edge_matches_filter(edge_id, pool, space, filter)
            }
        }
    }

    /// Find edges with filtering
    pub fn filter_edges(
        &mut self,
        pool: &GraphPool,
        space: &GraphSpace, // Already &
        filter: &EdgeFilter
    ) -> GraphResult<Vec<EdgeId>> {
        let start_time = std::time::Instant::now();
        let active_edges: Vec<EdgeId> = space.edge_ids(); // Direct call, no RefCell clone
        let _num_edges = active_edges.len();
        
        let results: Vec<EdgeId> = active_edges
            .into_iter()
            .filter(|&edge_id| self.edge_matches_filter(edge_id, pool, space, filter))
            .collect();
        
        let _total_time = start_time.elapsed();
        Ok(results)
    }

    /// Find all edges matching a filter (used by Graph API)
    pub fn find_edges_by_filter_with_space(
        &mut self,
        pool: &GraphPool,
        space: &GraphSpace, // Already &
        filter: &EdgeFilter
    ) -> GraphResult<Vec<EdgeId>> {
        self.filter_edges(pool, space, filter)
    }
}

/// Simple attribute filter for basic comparisons
#[derive(Debug, Clone, PartialEq)]
pub enum AttributeFilter {
    Equals(AttrValue),
    NotEquals(AttrValue),
    GreaterThan(AttrValue),
    LessThan(AttrValue),
    GreaterThanOrEqual(AttrValue),
    LessThanOrEqual(AttrValue),
}

impl AttributeFilter {
    /// Check if a value matches this filter
    pub fn matches(&self, value: &AttrValue) -> bool {
        match self {
            AttributeFilter::Equals(target) => value == target,
            AttributeFilter::NotEquals(target) => value != target,
            AttributeFilter::GreaterThan(target) => {
                // Flexible numeric comparison - handle all numeric type combinations
                self.compare_numeric(value, target, |a, b| a > b)
            }
            AttributeFilter::LessThan(target) => {
                // Flexible numeric comparison - handle all numeric type combinations
                self.compare_numeric(value, target, |a, b| a < b)
            }
            AttributeFilter::GreaterThanOrEqual(target) => {
                // Flexible numeric comparison - handle all numeric type combinations
                self.compare_numeric(value, target, |a, b| a >= b)
            }
            AttributeFilter::LessThanOrEqual(target) => {
                // Flexible numeric comparison - handle all numeric type combinations
                self.compare_numeric(value, target, |a, b| a <= b)
            }
        }
    }
    
    /// Helper method for flexible numeric comparisons
    /// OPTIMIZED: Use pattern matching to avoid allocations and improve performance
    fn compare_numeric<F>(&self, value: &AttrValue, target: &AttrValue, op: F) -> bool 
    where
        F: Fn(f64, f64) -> bool,
    {
        // OPTIMIZED: Direct pattern matching for common cases to avoid conversions
        match (value, target) {
            // Int comparisons - most common case
            (AttrValue::Int(a), AttrValue::Int(b)) => op(*a as f64, *b as f64),
            (AttrValue::SmallInt(a), AttrValue::SmallInt(b)) => op(*a as f64, *b as f64),
            (AttrValue::Float(a), AttrValue::Float(b)) => op(*a as f64, *b as f64),
            
            // Mixed comparisons
            (AttrValue::Int(a), AttrValue::Float(b)) => op(*a as f64, *b as f64),
            (AttrValue::Float(a), AttrValue::Int(b)) => op(*a as f64, *b as f64),
            (AttrValue::SmallInt(a), AttrValue::Int(b)) => op(*a as f64, *b as f64),
            (AttrValue::Int(a), AttrValue::SmallInt(b)) => op(*a as f64, *b as f64),
            (AttrValue::SmallInt(a), AttrValue::Float(b)) => op(*a as f64, *b as f64),
            (AttrValue::Float(a), AttrValue::SmallInt(b)) => op(*a as f64, *b as f64),
            
            // Non-numeric types
            _ => false,
        }
    }
}

/// Node filter for graph queries
#[derive(Debug, Clone, PartialEq)]
pub enum NodeFilter {
    HasAttribute { name: AttrName },
    AttributeEquals { name: AttrName, value: AttrValue },
    AttributeFilter { name: AttrName, filter: AttributeFilter },
    DegreeRange { min: usize, max: usize },
    HasNeighbor { neighbor_id: NodeId },
    And(Vec<NodeFilter>),
    Or(Vec<NodeFilter>),
    Not(Box<NodeFilter>),
}

/// Edge filter for graph queries
#[derive(Debug, Clone, PartialEq)]
pub enum EdgeFilter {
    HasAttribute { name: AttrName },
    AttributeEquals { name: AttrName, value: AttrValue },
    AttributeFilter { name: AttrName, filter: AttributeFilter },
    ConnectsNodes { source: NodeId, target: NodeId },
    ConnectsAny(Vec<NodeId>),
    And(Vec<EdgeFilter>),
    Or(Vec<EdgeFilter>),
    Not(Box<EdgeFilter>),
}

impl Default for QueryEngine {
    fn default() -> Self {
        Self::new()
    }
}


--- FILE: core/history.rs ---
//! History System - Git-like version control for graph evolution.
//!
//! ARCHITECTURE ROLE: 
//! This is the version control backbone of the system. It manages immutable 
//! snapshots of graph state over time, with branching and merging capabilities.
//!
//! DESIGN PHILOSOPHY:
//! - Immutable snapshots (states are never modified after creation)
//! - Content-addressed storage (deduplication via hashing)
//! - Git-like branching model (lightweight branches, merge capabilities)
//! - Efficient diff-based storage (only store what changed)

use std::collections::{HashMap, HashSet};
use std::sync::Arc;
use crate::types::{StateId, NodeId, EdgeId, AttrName, AttrValue, BranchName};
use crate::core::state::{StateMetadata, GraphSnapshot, StateDiff};
use crate::core::change_tracker::ChangeSet;
use crate::core::ref_manager::BranchInfo;
use crate::errors::{GraphError, GraphResult};

/*
=== HISTORY SYSTEM OVERVIEW ===

The history system is responsible for:
1. Creating immutable snapshots of graph state
2. Managing the DAG of state evolution (commits, branches, merges)
3. Providing time-travel capabilities (view graph at any point in history)
4. Handling branching and merging workflows
5. Garbage collection of unreachable states

KEY INSIGHTS:
- Store deltas (changes) rather than full snapshots for efficiency
- Use content addressing for automatic deduplication
- Separate metadata (who, when, why) from data (what changed)
- Support both linear history and complex branching workflows
*/

/// The main history management system
/// 
/// RESPONSIBILITIES:
/// - Store immutable snapshots of graph state over time
/// - Manage branching and merging operations
/// - Provide efficient diff-based storage
/// - Support time-travel queries
/// - Handle garbage collection of unreachable history
/// 
/// NOT RESPONSIBLE FOR:
/// - Current mutable state (that's GraphStore's job)
/// - Query processing (that's QueryEngine's job)
/// - Change tracking (that's ChangeTracker's job)
#[derive(Debug)]
pub struct HistoryForest {
    /*
    === COMMIT STORAGE ===
    The DAG of all commits in the system
    */
    
    /// All commits indexed by their state ID
    /// Each commit contains: parent_id, delta, metadata
    commits: HashMap<StateId, Arc<Commit>>,
    
    /// Content-addressed storage for deltas (automatic deduplication)
    /// If two commits have identical changes, they share the same delta
    deltas: HashMap<[u8; 32], Arc<Delta>>,
    
    /*
    === BRANCH MANAGEMENT ===
    Git-like lightweight branches
    */
    
    /// All branches: branch_name -> head_commit_id
    branches: HashMap<BranchName, StateId>,
    
    /// Tags (named references to specific commits)
    tags: HashMap<String, StateId>,
    
    /*
    === GRAPH STRUCTURE TRACKING ===
    Efficiently navigate the commit DAG
    */
    
    /// Parent-to-children index for efficient traversal
    /// Maps commit_id -> Vec<child_commit_ids>
    children: HashMap<StateId, Vec<StateId>>,
    
    /// Root commits (commits with no parent)
    roots: HashSet<StateId>,
    
    /*
    === ID MANAGEMENT ===
    */
    
    /// Next available state ID
    next_state_id: StateId,
}

impl HistoryForest {
    /// Create a new empty history system
    pub fn new() -> Self {
        let mut branches = HashMap::new();
        branches.insert("main".to_string(), 0); // main branch starts at state 0
        
        Self {
            commits: HashMap::new(),
            deltas: HashMap::new(),
            branches,
            tags: HashMap::new(),
            children: HashMap::new(),
            roots: HashSet::new(),
            next_state_id: 1,  // 0 is reserved for empty state
        }
    }
    
    /*
    === COMMIT OPERATIONS ===
    Creating new points in history
    */
    
    /// Create a new commit from a set of changes
    /// 
    /// ALGORITHM:
    /// 1. Create Delta from the changes
    /// 2. Compute content hash of delta for deduplication
    /// 3. Check if we already have this exact delta (hash collision -> reuse)
    /// 4. Create Commit with metadata (parent, message, author, timestamp)
    /// 5. Update parent-child relationships
    /// 6. Store everything and return new state ID
    pub fn create_commit(
        &mut self, 
        changes: ChangeSet, 
        message: String, 
        author: String, 
        parent: Option<StateId>
    ) -> Result<StateId, GraphError> {
        // 1. Create Delta from the changes
        let delta = Delta::from_changes(changes);
        
        // 2. Compute content hash of delta for deduplication
        let content_hash = delta.content_hash;
        
        // 3. Check if we already have this exact delta (reuse for deduplication)
        let delta_arc = self.deltas.entry(content_hash)
            .or_insert_with(|| Arc::new(delta));
        
        // 4. Create Commit with metadata
        let parents = match parent {
            Some(p) => vec![p],
            None => vec![],
        };
        let commit = Commit::new(
            self.next_state_id,
            parents,
            delta_arc.clone(),
            message,
            author
        );
        
        // 5. Store commit
        let commit_id = self.next_state_id;
        self.commits.insert(commit_id, Arc::new(commit));
        
        // 6. Update parent-child relationships
        if let Some(parent_id) = parent {
            self.children.entry(parent_id).or_insert_with(Vec::new).push(commit_id);
        } else {
            // This is a root commit
            self.roots.insert(commit_id);
        }
        
        // 7. Update state ID counter
        self.next_state_id += 1;
        
        // 8. Return new state ID
        Ok(commit_id)
    }
    
    /// Create a merge commit (commit with multiple parents)
    pub fn create_merge_commit(
        &mut self,
        changes: ChangeSet,
        message: String, 
        author: String,
        parents: Vec<StateId>
    ) -> Result<StateId, GraphError> {
        // 1. Create Delta from the changes
        let delta = Delta::from_changes(changes);
        
        // 2. Compute content hash of delta for deduplication
        let content_hash = delta.content_hash;
        
        // 3. Check if we already have this exact delta (reuse for deduplication)
        let delta_arc = self.deltas.entry(content_hash)
            .or_insert_with(|| Arc::new(delta));
        
        // 4. Create merge commit with multiple parents
        let commit = Commit::new(
            self.next_state_id,
            parents.clone(),
            delta_arc.clone(),
            message,
            author
        );
        
        // 5. Store commit
        let commit_id = self.next_state_id;
        self.commits.insert(commit_id, Arc::new(commit));
        
        // 6. Update parent-child relationships for all parents
        for parent_id in parents {
            self.children.entry(parent_id).or_insert_with(Vec::new).push(commit_id);
        }
        
        // 7. Update state ID counter
        self.next_state_id += 1;
        
        // 8. Return new state ID
        Ok(commit_id)
    }
    
    /*
    === BRANCH OPERATIONS ===
    Git-like branch management
    */
    
    /// Create a new branch pointing to a specific commit
    pub fn create_branch(&mut self, name: BranchName, commit_id: StateId) -> Result<(), GraphError> {
        // 1. Validate that commit_id exists
        if commit_id != 0 && !self.commits.contains_key(&commit_id) {
            return Err(GraphError::InvalidInput(format!("Commit {} does not exist", commit_id)));
        }
        
        // 2. Check that branch name doesn't already exist
        if self.branches.contains_key(&name) {
            return Err(GraphError::InvalidInput(format!("Branch '{}' already exists", name)));
        }
        
        // 3. Create the branch
        self.branches.insert(name, commit_id);
        Ok(())
    }
    
    /// Delete a branch (but not the commits it pointed to)
    pub fn delete_branch(&mut self, name: &BranchName) -> Result<(), GraphError> {
        // 1. Check that branch exists
        if !self.branches.contains_key(name) {
            return Err(GraphError::InvalidInput(format!("Branch '{}' does not exist", name)));
        }
        
        // 2. Check that it's not the main branch (safety check)
        if name == "main" {
            return Err(GraphError::InvalidInput("Cannot delete main branch".to_string()));
        }
        
        // 3. Remove the branch
        self.branches.remove(name);
        Ok(())
    }
    
    /// Update a branch to point to a different commit (e.g., after new commit)
    pub fn update_branch_head(&mut self, name: &BranchName, new_head: StateId) -> Result<(), GraphError> {
        // 1. Validate branch exists and commit exists
        if !self.branches.contains_key(name) {
            return Err(GraphError::InvalidInput(format!("Branch '{}' does not exist", name)));
        }
        if !self.commits.contains_key(&new_head) {
            return Err(GraphError::InvalidInput(format!("Commit {} does not exist", new_head)));
        }
        
        // 2. Update branch head
        self.branches.insert(name.clone(), new_head);
        Ok(())
    }
    
    /// List all branches with their head commits
    pub fn list_branches(&self) -> Vec<BranchInfo> {
        self.branches.iter().map(|(name, &head)| {
            BranchInfo {
                name: name.clone(),
                head: head,
                description: None, // TODO: add descriptions to branches
                created_at: 0, // TODO: track creation time
                created_by: "".to_string(), // TODO: track creator
                is_default: name == "main",
                is_current: false, // TODO: we need to track current branch in HistoryForest
            }
        }).collect()
    }
    
    /// Get the head commit of a branch
    pub fn get_branch_head(&self, name: &BranchName) -> Result<StateId, GraphError> {
        self.branches.get(name).copied().ok_or_else(|| 
            GraphError::InvalidInput(format!("Branch '{}' not found", name))
        )
    }
    
    /*
    === COMMIT QUERIES ===
    Navigating and inspecting the commit history
    */
    
    /// Get a specific commit by ID
    pub fn get_commit(&self, state_id: StateId) -> Result<Arc<Commit>, GraphError> {
        self.commits.get(&state_id).cloned().ok_or_else(|| 
            GraphError::InvalidInput(format!("Commit {} not found", state_id))
        )
    }
    
    /// Get all commits in chronological order
    pub fn get_commit_history(&self) -> Vec<Arc<Commit>> {
        let mut commits: Vec<Arc<Commit>> = self.commits.values().cloned().collect();
        commits.sort_by_key(|commit| commit.timestamp);
        commits
    }
    
    /// Get the commit history for a specific branch (following parent chain)
    pub fn get_branch_history(&self, branch_name: &BranchName) -> Result<Vec<Arc<Commit>>, GraphError> {
        // 1. Start from branch head
        let head_id = self.get_branch_head(branch_name)?;
        let mut history = Vec::new();
        let mut to_visit = vec![head_id];
        let mut visited = HashSet::new();
        
        // 2. Follow parent chain to roots using BFS
        while let Some(commit_id) = to_visit.pop() {
            if visited.contains(&commit_id) {
                continue;
            }
            visited.insert(commit_id);
            
            if let Some(commit) = self.commits.get(&commit_id) {
                history.push(commit.clone());
                // Add parents to visit queue
                for &parent_id in &commit.parents {
                    if !visited.contains(&parent_id) {
                        to_visit.push(parent_id);
                    }
                }
            }
        }
        
        // 3. Sort by timestamp (most recent first)
        history.sort_by(|a, b| b.timestamp.cmp(&a.timestamp));
        Ok(history)
    }
    
    /// Get all children of a commit
    pub fn get_children(&self, commit_id: StateId) -> Vec<StateId> {
        self.children.get(&commit_id).cloned().unwrap_or_default()
    }
    
    /// Get the parent(s) of a commit
    pub fn get_parents(&self, commit_id: StateId) -> Result<Vec<StateId>, GraphError> {
        let commit = self.get_commit(commit_id)?;
        Ok(commit.parents.clone())
    }
    
    /// Check if one commit is an ancestor of another
    pub fn is_ancestor(&self, ancestor: StateId, descendant: StateId) -> Result<bool, GraphError> {
        if ancestor == descendant {
            return Ok(true);
        }
        
        let mut to_visit = vec![descendant];
        let mut visited = HashSet::new();
        
        // BFS from descendant back through parents to find ancestor
        while let Some(commit_id) = to_visit.pop() {
            if visited.contains(&commit_id) {
                continue;
            }
            visited.insert(commit_id);
            
            if let Some(commit) = self.commits.get(&commit_id) {
                for &parent_id in &commit.parents {
                    if parent_id == ancestor {
                        return Ok(true);
                    }
                    if !visited.contains(&parent_id) {
                        to_visit.push(parent_id);
                    }
                }
            }
        }
        
        Ok(false)
    }
    
    /// Find the lowest common ancestor of two commits (useful for merging)
    pub fn find_common_ancestor(&self, commit1: StateId, commit2: StateId) -> Result<Option<StateId>, GraphError> {
        if commit1 == commit2 {
            return Ok(Some(commit1));
        }
        
        // Get all ancestors of commit1
        let mut ancestors1 = HashSet::new();
        let mut to_visit = vec![commit1];
        while let Some(commit_id) = to_visit.pop() {
            if ancestors1.contains(&commit_id) {
                continue;
            }
            ancestors1.insert(commit_id);
            
            if let Some(commit) = self.commits.get(&commit_id) {
                for &parent_id in &commit.parents {
                    to_visit.push(parent_id);
                }
            }
        }
        
        // BFS from commit2 to find first common ancestor
        let mut to_visit = vec![commit2];
        let mut visited = HashSet::new();
        while let Some(commit_id) = to_visit.pop() {
            if visited.contains(&commit_id) {
                continue;
            }
            visited.insert(commit_id);
            
            if ancestors1.contains(&commit_id) {
                return Ok(Some(commit_id));
            }
            
            if let Some(commit) = self.commits.get(&commit_id) {
                for &parent_id in &commit.parents {
                    to_visit.push(parent_id);
                }
            }
        }
        
        Ok(None)
    }
    
    /*
    === DIFF OPERATIONS ===
    Comparing different points in history
    */
    
    /// Compute the changes between two commits
    pub fn diff_commits(&self, from: StateId, to: StateId) -> Result<CommitDiff, GraphError> {
        let _ = (from, to); // Silence unused warnings
        // Basic implementation returns empty diff
        Ok(CommitDiff {
            from_commit: from,
            to_commit: to,
            nodes_added: Vec::new(),
            nodes_removed: Vec::new(),
            edges_added: Vec::new(),
            edges_removed: Vec::new(),
            attr_changes: Vec::new(),
        })
    }
    
    /// Get the delta (direct changes) introduced by a specific commit
    pub fn get_commit_delta(&self, commit_id: StateId) -> Result<Arc<Delta>, GraphError> {
        let commit = self.get_commit(commit_id)?;
        Ok(commit.delta.clone())
    }
    
    /*
    === STATE RECONSTRUCTION ===
    Building a graph state from history
    */
    
    /// Reconstruct the complete graph state at a specific commit
    /// This is expensive but necessary for time-travel functionality
    pub fn reconstruct_state_at(&self, commit_id: StateId) -> Result<GraphSnapshot, GraphError> {
        // Collect all deltas from root to this commit
        let mut deltas_to_apply = Vec::new();
        let mut current_id = commit_id;
        
        // Trace back to root, collecting commits
        let mut commit_chain = Vec::new();
        while let Some(commit) = self.commits.get(&current_id) {
            commit_chain.push((current_id, commit.clone()));
            if commit.parents.is_empty() {
                break; // Reached root
            }
            current_id = commit.parents[0]; // Follow first parent for linear reconstruction
        }
        
        // Reverse to get chronological order (root -> target)
        commit_chain.reverse();
        
        // Convert commits to deltas with state IDs
        for (state_id, commit) in &commit_chain {
            // Convert our Delta to the format expected by GraphSnapshot
            let history_delta = Delta {
                content_hash: commit.delta.content_hash,
                nodes_added: commit.delta.nodes_added.clone(),
                nodes_removed: commit.delta.nodes_removed.clone(),
                edges_added: commit.delta.edges_added.clone(),
                edges_removed: commit.delta.edges_removed.clone(),
                node_attr_changes: commit.delta.node_attr_changes.clone(),
                edge_attr_changes: commit.delta.edge_attr_changes.clone(),
            };
            deltas_to_apply.push((history_delta, *state_id));
        }
        
        // Start with empty state and apply all deltas
        GraphSnapshot::reconstruct_from_deltas(None, &deltas_to_apply)
    }
    
    /// Get the sequence of deltas needed to go from one commit to another
    pub fn get_delta_sequence(&self, from: StateId, to: StateId) -> Result<Vec<Arc<Delta>>, GraphError> {
        let _ = (from, to); // Silence unused warnings
        // Basic implementation returns empty sequence
        Ok(Vec::new())
    }
    
    /*
    === GARBAGE COLLECTION ===
    Cleaning up unreachable history
    */
    
    /// Find all commits reachable from branches and tags
    pub fn find_reachable_commits(&self) -> HashSet<StateId> {
        let mut reachable = HashSet::new();
        let mut to_visit = Vec::new();
        
        // 1. Start from all branch heads and tags
        for &head_id in self.branches.values() {
            to_visit.push(head_id);
        }
        for &tag_id in self.tags.values() {
            to_visit.push(tag_id);
        }
        
        // 2. DFS to find all reachable commits
        while let Some(commit_id) = to_visit.pop() {
            if reachable.contains(&commit_id) {
                continue;
            }
            reachable.insert(commit_id);
            
            if let Some(commit) = self.commits.get(&commit_id) {
                for &parent_id in &commit.parents {
                    if !reachable.contains(&parent_id) {
                        to_visit.push(parent_id);
                    }
                }
            }
        }
        
        reachable
    }
    
    /// Remove unreachable commits and their deltas
    pub fn garbage_collect(&mut self, keep_commits: &HashSet<StateId>) -> usize {
        let mut removed_count = 0;
        
        // 1. Find commits not in keep_commits and collect their deltas
        let mut removed_commits = Vec::new();
        let mut delta_hashes_to_check = Vec::new();
        
        for (&commit_id, commit) in &self.commits {
            if !keep_commits.contains(&commit_id) {
                removed_commits.push(commit_id);
                delta_hashes_to_check.push(commit.delta.content_hash);
            }
        }
        
        // 2. Remove commits from self.commits
        for commit_id in &removed_commits {
            self.commits.remove(commit_id);
            removed_count += 1;
        }
        
        // 3. Check if deltas are still referenced by remaining commits
        let mut still_referenced_deltas = HashSet::new();
        for commit in self.commits.values() {
            still_referenced_deltas.insert(commit.delta.content_hash);
        }
        
        // 4. Remove unreferenced deltas from self.deltas
        for delta_hash in delta_hashes_to_check {
            if !still_referenced_deltas.contains(&delta_hash) {
                self.deltas.remove(&delta_hash);
            }
        }
        
        // 5. Update children index
        for commit_id in &removed_commits {
            self.children.remove(commit_id);
            // Remove this commit from all parent's children lists
            for children_list in self.children.values_mut() {
                children_list.retain(|&child_id| child_id != *commit_id);
            }
        }
        
        removed_count
    }
    
    /*
    === STATISTICS AND INTROSPECTION ===
    */
    
    /// Get statistics about the history system
    pub fn statistics(&self) -> HistoryStatistics {
        // Find oldest and newest commits
        let mut oldest_timestamp = u64::MAX;
        let mut newest_timestamp = 0;
        
        for commit in self.commits.values() {
            oldest_timestamp = oldest_timestamp.min(commit.timestamp);
            newest_timestamp = newest_timestamp.max(commit.timestamp);
        }
        
        let now = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap_or_default()
            .as_secs();
            
        let oldest_age = if oldest_timestamp == u64::MAX {
            0
        } else {
            now.saturating_sub(oldest_timestamp)
        };
        let newest_age = now.saturating_sub(newest_timestamp);
        
        // Calculate storage efficiency (higher is better)
        let total_commits = self.commits.len();
        let unique_deltas = self.deltas.len();
        let storage_efficiency = if total_commits > 0 {
            unique_deltas as f64 / total_commits as f64
        } else {
            1.0
        };
        
        HistoryStatistics {
            total_commits,
            total_branches: self.branches.len(),
            total_tags: self.tags.len(),
            total_deltas: unique_deltas,
            storage_efficiency,
            oldest_commit_age: oldest_age,
            newest_commit_age: newest_age,
        }
    }
    
    /// List all commit IDs in the system
    pub fn list_all_commits(&self) -> Vec<StateId> {
        self.commits.keys().copied().collect()
    }
    
    /// Check if a commit exists
    pub fn has_commit(&self, commit_id: StateId) -> bool {
        self.commits.contains_key(&commit_id)
    }
}

/*
=== SUPPORTING DATA STRUCTURES ===
*/

/// A single commit in the history DAG
/// 
/// DESIGN: Immutable once created, reference-counted for sharing
#[derive(Debug, Clone)]
pub struct Commit {
    /// Unique identifier for this commit
    pub id: StateId,
    
    /// Parent commit(s) - None for root commits, Vec for merge commits
    pub parents: Vec<StateId>,
    
    /// The changes introduced by this commit
    pub delta: Arc<Delta>,
    
    /// Human-readable commit message
    pub message: String,
    
    /// Who created this commit
    pub author: String,
    
    /// When this commit was created (Unix timestamp)
    pub timestamp: u64,
    
    /// Content hash for verification and deduplication
    pub content_hash: [u8; 32],
}

impl Commit {
    /// Create a new commit
    pub fn new(
        id: StateId,
        parents: Vec<StateId>, 
        delta: Arc<Delta>,
        message: String,
        author: String
    ) -> Self {
        use std::time::{SystemTime, UNIX_EPOCH};
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};
        
        // Set timestamp to current time
        let timestamp = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap()
            .as_secs();
        
        // Compute content hash from all fields
        let mut hasher = DefaultHasher::new();
        id.hash(&mut hasher);
        parents.hash(&mut hasher);
        delta.content_hash.hash(&mut hasher);
        message.hash(&mut hasher);
        author.hash(&mut hasher);
        timestamp.hash(&mut hasher);
        let hash_u64 = hasher.finish();
        
        // Convert u64 hash to [u8; 32] (simple but deterministic)
        let mut content_hash = [0u8; 32];
        let hash_bytes = hash_u64.to_le_bytes();
        for i in 0..4 {
            content_hash[i * 8..(i + 1) * 8].copy_from_slice(&hash_bytes);
        }
        
        Self {
            id,
            parents,
            delta,
            message,
            author,
            timestamp,
            content_hash,
        }
    }
    
    /// Check if this is a root commit (no parents)
    pub fn is_root(&self) -> bool {
        self.parents.is_empty()
    }
    
    /// Check if this is a merge commit (multiple parents)
    pub fn is_merge(&self) -> bool {
        self.parents.len() > 1
    }
}

/// A delta represents the changes introduced by a single commit
/// 
/// DESIGN: Immutable, content-addressed for deduplication
#[derive(Debug, Clone)]
pub struct Delta {
    /// Hash of this delta's content (for deduplication)
    pub content_hash: [u8; 32],
    
    /// Nodes that were added in this commit
    pub nodes_added: Vec<NodeId>,
    
    /// Nodes that were removed in this commit  
    pub nodes_removed: Vec<NodeId>,
    
    /// Edges that were added in this commit
    pub edges_added: Vec<(EdgeId, NodeId, NodeId)>,
    
    /// Edges that were removed in this commit
    pub edges_removed: Vec<EdgeId>,
    
    /// Node attribute changes: (node_id, attr_name, old_value, new_value)
    pub node_attr_changes: Vec<(NodeId, AttrName, Option<AttrValue>, AttrValue)>,
    
    /// Edge attribute changes: (edge_id, attr_name, old_value, new_value)
    pub edge_attr_changes: Vec<(EdgeId, AttrName, Option<AttrValue>, AttrValue)>,
}

impl Delta {
    /// Create a delta from a change set
    pub fn from_changes(changes: ChangeSet) -> Self {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};
        
        // Extract changes from ChangeSet
        let nodes_added = changes.nodes_added.clone();
        let nodes_removed = Vec::new(); // TODO: when we implement node removal
        let edges_added = changes.edges_added.clone();
        let edges_removed = Vec::new(); // TODO: when we implement edge removal
        let node_attr_changes = changes.node_attr_changes.clone();
        let edge_attr_changes = changes.edge_attr_changes.clone();
        
        // Compute content hash from all changes
        let mut hasher = DefaultHasher::new();
        nodes_added.hash(&mut hasher);
        nodes_removed.hash(&mut hasher);
        edges_added.hash(&mut hasher);
        edges_removed.hash(&mut hasher);
        node_attr_changes.hash(&mut hasher);
        edge_attr_changes.hash(&mut hasher);
        let hash_u64 = hasher.finish();
        
        // Convert u64 hash to [u8; 32]
        let mut content_hash = [0u8; 32];
        let hash_bytes = hash_u64.to_le_bytes();
        for i in 0..4 {
            content_hash[i * 8..(i + 1) * 8].copy_from_slice(&hash_bytes);
        }
        
        Self {
            content_hash,
            nodes_added,
            nodes_removed,
            edges_added,
            edges_removed,
            node_attr_changes,
            edge_attr_changes,
        }
    }
    
    /// Check if this delta is empty (no changes)
    pub fn is_empty(&self) -> bool {
        self.nodes_added.is_empty() &&
        self.nodes_removed.is_empty() &&
        self.edges_added.is_empty() &&
        self.edges_removed.is_empty() &&
        self.node_attr_changes.is_empty() &&
        self.edge_attr_changes.is_empty()
    }
    
    /// Get a summary of what changed
    pub fn summary(&self) -> String {
        let mut parts = Vec::new();
        
        if !self.nodes_added.is_empty() {
            parts.push(format!("+{} nodes", self.nodes_added.len()));
        }
        if !self.nodes_removed.is_empty() {
            parts.push(format!("-{} nodes", self.nodes_removed.len()));
        }
        if !self.edges_added.is_empty() {
            parts.push(format!("+{} edges", self.edges_added.len()));
        }
        if !self.edges_removed.is_empty() {
            parts.push(format!("-{} edges", self.edges_removed.len()));
        }
        
        let total_attr_changes = self.node_attr_changes.len() + self.edge_attr_changes.len();
        if total_attr_changes > 0 {
            parts.push(format!("{} attr changes", total_attr_changes));
        }
        
        if parts.is_empty() {
            "no changes".to_string()
        } else {
            parts.join(", ")
        }
    }
}


/// Difference between two commits
#[derive(Debug, Clone)]
pub struct CommitDiff {
    pub from_commit: StateId,
    pub to_commit: StateId,
    pub nodes_added: Vec<NodeId>,
    pub nodes_removed: Vec<NodeId>,
    pub edges_added: Vec<(EdgeId, NodeId, NodeId)>,
    pub edges_removed: Vec<EdgeId>,
    pub attr_changes: Vec<AttributeChange>,
}

/// A single attribute change
#[derive(Debug, Clone)]
pub struct AttributeChange {
    pub entity_type: EntityType, // Node or Edge
    pub entity_id: u64,           // NodeId or EdgeId  
    pub attr_name: AttrName,
    pub old_value: Option<AttrValue>,
    pub new_value: Option<AttrValue>,
}

#[derive(Debug, Clone)]
pub enum EntityType {
    Node,
    Edge,
}

/// Statistics about the history system
#[derive(Debug, Clone)]
pub struct HistoryStatistics {
    pub total_commits: usize,
    pub total_branches: usize,
    pub total_tags: usize,
    pub total_deltas: usize,
    pub storage_efficiency: f64, // How much deduplication we achieved
    pub oldest_commit_age: u64,  // Seconds since oldest commit
    pub newest_commit_age: u64,  // Seconds since newest commit
}

impl Default for HistoryForest {
    fn default() -> Self {
        Self::new()
    }
}

/*
=== HISTORICAL VIEW SYSTEM ===
Read-only views of the graph at specific points in history
*/

/// Read-only view of a graph at a specific point in history
/// 
/// DESIGN: This provides a read-only interface to a historical graph state.
/// It uses lazy loading to reconstruct the state only when needed, and
/// caches the results for subsequent access.
/// 
/// LIFETIME: The view holds a reference to the history system, so it
/// cannot outlive the system that created it.
/// 
/// PERFORMANCE:
/// - First access triggers state reconstruction: O(depth * changes)
/// - Subsequent accesses use cached data: O(1) or O(log n)
/// - Memory usage: Only stores what's been accessed
#[derive(Debug)]
pub struct HistoricalView<'a> {
    /*
    === HISTORY REFERENCE ===
    Connection to the history system for data access
    */
    
    /// Reference to the history system that contains the state data
    /// LIFETIME: View cannot outlive this reference
    history: &'a HistoryForest,
    
    /// The specific state ID this view represents
    /// IMMUTABLE: Views always represent the same state
    state_id: StateId,
    
    /*
    === CACHED RECONSTRUCTION ===
    Lazily-built snapshot of the graph at this state
    */
    
    /// Cached snapshot of the complete graph state
    /// LAZY: Only built when first accessed
    /// CACHING: Kept for subsequent operations
    cached_snapshot: Option<GraphSnapshot>,
    
    /*
    === ACCESS OPTIMIZATION ===
    Tracking what's been loaded for selective reconstruction
    */
    
    /// Which node attributes have been loaded
    /// OPTIMIZATION: Avoid loading unused attributes
    loaded_node_attrs: HashMap<AttrName, bool>,
    
    /// Which edge attributes have been loaded
    /// OPTIMIZATION: Avoid loading unused attributes  
    loaded_edge_attrs: HashMap<AttrName, bool>,
}

impl<'a> HistoricalView<'a> {
    /// Create a new historical view for a specific commit
    /// 
    /// VALIDATION: Ensures the state exists in the history
    /// LAZY: Doesn't reconstruct the state until needed
    pub fn new(history: &'a HistoryForest, state_id: StateId) -> GraphResult<Self> {
        if !history.has_commit(state_id) {
            return Err(GraphError::InvalidInput(
                format!("Commit {} does not exist in history", state_id)
            ));
        }
        
        Ok(Self {
            history,
            state_id,
            cached_snapshot: None,
            loaded_node_attrs: HashMap::new(),
            loaded_edge_attrs: HashMap::new(),
        })
    }
    
    /*
    === SNAPSHOT MANAGEMENT ===
    Lazy loading and caching of the complete graph state
    */
    
    /// Get the complete snapshot, reconstructing if necessary
    /// 
    /// ALGORITHM:
    /// 1. If snapshot is cached, return it
    /// 2. Otherwise, reconstruct from history deltas
    /// 3. Cache the result for future use
    /// 4. Return reference to cached snapshot
    /// 
    /// PERFORMANCE: O(depth * changes) first time, O(1) after caching
    fn get_snapshot(&mut self) -> GraphResult<&GraphSnapshot> {
        if self.cached_snapshot.is_none() {
            let snapshot = self.history.reconstruct_state_at(self.state_id)?;
            self.cached_snapshot = Some(snapshot);
        }
        
        Ok(self.cached_snapshot.as_ref().unwrap())
    }
    
    /// Clear the cached snapshot to free memory
    /// 
    /// USAGE: Call this if memory usage is a concern and the view
    /// won't be accessed again soon
    pub fn clear_cache(&mut self) {
        self.cached_snapshot = None;
        self.loaded_node_attrs.clear();
        self.loaded_edge_attrs.clear();
    }
    
    /// Check if the snapshot is currently cached
    pub fn is_cached(&self) -> bool {
        self.cached_snapshot.is_some()
    }
    
    /*
    === NODE OPERATIONS ===
    Read-only access to nodes and their attributes
    */
    
    /// Get all active node IDs at this state
    pub fn get_node_ids(&mut self) -> GraphResult<Vec<NodeId>> {
        let snapshot = self.get_snapshot()?;
        Ok(snapshot.active_nodes.clone())
    }
    
    /// Check if a specific node exists at this state
    pub fn has_node(&mut self, node: NodeId) -> GraphResult<bool> {
        let snapshot = self.get_snapshot()?;
        Ok(snapshot.contains_node(node))
    }
    
    /// Get the number of active nodes at this state
    pub fn node_count(&mut self) -> GraphResult<usize> {
        let snapshot = self.get_snapshot()?;
        Ok(snapshot.active_nodes.len())
    }
    
    /// Get a specific attribute value for a node
    /// 
    /// OPTIMIZATION: This could potentially avoid loading the full snapshot
    /// by reconstructing only the requested attribute
    pub fn get_node_attribute(&mut self, node: NodeId, attr_name: &AttrName) -> GraphResult<Option<AttrValue>> {
        let snapshot = self.get_snapshot()?;
        if !snapshot.contains_node(node) {
            return Err(GraphError::NodeNotFound {
                node_id: node,
                operation: "get historical attribute".to_string(),
                suggestion: "Check if node exists in this historical state".to_string(),
            });
        }
        
        Ok(snapshot.node_attributes
            .get(&node)
            .and_then(|attrs| attrs.get(attr_name))
            .cloned())
    }
    
    /// Get all attributes for a specific node
    pub fn get_node_attributes(&mut self, node: NodeId) -> GraphResult<HashMap<AttrName, AttrValue>> {
        let snapshot = self.get_snapshot()?;
        if !snapshot.contains_node(node) {
            return Err(GraphError::NodeNotFound {
                node_id: node,
                operation: "get historical attributes".to_string(),
                suggestion: "Check if node exists in this historical state".to_string(),
            });
        }
        
        Ok(snapshot.node_attributes
            .get(&node)
            .cloned()
            .unwrap_or_default())
    }
    
    /*
    === EDGE OPERATIONS ===
    Read-only access to edges and their attributes
    */
    
    /// Get all active edge IDs at this state
    pub fn get_edge_ids(&mut self) -> GraphResult<Vec<EdgeId>> {
        let snapshot = self.get_snapshot()?;
        Ok(snapshot.edges.keys().cloned().collect())
    }
    
    /// Check if a specific edge exists at this state
    pub fn has_edge(&mut self, edge: EdgeId) -> GraphResult<bool> {
        let snapshot = self.get_snapshot()?;
        Ok(snapshot.contains_edge(edge))
    }
    
    /// Get the number of active edges at this state
    pub fn edge_count(&mut self) -> GraphResult<usize> {
        let snapshot = self.get_snapshot()?;
        Ok(snapshot.edges.len())
    }
    
    /// Get the endpoints of an edge
    pub fn get_edge_endpoints(&mut self, edge: EdgeId) -> GraphResult<(NodeId, NodeId)> {
        let snapshot = self.get_snapshot()?;
        snapshot.edges.get(&edge)
            .ok_or_else(|| GraphError::EdgeNotFound {
                edge_id: edge,
                operation: "get historical endpoints".to_string(),
                suggestion: "Check if edge exists in this historical state".to_string(),
            })
            .map(|&endpoints| endpoints)
    }
    
    /// Get a specific attribute value for an edge
    pub fn get_edge_attribute(&mut self, edge: EdgeId, attr_name: &AttrName) -> GraphResult<Option<AttrValue>> {
        let snapshot = self.get_snapshot()?;
        if !snapshot.contains_edge(edge) {
            return Err(GraphError::EdgeNotFound {
                edge_id: edge,
                operation: "get historical attribute".to_string(),
                suggestion: "Check if edge exists in this historical state".to_string(),
            });
        }
        
        Ok(snapshot.edge_attributes
            .get(&edge)
            .and_then(|attrs| attrs.get(attr_name))
            .cloned())
    }
    
    /// Get all attributes for a specific edge
    pub fn get_edge_attributes(&mut self, edge: EdgeId) -> GraphResult<HashMap<AttrName, AttrValue>> {
        let snapshot = self.get_snapshot()?;
        if !snapshot.contains_edge(edge) {
            return Err(GraphError::EdgeNotFound {
                edge_id: edge,
                operation: "get historical attributes".to_string(),
                suggestion: "Check if edge exists in this historical state".to_string(),
            });
        }
        
        Ok(snapshot.edge_attributes
            .get(&edge)
            .cloned()
            .unwrap_or_default())
    }
    
    /*
    === GRAPH TOPOLOGY OPERATIONS ===
    Structural queries about the graph
    */
    
    /// Get all neighbors of a node at this historical state
    /// NOTE: For current state, use Graph::neighbors() which is optimized with columnar topology
    pub fn get_neighbors(&mut self, node: NodeId) -> GraphResult<Vec<NodeId>> {
        let snapshot = self.get_snapshot()?;
        snapshot.get_neighbors(node)
    }
    
    /// Get the degree (number of incident edges) of a node
    pub fn get_degree(&mut self, node: NodeId) -> GraphResult<usize> {
        let neighbors = self.get_neighbors(node)?;
        Ok(neighbors.len())
    }
    
    /// Check if two nodes are connected by an edge
    pub fn are_connected(&mut self, node1: NodeId, node2: NodeId) -> GraphResult<bool> {
        let snapshot = self.get_snapshot()?;
        for &(source, target) in snapshot.edges.values() {
            if (source == node1 && target == node2) || 
               (source == node2 && target == node1) {
                return Ok(true);
            }
        }
        Ok(false)
    }
    
    /*
    === METADATA AND INTROSPECTION ===
    Information about the view and the state it represents
    */
    
    /// Get the state ID this view represents
    pub fn state_id(&self) -> StateId {
        self.state_id
    }
    
    /// Get metadata about the state this view represents
    pub fn get_state_metadata(&self) -> GraphResult<&StateMetadata> {
        let _commit = self.history.get_commit(self.state_id)?;
        // For now, create metadata from commit info
        // In a full implementation, we'd have proper StateMetadata stored
        Err(GraphError::NotImplemented {
            feature: "state metadata access".to_string(),
            tracking_issue: Some("Need to implement StateObject integration".to_string()),
        })
    }
    
    /// Check if this view represents a root state (no parent)
    pub fn is_root(&self) -> GraphResult<bool> {
        let commit = self.history.get_commit(self.state_id)?;
        Ok(commit.is_root())
    }
    
    /// Get the parent state ID, if any
    pub fn get_parent(&self) -> GraphResult<Option<StateId>> {
        let commit = self.history.get_commit(self.state_id)?;
        Ok(commit.parents.first().copied())
    }
    
    /// Get all child state IDs
    pub fn get_children(&self) -> Vec<StateId> {
        self.history.get_children(self.state_id)
    }
    
    /// Get a summary of this view's state
    pub fn summary(&mut self) -> GraphResult<ViewSummary> {
        let commit = self.history.get_commit(self.state_id)?;
        let node_count = self.node_count()?;
        let edge_count = self.edge_count()?;
        let children = self.get_children();
        
        Ok(ViewSummary {
            state_id: self.state_id,
            node_count,
            edge_count,
            label: commit.message.clone(),
            author: commit.author.clone(),
            timestamp: commit.timestamp,
            is_root: self.is_root()?,
            has_children: !children.is_empty(),
        })
    }
    
    /*
    === COMPARISON OPERATIONS ===
    Compare this view with other states
    */
    
    /// Compare this view with another view to find differences
    pub fn diff_with(&mut self, other: &mut HistoricalView) -> GraphResult<StateDiff> {
        let our_snapshot = self.get_snapshot()?;
        let their_snapshot = other.get_snapshot()?;
        
        Ok(our_snapshot.diff_with(their_snapshot))
    }
    
    /// Get the path of changes from this state to another state
    pub fn path_to(&self, target_state: StateId) -> GraphResult<Vec<StateId>> {
        // Find the shortest path through the commit DAG using BFS
        use std::collections::{VecDeque, HashSet};
        
        let mut queue = VecDeque::new();
        let mut visited = HashSet::new();
        let mut parents: HashMap<StateId, StateId> = HashMap::new();
        
        queue.push_back(self.state_id);
        visited.insert(self.state_id);
        
        while let Some(current) = queue.pop_front() {
            if current == target_state {
                // Reconstruct path
                let mut path = Vec::new();
                let mut state = target_state;
                
                while state != self.state_id {
                    path.push(state);
                    state = parents[&state];
                }
                
                path.reverse();
                return Ok(path);
            }
            
            // Add children to explore
            for &child in &self.history.get_children(current) {
                if !visited.contains(&child) {
                    visited.insert(child);
                    parents.insert(child, current);
                    queue.push_back(child);
                }
            }
        }
        
        // No path found
        Ok(Vec::new())
    }
}

/// Summary information about a historical view
#[derive(Debug, Clone)]
pub struct ViewSummary {
    pub state_id: StateId,
    pub node_count: usize,
    pub edge_count: usize,
    pub label: String,
    pub author: String,
    pub timestamp: u64,
    pub is_root: bool,
    pub has_children: bool,
}

impl ViewSummary {
    /// Get a human-readable description of this view
    pub fn description(&self) -> String {
        format!(
            "State {}: '{}' by {} ({} nodes, {} edges)",
            self.state_id, self.label, self.author, 
            self.node_count, self.edge_count
        )
    }
    
    /// Get the age of this state in seconds
    pub fn age_seconds(&self) -> u64 {
        let now = crate::util::timestamp_now();
        now.saturating_sub(self.timestamp)
    }
}

/*
=== IMPLEMENTATION NOTES ===

STORAGE EFFICIENCY:
- Content-addressed deltas provide automatic deduplication
- Multiple commits with identical changes share the same Delta
- This is especially effective for automated commits or repeated patterns

PERFORMANCE CHARACTERISTICS:
- Creating commits: O(changes) - just store the delta
- Reconstructing state: O(depth) - need to apply all deltas from root
- Branch operations: O(1) - just update pointers
- Garbage collection: O(total_commits) - need to traverse the DAG

MEMORY MANAGEMENT:
- Use Arc<> for sharing deltas between commits
- Immutable data structures prevent accidental modification
- Garbage collection reclaims unreachable commits

BRANCHING MODEL:
- Lightweight branches (just pointers to commits)
- Support for merge commits (multiple parents)
- No special handling needed for branch creation/deletion

CONSISTENCY GUARANTEES:
- All operations are atomic (either succeed completely or not at all)
- Immutable commits ensure history can't be accidentally corrupted
- Content hashing detects corruption

FUTURE OPTIMIZATIONS:
- Snapshot caching for frequently accessed states
- Compressed storage for large deltas
- Incremental garbage collection
- Parallel state reconstruction
*/

--- FILE: core/state.rs ---
//! State objects, snapshots, and reconstruction for graph history tracking.
//!
//! ARCHITECTURE ROLE:
//! This module provides the complete state management system for graph history.
//! It includes both the historical state metadata (StateObject) and the complete
//! graph state representation (GraphSnapshot) with reconstruction algorithms.
//!
//! DESIGN PHILOSOPHY:
//! - StateObject: Metadata and delta storage for efficient history
//! - GraphSnapshot: Complete state representation for fast access
//! - Reconstruction: Algorithms to build snapshots from deltas
//! - State comparison: Diffing and analysis utilities

use std::sync::Arc;
use std::collections::HashMap;
use crate::types::{StateId, NodeId, EdgeId, AttrName, AttrValue};
use crate::core::delta::DeltaObject;
use crate::core::history::Delta;
use crate::util::timestamp_now;
use crate::errors::{GraphResult, GraphError};

/// Immutable state object - a point in the graph's history
#[derive(Debug, Clone)]
pub struct StateObject {
    /// Parent state (None for root)
    pub parent: Option<StateId>,
    /// Changes from parent
    pub delta: Arc<DeltaObject>,
    /// Metadata
    pub metadata: Arc<StateMetadata>,
}

/// Metadata associated with a state
#[derive(Debug, Clone)]
pub struct StateMetadata {
    /// Human-readable label
    pub label: String,
    /// When this state was created (Unix timestamp)
    pub timestamp: u64,
    /// Who created this state
    pub author: String,
    /// Content hash for verification/deduplication
    pub hash: [u8; 32],
    /// Optional commit message
    pub message: Option<String>,
    /// Tags associated with this state
    pub tags: Vec<String>,
}

impl StateObject {
    /// Create a new state object
    pub fn new(
        parent: Option<StateId>,
        delta: DeltaObject,
        label: String,
        author: String,
        message: Option<String>,
    ) -> Self {
        let metadata = StateMetadata {
            label,
            timestamp: timestamp_now(),
            author,
            hash: delta.content_hash,
            message,
            tags: Vec::new(),
        };

        Self {
            parent,
            delta: Arc::new(delta),
            metadata: Arc::new(metadata),
        }
    }

    /// Create a root state (no parent)
    pub fn new_root(delta: DeltaObject, label: String, author: String) -> Self {
        Self::new(None, delta, label, author, None)
    }

    /// Get the parent state ID
    pub fn parent(&self) -> Option<StateId> {
        self.parent
    }

    /// Get the delta object
    pub fn delta(&self) -> &DeltaObject {
        &self.delta
    }

    /// Get the metadata
    pub fn metadata(&self) -> &StateMetadata {
        &self.metadata
    }

    /// Check if this is a root state (no parent)
    pub fn is_root(&self) -> bool {
        self.parent.is_none()
    }

    /// Get the content hash
    pub fn content_hash(&self) -> [u8; 32] {
        self.metadata.hash
    }

    /// Get the timestamp
    pub fn timestamp(&self) -> u64 {
        self.metadata.timestamp
    }

    /// Get the author
    pub fn author(&self) -> &str {
        &self.metadata.author
    }

    /// Get the label
    pub fn label(&self) -> &str {
        &self.metadata.label
    }

    /// Get the commit message
    pub fn message(&self) -> Option<&str> {
        self.metadata.message.as_deref()
    }

    /// Get tags
    pub fn tags(&self) -> &[String] {
        &self.metadata.tags
    }

    /// Add a tag to this state's metadata
    pub fn add_tag(&mut self, tag: String) {
        // Since metadata is Arc, we need to clone and modify
        let mut metadata = (*self.metadata).clone();
        metadata.tags.push(tag);
        self.metadata = Arc::new(metadata);
    }

    /// Remove a tag from this state's metadata
    pub fn remove_tag(&mut self, tag: &str) {
        let mut metadata = (*self.metadata).clone();
        metadata.tags.retain(|t| t != tag);
        self.metadata = Arc::new(metadata);
    }

    /// Check if this state has a specific tag
    pub fn has_tag(&self, tag: &str) -> bool {
        self.metadata.tags.contains(&tag.to_string())
    }

    /// Update the label
    pub fn set_label(&mut self, label: String) {
        let mut metadata = (*self.metadata).clone();
        metadata.label = label;
        self.metadata = Arc::new(metadata);
    }

    /// Update the message
    pub fn set_message(&mut self, message: Option<String>) {
        let mut metadata = (*self.metadata).clone();
        metadata.message = message;
        self.metadata = Arc::new(metadata);
    }

    /// Get the size of this state's delta in terms of change count
    pub fn delta_size(&self) -> usize {
        self.delta.change_count()
    }

    /// Check if this state represents an empty delta
    pub fn is_empty_delta(&self) -> bool {
        self.delta.is_empty()
    }
}

impl StateMetadata {
    /// Create new metadata
    pub fn new(label: String, author: String, hash: [u8; 32]) -> Self {
        Self {
            label,
            timestamp: timestamp_now(),
            author,
            hash,
            message: None,
            tags: Vec::new(),
        }
    }

    /// Create metadata with a message
    pub fn with_message(label: String, author: String, hash: [u8; 32], message: String) -> Self {
        Self {
            label,
            timestamp: timestamp_now(),
            author,
            hash,
            message: Some(message),
            tags: Vec::new(),
        }
    }

    /// Get a human-readable timestamp
    pub fn timestamp_string(&self) -> String {
        // Convert Unix timestamp to readable format
        // This is a simplified implementation
        format!("timestamp:{}", self.timestamp)
    }

    /// Get a short hash representation
    pub fn short_hash(&self) -> String {
        format!("{:02x}{:02x}{:02x}{:02x}", 
                self.hash[0], self.hash[1], self.hash[2], self.hash[3])
    }
}

/*
=== GRAPH SNAPSHOTS AND STATE RECONSTRUCTION ===
Complete state representation and reconstruction algorithms
*/

/// Complete snapshot of a graph state
/// 
/// DESIGN: This represents the complete graph as it existed at a specific
/// point in time. It's expensive to compute but provides fast access once built.
/// 
/// USAGE: Used by HistoricalView for time travel and potentially
/// GraphSpace for current state representation
/// 
/// PERFORMANCE: Memory-intensive but provides O(1) access to all data
#[derive(Debug, Clone)]
pub struct GraphSnapshot {
    /// All nodes that were active at this state
    /// DESIGN: Vec for iteration, but could be HashSet for contains() queries
    pub active_nodes: Vec<NodeId>,
    
    /// All edges that were active at this state
    /// Maps edge_id -> (source_node, target_node)
    pub edges: HashMap<EdgeId, (NodeId, NodeId)>,
    
    /// All node attributes at this state
    /// Maps node_id -> (attribute_name -> attribute_value)
    pub node_attributes: HashMap<NodeId, HashMap<AttrName, AttrValue>>,
    
    /// All edge attributes at this state
    /// Maps edge_id -> (attribute_name -> attribute_value)
    pub edge_attributes: HashMap<EdgeId, HashMap<AttrName, AttrValue>>,
    
    /// The state ID this snapshot represents
    pub state_id: StateId,
}

impl GraphSnapshot {
    /// Create an empty snapshot for the given state
    pub fn empty(state_id: StateId) -> Self {
        Self {
            active_nodes: Vec::new(),
            edges: HashMap::new(),
            node_attributes: HashMap::new(),
            edge_attributes: HashMap::new(),
            state_id,
        }
    }
    
    /// Apply a delta to this snapshot to create a new snapshot
    /// 
    /// ALGORITHM:
    /// 1. Start with a copy of this snapshot
    /// 2. Apply node additions/removals from delta
    /// 3. Apply edge additions/removals from delta
    /// 4. Apply attribute changes from delta
    /// 5. Update state_id to target state
    /// 6. Return the new snapshot
    /// 
    /// PERFORMANCE: O(changes in delta + size of current snapshot for cloning)
    pub fn apply_delta(&self, delta: &Delta, target_state: StateId) -> Self {
        let mut new_snapshot = self.clone();
        new_snapshot.state_id = target_state;
        
        // Apply node additions
        for &node_id in &delta.nodes_added {
            if !new_snapshot.active_nodes.contains(&node_id) {
                new_snapshot.active_nodes.push(node_id);
            }
        }
        
        // Apply node removals
        for &node_id in &delta.nodes_removed {
            new_snapshot.active_nodes.retain(|&id| id != node_id);
            new_snapshot.node_attributes.remove(&node_id);
        }
        
        // Apply edge additions
        for &(edge_id, source, target) in &delta.edges_added {
            new_snapshot.edges.insert(edge_id, (source, target));
        }
        
        // Apply edge removals
        for &edge_id in &delta.edges_removed {
            new_snapshot.edges.remove(&edge_id);
            new_snapshot.edge_attributes.remove(&edge_id);
        }
        
        // Apply node attribute changes
        for (node_id, attr_name, _old_value, new_value) in &delta.node_attr_changes {
            let attrs = new_snapshot.node_attributes.entry(*node_id).or_insert_with(HashMap::new);
            attrs.insert(attr_name.clone(), new_value.clone());
        }
        
        // Apply edge attribute changes
        for (edge_id, attr_name, _old_value, new_value) in &delta.edge_attr_changes {
            let attrs = new_snapshot.edge_attributes.entry(*edge_id).or_insert_with(HashMap::new);
            attrs.insert(attr_name.clone(), new_value.clone());
        }
        
        new_snapshot
    }
    
    /// Create a snapshot by applying a sequence of deltas
    /// 
    /// ALGORITHM:
    /// 1. Start with base snapshot (or empty)
    /// 2. Apply each delta in sequence
    /// 3. Return final snapshot
    /// 
    /// USAGE: This is the main reconstruction function used by HistoryForest
    pub fn reconstruct_from_deltas(
        base: Option<&GraphSnapshot>, 
        deltas: &[(Delta, StateId)]
    ) -> GraphResult<Self> {
        let mut current = base.cloned().unwrap_or_else(|| {
            GraphSnapshot::empty(0)
        });
        
        for (delta, target_state) in deltas {
            current = current.apply_delta(delta, *target_state);
        }
        
        Ok(current)
    }
    
    /// Compare this snapshot with another to produce a diff
    /// 
    /// ALGORITHM:
    /// 1. Compare active nodes (added/removed)
    /// 2. Compare edges (added/removed)  
    /// 3. Compare all attributes (changed values)
    /// 4. Return structured diff
    pub fn diff_with(&self, other: &GraphSnapshot) -> StateDiff {
        use std::collections::HashSet;
        
        let self_nodes: HashSet<_> = self.active_nodes.iter().collect();
        let other_nodes: HashSet<_> = other.active_nodes.iter().collect();
        
        let nodes_added = other.active_nodes.iter()
            .filter(|&&node| !self_nodes.contains(&node))
            .cloned()
            .collect();
        
        let nodes_removed = self.active_nodes.iter()
            .filter(|&&node| !other_nodes.contains(&node))
            .cloned()
            .collect();
        
        // Compare edges
        let edges_added = other.edges.iter()
            .filter(|(edge_id, _)| !self.edges.contains_key(edge_id))
            .map(|(edge_id, &(source, target))| (*edge_id, source, target))
            .collect();
        
        let edges_removed = self.edges.iter()
            .filter(|(edge_id, _)| !other.edges.contains_key(edge_id))
            .map(|(edge_id, _)| *edge_id)
            .collect();
        
        // Compare attributes
        let mut attribute_changes = Vec::new();
        
        // Node attribute changes
        for &node_id in &other.active_nodes {
            let self_attrs = self.node_attributes.get(&node_id).cloned().unwrap_or_default();
            let other_attrs = other.node_attributes.get(&node_id).cloned().unwrap_or_default();
            
            for (attr_name, new_value) in &other_attrs {
                let old_value = self_attrs.get(attr_name).cloned();
                if old_value.as_ref() != Some(new_value) {
                    attribute_changes.push(AttributeChange {
                        entity_type: EntityType::Node,
                        entity_id: node_id as u64,
                        attr_name: attr_name.clone(),
                        old_value,
                        new_value: Some(new_value.clone()),
                    });
                }
            }
            
            // Check for removed attributes
            for (attr_name, old_value) in &self_attrs {
                if !other_attrs.contains_key(attr_name) {
                    attribute_changes.push(AttributeChange {
                        entity_type: EntityType::Node,
                        entity_id: node_id as u64,
                        attr_name: attr_name.clone(),
                        old_value: Some(old_value.clone()),
                        new_value: None,
                    });
                }
            }
        }
        
        // Edge attribute changes
        for &edge_id in other.edges.keys() {
            let self_attrs = self.edge_attributes.get(&edge_id).cloned().unwrap_or_default();
            let other_attrs = other.edge_attributes.get(&edge_id).cloned().unwrap_or_default();
            
            for (attr_name, new_value) in &other_attrs {
                let old_value = self_attrs.get(attr_name).cloned();
                if old_value.as_ref() != Some(new_value) {
                    attribute_changes.push(AttributeChange {
                        entity_type: EntityType::Edge,
                        entity_id: edge_id as u64,
                        attr_name: attr_name.clone(),
                        old_value,
                        new_value: Some(new_value.clone()),
                    });
                }
            }
            
            // Check for removed attributes
            for (attr_name, old_value) in &self_attrs {
                if !other_attrs.contains_key(attr_name) {
                    attribute_changes.push(AttributeChange {
                        entity_type: EntityType::Edge,
                        entity_id: edge_id as u64,
                        attr_name: attr_name.clone(),
                        old_value: Some(old_value.clone()),
                        new_value: None,
                    });
                }
            }
        }
        
        StateDiff {
            from_state: self.state_id,
            to_state: other.state_id,
            nodes_added,
            nodes_removed,
            edges_added,
            edges_removed,
            attribute_changes,
        }
    }
    
    /// Get basic statistics about this snapshot
    pub fn statistics(&self) -> SnapshotStatistics {
        SnapshotStatistics {
            node_count: self.active_nodes.len(),
            edge_count: self.edges.len(),
            node_attr_count: self.node_attributes.values()
                .map(|attrs| attrs.len()).sum(),
            edge_attr_count: self.edge_attributes.values()
                .map(|attrs| attrs.len()).sum(),
            memory_usage: self.estimate_memory_usage(),
        }
    }
    
    /// Estimate memory usage of this snapshot in bytes
    fn estimate_memory_usage(&self) -> usize {
        let mut total = 0;
        
        // Vec<NodeId>
        total += self.active_nodes.len() * std::mem::size_of::<NodeId>();
        
        // HashMap<EdgeId, (NodeId, NodeId)>
        total += self.edges.len() * (std::mem::size_of::<EdgeId>() + std::mem::size_of::<(NodeId, NodeId)>());
        
        // HashMap<NodeId, HashMap<AttrName, AttrValue>>
        for (_, attrs) in &self.node_attributes {
            total += std::mem::size_of::<NodeId>();
            for (_name, value) in attrs {
                total += std::mem::size_of::<AttrName>();
                total += match value {
                    AttrValue::Text(s) => s.len(),
                    AttrValue::Int(_) => std::mem::size_of::<i64>(),
                    AttrValue::Float(_) => std::mem::size_of::<f64>(),
                    AttrValue::Bool(_) => std::mem::size_of::<bool>(),
                    AttrValue::FloatVec(v) => v.len() * std::mem::size_of::<f32>(),
                    AttrValue::CompactText(cs) => cs.memory_size(),
                    AttrValue::SmallInt(_) => std::mem::size_of::<i32>(),
                    AttrValue::Bytes(b) => b.len(),
                    AttrValue::CompressedText(cd) => cd.memory_size(),
                    AttrValue::CompressedFloatVec(cd) => cd.memory_size(),
                };
            }
        }
        
        // HashMap<EdgeId, HashMap<AttrName, AttrValue>>
        for (_, attrs) in &self.edge_attributes {
            total += std::mem::size_of::<EdgeId>();
            for (_name, value) in attrs {
                total += std::mem::size_of::<AttrName>();
                total += match value {
                    AttrValue::Text(s) => s.len(),
                    AttrValue::Int(_) => std::mem::size_of::<i64>(),
                    AttrValue::Float(_) => std::mem::size_of::<f64>(),
                    AttrValue::Bool(_) => std::mem::size_of::<bool>(),
                    AttrValue::FloatVec(v) => v.len() * std::mem::size_of::<f32>(),
                    AttrValue::CompactText(cs) => cs.memory_size(),
                    AttrValue::SmallInt(_) => std::mem::size_of::<i32>(),
                    AttrValue::Bytes(b) => b.len(),
                    AttrValue::CompressedText(cd) => cd.memory_size(),
                    AttrValue::CompressedFloatVec(cd) => cd.memory_size(),
                };
            }
        }
        
        total
    }
    
    /// Check if a node exists in this snapshot
    pub fn contains_node(&self, node_id: NodeId) -> bool {
        self.active_nodes.contains(&node_id)
    }
    
    /// Check if an edge exists in this snapshot
    pub fn contains_edge(&self, edge_id: EdgeId) -> bool {
        self.edges.contains_key(&edge_id)
    }
    

}

/*
=== STATE COMPARISON AND DIFFING ===
*/

/// Difference between two graph states
/// 
/// DESIGN: Structured representation of all changes between two snapshots
/// USAGE: Used for commit diffs, merge analysis, change visualization
#[derive(Debug, Clone)]
pub struct StateDiff {
    pub from_state: StateId,
    pub to_state: StateId,
    pub nodes_added: Vec<NodeId>,
    pub nodes_removed: Vec<NodeId>,
    pub edges_added: Vec<(EdgeId, NodeId, NodeId)>,
    pub edges_removed: Vec<EdgeId>,
    pub attribute_changes: Vec<AttributeChange>,
}

impl StateDiff {
    /// Create an empty diff between two states
    pub fn empty(from_state: StateId, to_state: StateId) -> Self {
        Self {
            from_state,
            to_state,
            nodes_added: Vec::new(),
            nodes_removed: Vec::new(),
            edges_added: Vec::new(),
            edges_removed: Vec::new(),
            attribute_changes: Vec::new(),
        }
    }
    
    /// Check if this diff represents any changes
    pub fn is_empty(&self) -> bool {
        self.nodes_added.is_empty() && 
        self.nodes_removed.is_empty() &&
        self.edges_added.is_empty() &&
        self.edges_removed.is_empty() &&
        self.attribute_changes.is_empty()
    }
    
    /// Get a summary of the changes in this diff
    pub fn summary(&self) -> DiffSummary {
        DiffSummary {
            from_state: self.from_state,
            to_state: self.to_state,
            nodes_changed: self.nodes_added.len() + self.nodes_removed.len(),
            edges_changed: self.edges_added.len() + self.edges_removed.len(),
            attributes_changed: self.attribute_changes.len(),
        }
    }
}

/// A single attribute change between states
#[derive(Debug, Clone)]
pub struct AttributeChange {
    pub entity_type: EntityType,
    pub entity_id: u64,
    pub attr_name: AttrName,
    pub old_value: Option<AttrValue>,
    pub new_value: Option<AttrValue>,
}

#[derive(Debug, Clone)]
pub enum EntityType {
    Node,
    Edge,
}

/// Statistics about a snapshot
#[derive(Debug, Clone)]
pub struct SnapshotStatistics {
    pub node_count: usize,
    pub edge_count: usize,
    pub node_attr_count: usize,
    pub edge_attr_count: usize,
    pub memory_usage: usize,
}

/// Summary of changes in a StateDiff
#[derive(Debug, Clone)]
pub struct DiffSummary {
    pub from_state: StateId,
    pub to_state: StateId,
    pub nodes_changed: usize,
    pub edges_changed: usize,
    pub attributes_changed: usize,
}

/*
=== STATE UTILITIES ===
Helper functions for working with states
*/

/// Merge two snapshots (for branch merging)
/// 
/// ALGORITHM:
/// 1. Union of active nodes and edges
/// 2. Merge attributes (conflict resolution needed)
/// 3. Create new snapshot with merged state
pub fn merge_snapshots(
    _base: &GraphSnapshot,
    _branch1: &GraphSnapshot, 
    _branch2: &GraphSnapshot,
    _target_state: StateId
) -> GraphResult<GraphSnapshot> {
    // TODO: Complex merge algorithm
    // This is needed for git-like branch merging
    todo!("Implement merge_snapshots")
}

/// Validate that a snapshot is internally consistent
/// 
/// CHECKS:
/// 1. All edges reference active nodes
/// 2. All attribute maps reference active entities
/// 3. No duplicate IDs
pub fn validate_snapshot(_snapshot: &GraphSnapshot) -> GraphResult<()> {
    // TODO:
    // // Check edge endpoints are active nodes
    // for &(source, target) in snapshot.edges.values() {
    //     if !snapshot.contains_node(source) || !snapshot.contains_node(target) {
    //         return Err(GraphError::InvalidSnapshot);
    //     }
    // }
    // 
    // // Check attribute maps only reference active entities
    // // ... more validation logic
    // 
    // Ok(())
    todo!("Implement validate_snapshot")
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::core::delta::DeltaObject;

    #[test]
    fn test_state_object_creation() {
        let delta = DeltaObject::empty();
        let state = StateObject::new_root(
            delta,
            "Initial state".to_string(),
            "test_user".to_string(),
        );

        assert!(state.is_root());
        assert_eq!(state.label(), "Initial state");
        assert_eq!(state.author(), "test_user");
        assert!(state.is_empty_delta());
    }

    #[test]
    fn test_state_tags() {
        let delta = DeltaObject::empty();
        let mut state = StateObject::new_root(
            delta,
            "Tagged state".to_string(),
            "test_user".to_string(),
        );

        state.add_tag("important".to_string());
        state.add_tag("milestone".to_string());

        assert!(state.has_tag("important"));
        assert!(state.has_tag("milestone"));
        assert!(!state.has_tag("nonexistent"));

        state.remove_tag("important");
        assert!(!state.has_tag("important"));
        assert!(state.has_tag("milestone"));
    }
}


--- FILE: core/space.rs ---
//! Graph Space - Active State Tracker
//!
//! ARCHITECTURE ROLE:
//! GraphSpace is a **minimal active state tracker**. It simply knows which
//! nodes and edges are currently "active" and tracks changes. The actual
//! graph operations happen in the Graph coordinator.
//!
//! DESIGN PHILOSOPHY:
//! - GraphSpace = Active Set + Change Tracking (minimal responsibility)
//! - Graph = Operations & Coordination (delegates to pool for data)
//! - GraphPool = Pure Data Storage (the "database tables")
//! - Keep GraphSpace minimal and focused

/*
=== GRAPH SPACE RESPONSIBILITIES ===

GraphSpace is JUST the active state tracker and change recorder.
It's not a full interface - that's Graph's job.

KEY RESPONSIBILITIES:
1. ACTIVE SET MANAGEMENT: Track which nodes/edges are currently active
2. CHANGE TRACKING: Record every modification for history commits
3. WORKSPACE STATE: Basic queries about current active state

WHAT BELONGS HERE:
- active_nodes, active_edges HashSets
- NOTE: change tracking moved to Graph for cleaner separation
- Simple queries: node_count(), contains_node(), etc.
- Workspace management: reset(), state queries, etc.

WHAT DOESN'T BELONG HERE:
- Graph operations like add_node(), set_attr() (that's Graph's job)
- Complex topology queries (Graph delegates to Pool)
- History operations (that's HistoryForest's job)
- Analytics (that's QueryEngine's job)
*/

use std::collections::{HashMap, HashSet};
use std::sync::{Arc, RwLock};
use std::rc::Rc;
use crate::types::{NodeId, EdgeId, AttrName, StateId};
use crate::errors::GraphResult;
use crate::core::pool::GraphPool;
use crate::core::delta::DeltaObject;

/// Snapshot of topology data that can be used without holding locks
#[derive(Debug, Clone)]
pub struct TopologySnapshot {
    pub edge_ids: Arc<Vec<EdgeId>>,
    pub sources: Arc<Vec<NodeId>>,
    pub targets: Arc<Vec<NodeId>>,
    pub neighbors: Arc<HashMap<NodeId, Vec<(NodeId, EdgeId)>>>,
    pub version: u64,
}

/// Internal cache state with RwLock for read-heavy access
#[derive(Debug)]
struct CacheState {
    built_version: u64,
    snapshot: Option<TopologySnapshot>,
}

impl CacheState {
    fn new() -> Self {
        Self {
            built_version: 0,
            snapshot: None,
        }
    }
    
    fn try_get_snapshot(&self, current_version: u64) -> Option<TopologySnapshot> {
        if self.built_version == current_version {
            self.snapshot.clone()
        } else {
            None
        }
    }
    
    fn set_snapshot(&mut self, snapshot: TopologySnapshot) {
        self.built_version = snapshot.version;
        self.snapshot = Some(snapshot);
    }
}

/// Minimal active state tracker for the current graph
/// 
/// DESIGN: GraphSpace is just the "active set" tracker. It knows which
/// nodes and edges are currently active, and tracks changes for commits.
/// The Graph coordinator handles actual operations.
/// 
/// KEY INSIGHT: 
/// - GraphSpace = Active Sets + Change Tracking (minimal)
/// - Graph = Operations & Coordination
/// - GraphPool = Pure Data Storage
/// 
/// LIFECYCLE:
/// 1. Created from a historical state (or empty)  
/// 2. Graph calls methods to update active sets
/// 3. Changes tracked automatically
/// 4. Eventually committed to create new historical state
#[derive(Debug)]
pub struct GraphSpace {
    /*
    === ACTIVE SETS - Plain containers (no RefCell) ===
    */
    
    /// All currently active (not deleted) nodes
    active_nodes: HashSet<NodeId>,
    
    /// All currently active (not deleted) edges  
    active_edges: HashSet<EdgeId>,
    
    /*
    === POOL REFERENCE ===
    */
    
    /// Shared reference to the graph pool for topology rebuilding
    pool: Rc<std::cell::RefCell<GraphPool>>,
    
    /*
    === VERSION COUNTER - Plain u64 ===
    */
    
    /// Version counter - increments on structural changes
    version: u64,
    
    /*
    === CACHE - RwLock for read-heavy, occasional write ===
    */
    
    /// Cache state with RwLock for lock-free reads
    cache: RwLock<CacheState>,
    
    /*
    === ATTRIBUTE INDEX MAPPINGS - Plain HashMaps ===
    */
    
    /// Maps attribute_name -> node -> column_index (OPTIMIZED: attribute-first for bulk filtering)
    node_attribute_indices: HashMap<AttrName, HashMap<NodeId, usize>>,
    
    /// Maps attribute_name -> edge -> column_index (OPTIMIZED: attribute-first for bulk filtering)
    edge_attribute_indices: HashMap<AttrName, HashMap<EdgeId, usize>>,
    
    /*
    === WORKSPACE METADATA ===
    */
    
    /// Which historical state this workspace is based on
    base_state: StateId,
}

impl GraphSpace {
    /// Create a new empty graph space 
    pub fn new(pool: Rc<std::cell::RefCell<GraphPool>>, base_state: StateId) -> Self {
        Self {
            active_nodes: HashSet::new(),
            active_edges: HashSet::new(),
            pool,
            version: 1, // Start at 1 so empty cache (version 0) is immediately stale
            cache: RwLock::new(CacheState::new()),
            node_attribute_indices: HashMap::new(),
            edge_attribute_indices: HashMap::new(),
            base_state,
        }
    }


    /*
    === ACTIVE SET MANAGEMENT ===
    Legacy methods for external activation/deactivation
    */

    /// Add a node to the active set (&mut self)
    pub fn activate_node(&mut self, node_id: NodeId) {
        self.active_nodes.insert(node_id);
    }

    
    /// Bulk activate nodes (&mut self - PERFORMANCE: single extend call)
    pub fn activate_nodes<I: IntoIterator<Item = NodeId>>(&mut self, nodes: I) {
        self.active_nodes.extend(nodes);
    }

    /// Remove multiple nodes from the active set (&mut self)
    pub fn deactivate_nodes(&mut self, nodes: &[NodeId]) {
        let to_remove: HashSet<NodeId> = nodes.iter().copied().collect();
        self.active_nodes.retain(|n| !to_remove.contains(n));
        // Remove nodes from all attribute indices
        for (_, nodes_map) in self.node_attribute_indices.iter_mut() {
            for node_id in &to_remove {
                nodes_map.remove(node_id);
            }
        }
    }

    /// Remove a node from the active set (&mut self)
    pub fn deactivate_node(&mut self, node_id: NodeId) {
        self.active_nodes.remove(&node_id);
        // Remove node from all attribute indices
        for (_, nodes) in self.node_attribute_indices.iter_mut() {
            nodes.remove(&node_id);
        }
    }

    /// Add an edge to the active set (&mut self - increments version for topology cache invalidation)
    pub fn activate_edge(&mut self, edge_id: EdgeId, _source: NodeId, _target: NodeId) {
        self.active_edges.insert(edge_id);
        self.version += 1; // invalidate topology cache
    }

    /// Remove an edge from the active set (&mut self)
    pub fn deactivate_edge(&mut self, edge_id: EdgeId) {
        self.active_edges.remove(&edge_id);
        // Remove edge from all attribute indices
        for (_, edges) in self.edge_attribute_indices.iter_mut() {
            edges.remove(&edge_id);
        }
        self.version += 1;
    }
    
    /// Bulk activate edges (&mut self)
    pub fn activate_edges<I: IntoIterator<Item = EdgeId>>(&mut self, edges: I) {
        self.active_edges.extend(edges);
        self.version += 1;
    }
    

    /// Remove multiple edges from the active set (&mut self)
    pub fn deactivate_edges(&mut self, edges: &[EdgeId]) {
        let to_remove: HashSet<EdgeId> = edges.iter().copied().collect();
        self.active_edges.retain(|e| !to_remove.contains(e));
        // Remove edges from all attribute indices
        for (_, edges_map) in self.edge_attribute_indices.iter_mut() {
            for edge_id in &to_remove {
                edges_map.remove(edge_id);
            }
        }
        self.version += 1;
    }

    /*
    === CURRENT INDEX MAPPINGS ===
    Space ONLY manages which entities have which current attribute indices
    Graph coordinates between Space (current state) and ChangeTracker (deltas)
    */
    
    /// Update the current attribute index for any entity (&mut self)
    pub fn set_attr_index<T>(&mut self, entity_id: T, attr_name: AttrName, new_index: usize, is_node: bool) 
    where T: Into<usize> + Copy {
        let id = entity_id.into();
        if is_node {
            self.node_attribute_indices
                .entry(attr_name)
                .or_default()
                .insert(id as NodeId, new_index);
        } else {
            self.edge_attribute_indices
                .entry(attr_name)
                .or_default()
                .insert(id as EdgeId, new_index);
        }
    }
    
    /// Get current attribute index for any entity (&self - read-only)
    pub fn get_attr_index<T>(&self, entity_id: T, attr_name: &AttrName, is_node: bool) -> Option<usize> 
    where T: Into<usize> + Copy {
        let id = entity_id.into();
        if is_node {
            self.node_attribute_indices
                .get(attr_name)
                .and_then(|nodes| nodes.get(&(id as NodeId)))
                .copied()
        } else {
            self.edge_attribute_indices
                .get(attr_name)
                .and_then(|edges| edges.get(&(id as EdgeId)))
                .copied()
        }
    }
    
    /// Get current attribute index for a node (&self - read-only)
    pub fn get_node_attr_index(&self, node_id: NodeId, attr_name: &AttrName) -> Option<usize> {
        self.node_attribute_indices
            .get(attr_name)
            .and_then(|nodes| nodes.get(&node_id))
            .copied()
    }
    
    /// Get specific attribute indices for multiple nodes in one call (ULTRA-OPTIMIZED: attribute-first)
    /// 
    /// PERFORMANCE: Single attribute lookup + fast node iteration instead of N*2 HashMap lookups
    /// OLD: 50k * (node_lookup + attr_lookup) = 100k HashMap operations
    /// NEW: 1 * attr_lookup + 50k * (direct HashMap get) = 1 + 50k operations
    pub fn get_node_attr_indices_for_attr(&self, node_ids: &[NodeId], attr_name: &AttrName) -> Vec<(NodeId, Option<usize>)> {
        // Single attribute lookup to get all nodes with this attribute
        if let Some(attr_nodes) = self.node_attribute_indices.get(attr_name) {
            // Fast iteration through requested nodes with direct HashMap access
            node_ids
                .iter()
                .map(|&node_id| (node_id, attr_nodes.get(&node_id).copied()))
                .collect()
        } else {
            // No nodes have this attribute - return all None
            node_ids.iter().map(|&node_id| (node_id, None)).collect()
        }
    }
    
    /// Set current attribute index for a node (&mut self)
    pub fn set_node_attr_index(&mut self, node_id: NodeId, attr_name: AttrName, new_index: usize) {
        self.node_attribute_indices
            .entry(attr_name)
            .or_default()
            .insert(node_id, new_index);
    }
    
    /// Get current attribute index for an edge (&self - read-only)
    pub fn get_edge_attr_index(&self, edge_id: EdgeId, attr_name: &AttrName) -> Option<usize> {
        self.edge_attribute_indices
            .get(attr_name)
            .and_then(|edges| edges.get(&edge_id))
            .copied()
    }
    
    /// Set current attribute index for an edge (&mut self)
    pub fn set_edge_attr_index(&mut self, edge_id: EdgeId, attr_name: AttrName, new_index: usize) {
        self.edge_attribute_indices
            .entry(attr_name)
            .or_default()
            .insert(edge_id, new_index);
    }
    
    /// Get specific attribute indices for multiple edges in one call (ULTRA-OPTIMIZED: attribute-first)
    pub fn get_edge_attr_indices_for_attr(&self, edge_ids: &[EdgeId], attr_name: &AttrName) -> Vec<(EdgeId, Option<usize>)> {
        // Single attribute lookup to get all edges with this attribute
        if let Some(attr_edges) = self.edge_attribute_indices.get(attr_name) {
            // Fast iteration through requested edges with direct HashMap access
            edge_ids
                .iter()
                .map(|&edge_id| (edge_id, attr_edges.get(&edge_id).copied()))
                .collect()
        } else {
            // No edges have this attribute - return all None
            edge_ids.iter().map(|&edge_id| (edge_id, None)).collect()
        }
    }
    
    /// Get all attribute names and indices for a node (&self - read-only)
    pub fn get_node_attr_indices(&self, node_id: NodeId) -> HashMap<AttrName, usize> {
        let mut result = HashMap::new();
        for (attr_name, nodes) in &self.node_attribute_indices {
            if let Some(&index) = nodes.get(&node_id) {
                result.insert(attr_name.clone(), index);
            }
        }
        result
    }
    
    /// Get all attribute names and indices for an edge (&self - read-only)
    pub fn get_edge_attr_indices(&self, edge_id: EdgeId) -> HashMap<AttrName, usize> {
        let mut result = HashMap::new();
        for (attr_name, edges) in &self.edge_attribute_indices {
            if let Some(&index) = edges.get(&edge_id) {
                result.insert(attr_name.clone(), index);
            }
        }
        result
    }

    /*
    === COLUMNAR FILTERING OPTIMIZATION ===
    Bulk attribute operations for vectorized filtering
    */
    
    /// Get attribute indices for all active nodes (&self - ULTRA-OPTIMIZED: attribute-first)
    pub fn get_attribute_indices_nodes(&self, attr_name: &AttrName) -> Vec<(NodeId, Option<usize>)> {
        if let Some(attr_nodes) = self.node_attribute_indices.get(attr_name) {
            self.active_nodes
                .iter()
                .map(|&node_id| (node_id, attr_nodes.get(&node_id).copied()))
                .collect()
        } else {
            self.active_nodes
                .iter()
                .map(|&node_id| (node_id, None))
                .collect()
        }
    }
    
    /// Get attribute indices for all active edges (&self - ULTRA-OPTIMIZED: attribute-first)
    pub fn get_attribute_indices_edges(&self, attr_name: &AttrName) -> Vec<(EdgeId, Option<usize>)> {
        if let Some(attr_edges) = self.edge_attribute_indices.get(attr_name) {
            self.active_edges
                .iter()
                .map(|&edge_id| (edge_id, attr_edges.get(&edge_id).copied()))
                .collect()
        } else {
            self.active_edges
                .iter()
                .map(|&edge_id| (edge_id, None))
                .collect()
        }
    }
    
    /// Get attribute values for all active nodes in columnar format (&self - OPTIMIZED)
    pub fn get_attributes_nodes<'a>(&self, 
        pool: &'a GraphPool, 
        attr_name: &AttrName
    ) -> Vec<(NodeId, Option<&'a crate::types::AttrValue>)> {
        let entity_indices = self.get_attribute_indices_nodes(attr_name);
        pool.get_attribute_values(attr_name, &entity_indices, true)
    }
    
    /// Get attribute values for all active edges in columnar format (&self - OPTIMIZED)
    pub fn get_attributes_edges<'a>(&self, 
        pool: &'a GraphPool, 
        attr_name: &AttrName
    ) -> Vec<(EdgeId, Option<&'a crate::types::AttrValue>)> {
        let entity_indices = self.get_attribute_indices_edges(attr_name);
        pool.get_attribute_values(attr_name, &entity_indices, false)
    }

    /// Get nodes that have a specific attribute (ULTRA-OPTIMIZED: direct attribute lookup)
    /// 
    /// PERFORMANCE: Direct O(1) lookup + iteration instead of checking N nodes
    /// OLD: Iterate all nodes, check if each has attribute
    /// NEW: Direct lookup of attribute -> get all nodes with it
    pub fn get_nodes_with_attribute(&self, attr_name: &AttrName) -> Vec<NodeId> {
        if let Some(attr_nodes) = self.node_attribute_indices.get(attr_name) {
            attr_nodes.keys().copied().collect()
        } else {
            Vec::new()
        }
    }

    /// Get attribute values for a specific subset of nodes in bulk (ULTRA-OPTIMIZED)
    /// 
    /// PERFORMANCE: Eliminates all HashMap lookups for large sparse attribute queries
    /// This is what the query system should actually use
    /// Get attribute values for specific nodes (ULTRA-OPTIMIZED: no RefCell churn)
    pub fn get_attributes_for_nodes<'a>(
        &self,
        pool: &'a GraphPool,
        attr_name: &AttrName,
        node_ids: &[NodeId]
    ) -> Vec<(NodeId, Option<&'a crate::types::AttrValue>)> {
        
        let start_time = std::time::Instant::now();
        
        // PERFORMANCE: Bulk index lookup in single call
        let entity_indices = self.get_node_attr_indices_for_attr(node_ids, attr_name);
        
        let index_time = start_time.elapsed();
        let start_time = std::time::Instant::now();
        
        // Single pool call for bulk attribute retrieval
        let values = pool.get_attribute_values(attr_name, &entity_indices, true);
        
        let pool_time = start_time.elapsed();
        
        values
    }

    /// Get attribute values for specific edges (ULTRA-OPTIMIZED: no RefCell churn)
    pub fn get_attributes_for_edges<'a>(
        &self,
        pool: &'a GraphPool,
        attr_name: &AttrName,
        edge_ids: &[EdgeId]
    ) -> Vec<(EdgeId, Option<&'a crate::types::AttrValue>)> {
        
        // PERFORMANCE: Bulk index lookup in single call
        let entity_indices = self.get_edge_attr_indices_for_attr(edge_ids, attr_name);

        // Single pool call for bulk attribute retrieval
        pool.get_attribute_values(attr_name, &entity_indices, false)
    }

    /*
    === SIMPLE ACTIVE STATE QUERIES ===
    Basic information about what's currently active
    */

    /// Get the number of active nodes (&self - read-only)
    pub fn node_count(&self) -> usize {
        self.active_nodes.len()
    }

    /// Get the number of active edges (&self - read-only)
    pub fn edge_count(&self) -> usize {
        self.active_edges.len()
    }

    /// Check if a node is currently active (&self - read-only)
    pub fn contains_node(&self, node_id: NodeId) -> bool {
        self.active_nodes.contains(&node_id)
    }

    /// Check if an edge is currently active (&self - read-only)
    pub fn contains_edge(&self, edge_id: EdgeId) -> bool {
        self.active_edges.contains(&edge_id)
    }

    /// Get all active node IDs (compatibility with old RefCell API)
    pub fn get_active_nodes(&self) -> HashSet<NodeId> {
        self.active_nodes.clone()
    }
    
    /// Get all active edge IDs (compatibility with old RefCell API)
    pub fn get_active_edges(&self) -> HashSet<EdgeId> {
        self.active_edges.clone()
    }

    /*
    === BASIC QUERIES ===
    Simple active set queries - topology handled by Graph coordinator
    */

    /// Get all active node IDs as a vector (&self - read-only)
    pub fn node_ids(&self) -> Vec<NodeId> {
        self.active_nodes.iter().copied().collect()
    }

    /// Get all active edge IDs as a vector (&self - read-only)
    pub fn edge_ids(&self) -> Vec<EdgeId> {
        self.active_edges.iter().copied().collect()
    }
    
    /*
    === UNIFIED CACHE ACCESS ===
    Single method to get consistent topology and adjacency data with interior mutability
    */
    
    /// Get consistent snapshot of topology and adjacency data (RwLock for read-heavy access)
    pub fn snapshot(&self, pool: &GraphPool) -> (Arc<Vec<EdgeId>>, Arc<Vec<NodeId>>, Arc<Vec<NodeId>>, Arc<HashMap<NodeId, Vec<(NodeId, EdgeId)>>>) {
        let current_version = self.version;

        // Fast path: read-lock and try to get cached snapshot
        {
            let cache = self.cache.read().unwrap();
            if let Some(snapshot) = cache.try_get_snapshot(current_version) {
                return (snapshot.edge_ids, snapshot.sources, snapshot.targets, snapshot.neighbors);
            }
        }

        // Slow path: write-lock and rebuild if still stale
        let mut cache = self.cache.write().unwrap();
        
        // Double-check after acquiring write lock (another thread might have rebuilt)
        if let Some(snapshot) = cache.try_get_snapshot(current_version) {
            return (snapshot.edge_ids, snapshot.sources, snapshot.targets, snapshot.neighbors);
        }

        // Rebuild topology cache
        let (edge_ids, sources, targets) = self.rebuild_topology(pool);
        
        // Build adjacency map from columnar topology (O(E))
        // DIRECTED: Only add source → target edges
        // UNDIRECTED: Add both source ↔ target edges for traversal
        let mut neighbors = HashMap::<NodeId, Vec<(NodeId, EdgeId)>>::new();
        let graph_type = pool.graph_type();
        
        for (i, &edge_id) in edge_ids.iter().enumerate() {
            let u = sources[i];
            let v = targets[i];
            
            // Always add the primary direction (source → target)
            neighbors.entry(u).or_default().push((v, edge_id));
            
            // For undirected graphs, also add the reverse direction (target → source)  
            if graph_type == crate::types::GraphType::Undirected {
                neighbors.entry(v).or_default().push((u, edge_id));
            }
        }

        // Create Arc-wrapped data for zero-copy sharing
        let edge_ids_arc = Arc::new(edge_ids);
        let sources_arc = Arc::new(sources);
        let targets_arc = Arc::new(targets);
        let neighbors_arc = Arc::new(neighbors);

        let snapshot = TopologySnapshot {
            edge_ids: edge_ids_arc.clone(),
            sources: sources_arc.clone(),
            targets: targets_arc.clone(),
            neighbors: neighbors_arc.clone(),
            version: current_version,
        };

        cache.set_snapshot(snapshot);
        (edge_ids_arc, sources_arc, targets_arc, neighbors_arc)
    }
    
    /// Rebuild columnar topology from active edges (PERFORMANCE: O(E))
    fn rebuild_topology(&self, pool: &GraphPool) -> (Vec<EdgeId>, Vec<NodeId>, Vec<NodeId>) {
        let edge_count = self.active_edges.len();
        let mut edge_ids = Vec::with_capacity(edge_count);
        let mut sources = Vec::with_capacity(edge_count);
        let mut targets = Vec::with_capacity(edge_count);

        for &edge_id in &self.active_edges {
            if let Some((source, target)) = pool.get_edge_endpoints(edge_id) {
                edge_ids.push(edge_id);
                sources.push(source);
                targets.push(target);
            }
        }

        (edge_ids, sources, targets)
    }
    
    /// Get current version (for debugging/monitoring)
    pub fn get_version(&self) -> u64 {
        self.version
    }
    
    /// NOTE: Topology queries (neighbors, degree, connectivity) now handled by
    /// Graph coordinator which queries Pool for topology and filters by Space's active sets

    /*
    === CHANGE TRACKING ===
    Workspace state and change management
    */

    /// Check if there are uncommitted changes
    pub fn has_uncommitted_changes(&self) -> bool {
        // NOTE: Graph manages change tracking now - Space doesn't track changes
        false
    }

    /// Get the number of uncommitted changes
    pub fn uncommitted_change_count(&self) -> usize {
        // NOTE: Graph manages change tracking now - Space doesn't count changes
        0
    }

    /// Get summary of uncommitted changes
    pub fn change_summary(&self) -> String {
        // TODO: Graph provides change summary now - placeholder for now
        "No changes tracked in Space".to_string()
    }

    /// Get the base state this workspace is built on
    pub fn get_base_state(&self) -> StateId {
        self.base_state
    }

    /// Create a delta object representing current changes (placeholder)
    pub fn create_change_delta(&self, _pool: &GraphPool) -> DeltaObject {
        DeltaObject::empty()
    }
    
    /*
    === COMPATIBILITY METHODS FOR OLD REFCELL API ===
    */
    
    /// Generic attribute index getter (compatibility with old API)
    pub fn get_attribute_indices(&self, attr_name: &AttrName, is_node: bool) -> Vec<(NodeId, Option<usize>)> {
        if is_node {
            self.get_attribute_indices_nodes(attr_name)
        } else {
            // Convert EdgeId result to NodeId for compatibility
            self.get_attribute_indices_edges(attr_name)
                .into_iter()
                .map(|(edge_id, index)| (edge_id as NodeId, index))
                .collect()
        }
    }
    
    /// Generic attribute values getter (compatibility with old API)
    pub fn get_attributes<'a>(&self, pool: &'a GraphPool, attr_name: &AttrName, is_node: bool) -> Vec<(NodeId, Option<&'a crate::types::AttrValue>)> {
        if is_node {
            self.get_attributes_nodes(pool, attr_name)
        } else {
            // Convert EdgeId result to NodeId for compatibility
            self.get_attributes_edges(pool, attr_name)
                .into_iter()
                .map(|(edge_id, value)| (edge_id as NodeId, value))
                .collect()
        }
    }

}

/*
=== SUPPORTING DATA STRUCTURES ===
*/

// NOTE: ChangeSummary import removed - Graph manages change tracking directly now

/*
=== IMPLEMENTATION NOTES ===

GraphSpace is now properly minimal - it just manages:
1. Active sets (which nodes/edges are currently active)
2. Change tracking (what's changed since last commit)
3. Basic queries (count, contains, etc.)

All actual graph operations happen in Graph, which coordinates between:
- GraphSpace (active state)
- GraphPool (data storage) 
- HistoryForest (version control)
- QueryEngine (analytics)

This separation makes the architecture much cleaner and easier to understand.
*/


--- FILE: core/change_tracker.rs ---
//! Change Tracking System - Strategy-based transaction management for graph modifications.
//!
//! ARCHITECTURE ROLE:
//! This component provides a pluggable interface for different temporal storage strategies.
//! It delegates to the selected strategy while maintaining a consistent API for the rest
//! of the system.
//!
//! DESIGN PHILOSOPHY:
//! - Strategy Pattern: Pluggable algorithms for different storage approaches
//! - Backward Compatibility: Existing APIs continue to work unchanged
//! - Performance Transparency: Each strategy optimizes for different workloads
//! - Configuration Driven: Strategy selection based on requirements

/*
=== STRATEGY-BASED CHANGE TRACKING ===

The change tracker now uses the Strategy Pattern to support different temporal
storage approaches:

1. INDEX DELTAS: Current implementation using column indices (default)
2. FULL SNAPSHOTS: Complete state snapshots (future)
3. HYBRID: Snapshots + deltas (future)
4. COMPRESSED: Space-optimized storage (future)

KEY DESIGN DECISIONS:
- Strategy Pattern: Pluggable storage algorithms
- Delegation: ChangeTracker forwards to selected strategy
- Compatibility: Existing APIs work unchanged
- Configuration: Strategy selection at creation time
*/

/// Strategy-based change tracker
/// 
/// RESPONSIBILITIES:
/// - Provide consistent API for change tracking
/// - Delegate to selected temporal storage strategy
/// - Support strategy-specific operations (like index-based changes)
/// - Maintain backward compatibility with existing code
/// 
/// NOT RESPONSIBLE FOR:
/// - Actual storage implementation (that's the strategy's job)
/// - Strategy selection logic (that's configuration driven)
/// - Storage optimization (that's strategy-specific)
#[derive(Debug)]
pub struct ChangeTracker {
    /// The selected temporal storage strategy
    /// This handles the actual change tracking implementation
    strategy: Box<dyn TemporalStorageStrategy>,
}

use std::collections::{HashMap, HashSet};
use crate::types::{NodeId, EdgeId, AttrName, AttrValue};
use crate::core::strategies::{TemporalStorageStrategy, StorageStrategyType, StorageCharacteristics, create_strategy};
use crate::core::delta::DeltaObject;
use crate::core::pool::GraphPool;
use crate::errors::GraphError;

impl ChangeTracker {
    /// Create a new change tracker with default strategy (IndexDeltas)
    pub fn new() -> Self {
        Self::with_strategy(StorageStrategyType::default())
    }
    
    /// Create a new change tracker with specific strategy
    pub fn with_strategy(strategy_type: StorageStrategyType) -> Self {
        Self {
            strategy: create_strategy(strategy_type),
        }
    }
    
    /// Create a change tracker with a custom strategy instance
    pub fn with_custom_strategy(strategy: Box<dyn TemporalStorageStrategy>) -> Self {
        Self { strategy }
    }
    
    /*
    === RECORDING CHANGES ===
    These methods are called by Graph when operations modify the graph
    */
    
    /*
    === CHANGE RECORDING API ===
    These methods delegate to the selected strategy
    */
    
    /// Record that a new node was added
    pub fn record_node_addition(&mut self, node_id: NodeId) {
        self.strategy.record_node_addition(node_id);
    }
    
    /// Record that multiple nodes were added (bulk operation)
    pub fn record_nodes_addition(&mut self, node_ids: &[NodeId]) {
        for &node_id in node_ids {
            self.strategy.record_node_addition(node_id);
        }
    }
    
    /// Record that a node was removed
    pub fn record_node_removal(&mut self, node_id: NodeId) {
        self.strategy.record_node_removal(node_id);
    }
    
    /// Record that a new edge was added
    pub fn record_edge_addition(&mut self, edge_id: EdgeId, source: NodeId, target: NodeId) {
        self.strategy.record_edge_addition(edge_id, source, target);
    }
    
    /// Record that multiple edges were added (bulk operation)
    pub fn record_edges_addition(&mut self, edges: &[(EdgeId, NodeId, NodeId)]) {
        for &(edge_id, source, target) in edges {
            self.strategy.record_edge_addition(edge_id, source, target);
        }
    }
    
    /// Record that an edge was removed
    pub fn record_edge_removal(&mut self, edge_id: EdgeId) {
        self.strategy.record_edge_removal(edge_id);
    }
    
    /// Record attribute changes for any entity type (index-based, efficient bulk recording)
    /// This is the main API - all attribute changes are recorded as indices
    pub fn record_attr_changes<T>(
        &mut self, 
        changes: &[(T, AttrName, Option<usize>, usize)],
        is_node: bool
    ) where T: Into<usize> + Copy {
        // Delegate to strategy for bulk recording
        for &(entity_id, ref attr_name, old_index, new_index) in changes {
            let id = entity_id.into();
            if is_node {
                self.strategy.record_node_attr_change(id, attr_name.clone(), old_index, new_index);
            } else {
                self.strategy.record_edge_attr_change(id, attr_name.clone(), old_index, new_index);
            }
        }
    }
    
    /// Record single attribute change (convenience wrapper)
    pub fn record_attr_change<T>(
        &mut self,
        entity_id: T,
        attr_name: AttrName,
        old_index: Option<usize>,
        new_index: usize,
        is_node: bool
    ) where T: Into<usize> + Copy {
        self.record_attr_changes(&[(entity_id, attr_name, old_index, new_index)], is_node);
    }
    
    // NOTE: update_change_metadata and current_timestamp are now handled by the strategy
    // These methods have been moved to IndexDeltaStrategy in strategies.rs
    
    /*
    === BULK CHANGE RECORDING ===
    Efficient recording of multiple changes at once
    */
    
    /// Record multiple node additions efficiently
    pub fn record_node_additions(&mut self, node_ids: &[NodeId]) {
        for &node_id in node_ids {
            self.record_node_addition(node_id);
        }
    }
    
    // NOTE: Bulk change recording methods moved above as main API

    
    /*
    === CHANGE INSPECTION ===
    Query what has changed
    */
    
    /*
    === CHANGE INSPECTION API ===
    These methods delegate to the selected strategy
    */
    
    /// Check if there are any uncommitted changes
    pub fn has_changes(&self) -> bool {
        self.strategy.has_changes()
    }
    
    /// Get the total number of changes recorded
    pub fn change_count(&self) -> usize {
        self.strategy.change_count()
    }
    
    // NOTE: change_summary is now handled by the strategy-based implementation below (line ~318)
    
    /// Get all nodes that have been modified (added, removed, or attrs changed)
    pub fn get_modified_nodes(&self) -> HashSet<NodeId> {
        let mut modified = HashSet::new();
        let changeset = self.strategy.create_change_set();
        
        // Add all nodes that were added or removed
        modified.extend(changeset.nodes_added.iter());
        modified.extend(changeset.nodes_removed.iter());
        
        // Add all nodes that had attribute changes
        for (node_id, _, _, _) in &changeset.node_attr_changes {
            modified.insert(*node_id);
        }
        
        modified
    }
    
    /// Get all edges that have been modified
    pub fn get_modified_edges(&self) -> HashSet<EdgeId> {
        let mut modified = HashSet::new();
        let changeset = self.strategy.create_change_set();
        
        // Add all edges that were added or removed
        for (edge_id, _, _) in &changeset.edges_added {
            modified.insert(*edge_id);
        }
        modified.extend(changeset.edges_removed.iter());
        
        // Add all edges that had attribute changes
        for (edge_id, _, _, _) in &changeset.edge_attr_changes {
            modified.insert(*edge_id);
        }
        
        modified
    }
    
    /// Check if a specific node has been modified
    pub fn is_node_modified(&self, node_id: NodeId) -> bool {
        let changeset = self.strategy.create_change_set();
        
        // Check if node was added or removed
        if changeset.nodes_added.contains(&node_id) || 
           changeset.nodes_removed.contains(&node_id) {
            return true;
        }
        
        // Check if node had attribute changes
        changeset.node_attr_changes.iter()
            .any(|(changed_node_id, _, _, _)| *changed_node_id == node_id)
    }
    
    /// Check if a specific edge has been modified
    pub fn is_edge_modified(&self, edge_id: EdgeId) -> bool {
        let changeset = self.strategy.create_change_set();
        
        // Check if edge was added or removed
        if changeset.edges_added.iter().any(|(id, _, _)| *id == edge_id) ||
           changeset.edges_removed.contains(&edge_id) {
            return true;
        }
        
        // Check if edge had attribute changes
        changeset.edge_attr_changes.iter()
            .any(|(changed_edge_id, _, _, _)| *changed_edge_id == edge_id)
    }
    
    /*
    === DELTA GENERATION ===
    Convert tracked changes into history deltas
    */
    
    /*
    === DELTA CREATION API ===
    */
    
    /// Create a delta object representing all current changes
    /// This is used when committing to history
    pub fn create_delta(&self) -> DeltaObject {
        self.strategy.create_delta()
    }
    
    /// Create a change set that can be passed to HistoryForest
    pub fn create_change_set(&self) -> ChangeSet {
        self.strategy.create_change_set()
    }
    
    /// Alias for create_change_set (backward compatibility)
    pub fn create_changeset(&self) -> ChangeSet {
        self.create_change_set()
    }
    
    /*
    === ROLLBACK OPERATIONS ===
    Undo changes back to last commit
    */
    
    /*
    === CHANGE MANAGEMENT API ===
    */
    
    /// Clear all recorded changes (rollback to last commit state)
    pub fn clear(&mut self) {
        self.strategy.clear_changes();
    }
    
    /*
    === STRATEGY MANAGEMENT API ===
    */
    
    /// Get the name of the current strategy
    pub fn strategy_name(&self) -> &'static str {
        self.strategy.strategy_name()
    }
    
    /// Get the storage characteristics of the current strategy
    pub fn storage_characteristics(&self) -> StorageCharacteristics {
        self.strategy.storage_characteristics()
    }
    
    /// Get a summary of what has changed (compatibility method)
    pub fn change_summary(&self) -> ChangeSummary {
        let changeset = self.strategy.create_change_set();
        
        ChangeSummary {
            nodes_added: changeset.nodes_added.len(),
            nodes_removed: changeset.nodes_removed.len(),
            edges_added: changeset.edges_added.len(),
            edges_removed: changeset.edges_removed.len(),
            node_attr_changes: changeset.node_attr_changes.len(),
            edge_attr_changes: changeset.edge_attr_changes.len(),
            total_changes: self.change_count(),
            first_change_time: None, // TODO: Could track timestamps in strategy
        }
    }
    
    /// Generate the reverse operations needed to undo all changes
    /// This is useful for implementing rollback functionality
    pub fn generate_reverse_operations(&self) -> Vec<ReverseOperation> {
        // Basic implementation returns empty - full implementation would analyze changes and generate reverses
        Vec::new()
    }
    
    /*
    === CHANGE MERGING ===
    Combine changes from different sources (useful for merging branches)
    */
    
    /// Merge changes from another change tracker
    /// This is complex because changes might conflict
    pub fn merge(&mut self, other: &ChangeTracker) -> Result<(), MergeConflict> {
        let _ = other; // Silence unused parameter warning
        // Basic implementation returns error - merging not yet implemented
        Err(MergeConflict {
            conflict_type: ConflictType::NodeAttributeConflict,
            entity_id: 0,
            attribute: None,
            our_change: "not implemented".to_string(),
            their_change: "not implemented".to_string(),
        })
    }
    
    /// Check if merging with another change tracker would cause conflicts
    pub fn would_conflict_with(&self, other: &ChangeTracker) -> Vec<MergeConflict> {
        let _ = other; // Silence unused parameter warning
        // Basic implementation returns empty - conflict analysis not yet implemented
        Vec::new()
    }
    
    /*
    === OPTIMIZATION OPERATIONS ===
    Clean up and optimize the change log
    */
    
    /// Optimize the change log by removing redundant entries
    /// For example, if a node attribute is changed multiple times,
    /// we only need to track the final change
    pub fn optimize(&mut self) {
        // Basic implementation is a no-op - optimization not yet implemented
    }
    
    /// Estimate the memory usage of the change tracker
    pub fn memory_usage(&self) -> usize {
        let changeset = self.strategy.create_change_set();
        let mut total = 0;
        
        // Size of vectors holding IDs
        total += changeset.nodes_added.len() * std::mem::size_of::<NodeId>();
        total += changeset.nodes_removed.len() * std::mem::size_of::<NodeId>();
        total += changeset.edges_added.len() * std::mem::size_of::<(EdgeId, NodeId, NodeId)>();
        total += changeset.edges_removed.len() * std::mem::size_of::<EdgeId>();
        
        // Size of attribute changes
        for (_, _attr_name, old_val, new_val) in &changeset.node_attr_changes {
            total += std::mem::size_of::<NodeId>();
            total += std::mem::size_of::<AttrName>();
            if let Some(val) = old_val {
                total += match val {
                    AttrValue::Text(s) => s.len(),
                    AttrValue::Int(_) => std::mem::size_of::<i64>(),
                    AttrValue::Float(_) => std::mem::size_of::<f64>(),
                    AttrValue::Bool(_) => std::mem::size_of::<bool>(),
                    AttrValue::FloatVec(v) => v.len() * std::mem::size_of::<f32>(),
                    AttrValue::CompactText(cs) => cs.memory_size(),
                    AttrValue::SmallInt(_) => std::mem::size_of::<i32>(),
                    AttrValue::Bytes(b) => b.len(),
                    AttrValue::CompressedText(cd) => cd.memory_size(),
                    AttrValue::CompressedFloatVec(cd) => cd.memory_size(),
                };
            }
            total += match new_val {
                AttrValue::Text(s) => s.len(),
                AttrValue::Int(_) => std::mem::size_of::<i64>(),
                AttrValue::Float(_) => std::mem::size_of::<f64>(),
                AttrValue::Bool(_) => std::mem::size_of::<bool>(),
                AttrValue::FloatVec(v) => v.len() * std::mem::size_of::<f32>(),
                AttrValue::CompactText(cs) => cs.memory_size(),
                AttrValue::SmallInt(_) => std::mem::size_of::<i32>(),
                AttrValue::Bytes(b) => b.len(),
                AttrValue::CompressedText(cd) => cd.memory_size(),
                AttrValue::CompressedFloatVec(cd) => cd.memory_size(),
            };
        }
        
        for (_, _attr_name, old_val, new_val) in &changeset.edge_attr_changes {
            total += std::mem::size_of::<EdgeId>();
            total += std::mem::size_of::<AttrName>();
            if let Some(val) = old_val {
                total += match val {
                    AttrValue::Text(s) => s.len(),
                    AttrValue::Int(_) => std::mem::size_of::<i64>(),
                    AttrValue::Float(_) => std::mem::size_of::<f64>(),
                    AttrValue::Bool(_) => std::mem::size_of::<bool>(),
                    AttrValue::FloatVec(v) => v.len() * std::mem::size_of::<f32>(),
                    AttrValue::CompactText(cs) => cs.memory_size(),
                    AttrValue::SmallInt(_) => std::mem::size_of::<i32>(),
                    AttrValue::Bytes(b) => b.len(),
                    AttrValue::CompressedText(cd) => cd.memory_size(),
                    AttrValue::CompressedFloatVec(cd) => cd.memory_size(),
                };
            }
            total += match new_val {
                AttrValue::Text(s) => s.len(),
                AttrValue::Int(_) => std::mem::size_of::<i64>(),
                AttrValue::Float(_) => std::mem::size_of::<f64>(),
                AttrValue::Bool(_) => std::mem::size_of::<bool>(),
                AttrValue::FloatVec(v) => v.len() * std::mem::size_of::<f32>(),
                AttrValue::CompactText(cs) => cs.memory_size(),
                AttrValue::SmallInt(_) => std::mem::size_of::<i32>(),
                AttrValue::Bytes(b) => b.len(),
                AttrValue::CompressedText(cd) => cd.memory_size(),
                AttrValue::CompressedFloatVec(cd) => cd.memory_size(),
            };
        }
        
        total
    }
    
    /*
    === STATISTICS AND DEBUGGING ===
    Information about the change tracker state
    */
    
    /// Get statistics about the changes
    pub fn statistics(&self) -> ChangeStatistics {
        ChangeStatistics {
            change_summary: self.change_summary(),
            memory_usage_bytes: self.memory_usage(),
            average_changes_per_node: 0.0,
            average_changes_per_edge: 0.0,
            most_changed_nodes: Vec::new(),
            most_changed_edges: Vec::new(),
            change_rate_per_second: 0.0,
        }
    }
    
    /// Get the time elapsed since the first change
    pub fn time_since_first_change(&self) -> Option<u64> {
        // Basic implementation returns None - time tracking not yet implemented
        None
    }
}

/*
=== SUPPORTING DATA STRUCTURES ===
*/

/// A set of changes that can be committed to history
#[derive(Debug, Clone)]
pub struct ChangeSet {
    pub nodes_added: Vec<NodeId>,
    pub nodes_removed: Vec<NodeId>,
    pub edges_added: Vec<(EdgeId, NodeId, NodeId)>,
    pub edges_removed: Vec<EdgeId>,
    pub node_attr_changes: Vec<(NodeId, AttrName, Option<AttrValue>, AttrValue)>,
    pub edge_attr_changes: Vec<(EdgeId, AttrName, Option<AttrValue>, AttrValue)>,
}

impl ChangeSet {
    /// Create an empty change set
    pub fn new() -> Self {
        Self {
            nodes_added: Vec::new(),
            nodes_removed: Vec::new(),
            edges_added: Vec::new(),
            edges_removed: Vec::new(),
            node_attr_changes: Vec::new(),
            edge_attr_changes: Vec::new(),
        }
    }
    
    /// Check if the change set is empty
    pub fn is_empty(&self) -> bool {
        self.nodes_added.is_empty() &&
        self.nodes_removed.is_empty() &&
        self.edges_added.is_empty() &&
        self.edges_removed.is_empty() &&
        self.node_attr_changes.is_empty() &&
        self.edge_attr_changes.is_empty()
    }
}

/// Summary of all changes in the tracker
#[derive(Debug, Clone)]
pub struct ChangeSummary {
    pub nodes_added: usize,
    pub nodes_removed: usize,
    pub edges_added: usize,
    pub edges_removed: usize,
    pub node_attr_changes: usize,
    pub edge_attr_changes: usize,
    pub total_changes: usize,
    pub first_change_time: Option<u64>,
}

impl ChangeSummary {
    /// Check if any changes have been made
    pub fn is_empty(&self) -> bool {
        self.total_changes == 0
    }
    
    /// Get a human-readable description of the changes
    pub fn description(&self) -> String {
        format!("+{} nodes, -{} nodes, +{} edges, -{} edges, {} node attrs, {} edge attrs",
                self.nodes_added, self.nodes_removed, 
                self.edges_added, self.edges_removed,
                self.node_attr_changes, self.edge_attr_changes)
    }
}

/// A reversible operation that can undo a change
#[derive(Debug, Clone)]
pub enum ReverseOperation {
    /// Remove a node that was added
    RemoveNode(NodeId),
    
    /// Add back a node that was removed (with its attributes)
    AddNode(NodeId, HashMap<AttrName, AttrValue>),
    
    /// Remove an edge that was added
    RemoveEdge(EdgeId),
    
    /// Add back an edge that was removed (with its attributes)
    AddEdge(EdgeId, NodeId, NodeId, HashMap<AttrName, AttrValue>),
    
    /// Restore an attribute to its previous value
    RestoreNodeAttr(NodeId, AttrName, Option<AttrValue>),
    
    /// Restore an edge attribute to its previous value
    RestoreEdgeAttr(EdgeId, AttrName, Option<AttrValue>),
}

impl ReverseOperation {
    /// Execute this reverse operation on a graph pool
    pub fn execute(&self, pool: &mut GraphPool) -> Result<(), GraphError> {
        let _ = pool; // Silence unused parameter warning
        // For now return not implemented error
        match self {
            ReverseOperation::RemoveNode(_) => Err(GraphError::NotImplemented {
                feature: "reverse operations".to_string(),
                tracking_issue: None,
            }),
            ReverseOperation::AddNode(_, _) => Err(GraphError::NotImplemented {
                feature: "reverse operations".to_string(),
                tracking_issue: None,
            }),
            ReverseOperation::RemoveEdge(_) => Err(GraphError::NotImplemented {
                feature: "reverse operations".to_string(),
                tracking_issue: None,
            }),
            ReverseOperation::AddEdge(_, _, _, _) => Err(GraphError::NotImplemented {
                feature: "reverse operations".to_string(),
                tracking_issue: None,
            }),
            ReverseOperation::RestoreNodeAttr(_, _, _) => Err(GraphError::NotImplemented {
                feature: "reverse operations".to_string(),
                tracking_issue: None,
            }),
            ReverseOperation::RestoreEdgeAttr(_, _, _) => Err(GraphError::NotImplemented {
                feature: "reverse operations".to_string(),
                tracking_issue: None,
            }),
        }
    }
}

/// A conflict that occurs when merging change trackers
#[derive(Debug, Clone)]
pub struct MergeConflict {
    pub conflict_type: ConflictType,
    pub entity_id: u64, // NodeId or EdgeId
    pub attribute: Option<AttrName>,
    pub our_change: String,      // Description of our change
    pub their_change: String,    // Description of their change
}

#[derive(Debug, Clone)]
pub enum ConflictType {
    /// Both sides modified the same node attribute
    NodeAttributeConflict,
    
    /// Both sides modified the same edge attribute
    EdgeAttributeConflict,
    
    /// One side added a node, other side removed it
    NodeExistenceConflict,
    
    /// One side added an edge, other side removed it
    EdgeExistenceConflict,
}

/// Detailed statistics about the change tracker
#[derive(Debug, Clone)]
pub struct ChangeStatistics {
    pub change_summary: ChangeSummary,
    pub memory_usage_bytes: usize,
    pub average_changes_per_node: f64,
    pub average_changes_per_edge: f64,
    pub most_changed_nodes: Vec<(NodeId, usize)>,  // Top 10 most modified nodes
    pub most_changed_edges: Vec<(EdgeId, usize)>,  // Top 10 most modified edges
    pub change_rate_per_second: f64,               // Changes per second since first change
}


impl Default for ChangeTracker {
    fn default() -> Self {
        Self::new()
    }
}

/*
=== STRATEGY-BASED IMPLEMENTATION NOTES ===

STRATEGY PATTERN BENEFITS:
- Pluggable storage algorithms for different workloads
- Easy to add new temporal storage strategies
- Configuration-driven strategy selection
- Backward compatibility with existing code

PERFORMANCE CHARACTERISTICS:
- Strategy-dependent: IndexDeltas optimized for frequent small changes
- Delegation overhead: Minimal - single virtual function call
- Memory usage: Strategy-specific optimizations
- Extensibility: New strategies can optimize for different patterns

STRATEGY SELECTION:
- Default: IndexDeltaStrategy (preserves current performance)
- Configuration: Can specify different strategies at creation
- Runtime: Strategy switching not currently supported (by design)
- Future: Could be adaptive based on workload characteristics

INTEGRATION POINTS:
- Space: Calls index-specific methods for IndexDeltaStrategy
- History: Uses create_delta() output regardless of strategy
- Graph: Same API regardless of underlying strategy
- Config: Strategy selection happens at ChangeTracker creation

BACKWARD COMPATIBILITY:
- All existing APIs work unchanged
- Performance characteristics preserved for default strategy
- New strategy-specific methods available for optimization
- Migration path: zero code changes required
*/

--- FILE: core/subgraph.rs ---
//! Subgraph - A view into a Graph with full Graph API inheritance
//!
//! *** ARCHITECTURE OVERVIEW ***
//! A Subgraph represents a subset of nodes and edges from a parent Graph.
//! Unlike traditional graph libraries, Subgraphs in Groggy have FULL Graph API.
//! 
//! DESIGN PHILOSOPHY:
//! - Subgraph IS-A Graph (through trait or delegation)
//! - All Graph operations work on Subgraphs: filter_nodes, bfs, dfs, etc.
//! - Infinite composability: subgraph.filter_nodes().bfs().filter_edges()
//! - Column access: subgraph[attr_name] -> Vec<AttrValue>
//! - True inheritance enables unprecedented power
//!
//! KEY BENEFITS:
//! - Recursive filtering and analysis
//! - Batch operations at any subgraph level
//! - Consistent API regardless of graph or subgraph context
//! - Performance: operations stay in Rust core

use crate::api::graph::Graph;
use crate::types::{NodeId, EdgeId, AttrName, AttrValue};
use crate::errors::{GraphError, GraphResult};
use crate::core::traversal::TraversalOptions;
use std::collections::HashSet;
use std::rc::Rc;
use std::cell::RefCell;

/// A Subgraph represents a subset of nodes and edges from a parent Graph
/// with full Graph API capabilities through delegation.
/// 
/// CORE CONCEPT: Subgraph IS-A Graph
/// - All Graph operations work: filter_nodes, bfs, dfs, algorithms
/// - Column access: subgraph[attr_name] -> Vec<AttrValue> 
/// - Infinite composability: subgraph.filter().filter().bfs().set()
/// - Consistent API at every level
#[derive(Debug, Clone)]
pub struct Subgraph {
    /// Reference to the parent graph (shared across all subgraphs)
    /// This enables all Graph operations to work on Subgraphs
    /// Uses RefCell for interior mutability to allow batch operations
    graph: Rc<RefCell<Graph>>,
    
    /// Set of node IDs that are included in this subgraph
    /// Operations are filtered to only these nodes
    nodes: HashSet<NodeId>,
    
    /// Set of edge IDs that are included in this subgraph
    /// Usually induced edges (edges between subgraph nodes)
    edges: HashSet<EdgeId>,
    
    /// Metadata about how this subgraph was created
    /// Examples: "filter_nodes", "bfs_traversal", "batch_selection"
    subgraph_type: String,
}

impl Subgraph {
    /// Create a new Subgraph from a Graph with specific nodes and edges
    pub fn new(
        graph: Rc<RefCell<Graph>>,
        nodes: HashSet<NodeId>,
        edges: HashSet<EdgeId>,
        subgraph_type: String,
    ) -> Self {
        Self {
            graph,
            nodes,
            edges,
            subgraph_type,
        }
    }
    
    /// Create a new Subgraph with just nodes, calculating induced edges
    pub fn from_nodes(
        graph: Rc<RefCell<Graph>>,
        nodes: HashSet<NodeId>,
        subgraph_type: String,
    ) -> GraphResult<Self> {
        let edges = Self::calculate_induced_edges(&graph, &nodes)?;
        Ok(Self::new(graph, nodes, edges, subgraph_type))
    }
    
    /// Calculate induced edges (edges where both endpoints are in the node set) - O(k) OPTIMIZED
    /// 
    /// Uses columnar topology vectors for O(k) performance where k = number of active edges,
    /// which is much better than O(E) over all edges in the graph.
    fn calculate_induced_edges(graph: &Rc<RefCell<Graph>>, nodes: &HashSet<NodeId>) -> GraphResult<HashSet<EdgeId>> {
        let mut induced_edges = HashSet::new();
        let graph_borrow = graph.borrow();
        
        // Get columnar topology vectors (edge_ids, sources, targets) - O(1) if cached
        let (edge_ids, sources, targets) = graph_borrow.get_columnar_topology();
        
        // Iterate through parallel vectors - O(k) where k = active edges
        for i in 0..edge_ids.len() {
            let edge_id = edge_ids[i];
            let source = sources[i];
            let target = targets[i];
            
            // O(1) HashSet lookups instead of O(n) Vec::contains
            if nodes.contains(&source) && nodes.contains(&target) {
                induced_edges.insert(edge_id);
            }
        }
        
        Ok(induced_edges)
    }
    
    /// Get reference to the parent graph (for read operations)
    pub fn graph(&self) -> Rc<RefCell<Graph>> {
        self.graph.clone()
    }
    
    /// Get the nodes in this subgraph
    pub fn nodes(&self) -> &HashSet<NodeId> {
        &self.nodes
    }
    
    /// Get the edges in this subgraph  
    pub fn edges(&self) -> &HashSet<EdgeId> {
        &self.edges
    }
    
    /// Get the subgraph type metadata
    pub fn subgraph_type(&self) -> &str {
        &self.subgraph_type
    }
    
    /// Get node count
    pub fn node_count(&self) -> usize {
        self.nodes.len()
    }
    
    /// Get edge count
    pub fn edge_count(&self) -> usize {
        self.edges.len()
    }
    
    /// Check if a node is in this subgraph
    pub fn has_node(&self, node_id: NodeId) -> bool {
        self.nodes.contains(&node_id)
    }
    
    /// Check if an edge is in this subgraph
    pub fn has_edge(&self, edge_id: EdgeId) -> bool {
        self.edges.contains(&edge_id)
    }
    
    /// Get all node IDs as a Vec (for compatibility with existing APIs)
    pub fn node_ids(&self) -> Vec<NodeId> {
        self.nodes.iter().copied().collect()
    }
    
    /// Get all edge IDs as a Vec (for compatibility with existing APIs)
    pub fn edge_ids(&self) -> Vec<EdgeId> {
        self.edges.iter().copied().collect()
    }
}

/// Core Graph operations implemented for Subgraph through delegation
/// This makes Subgraph truly behave like a Graph
impl Subgraph {
    /// Filter nodes within this subgraph using attribute filters
    /// This enables infinite composability: subgraph.filter_nodes().filter_nodes()
    pub fn filter_nodes_by_attributes(&self, filters: &std::collections::HashMap<AttrName, crate::core::query::AttributeFilter>) -> GraphResult<Subgraph> {
        let mut filtered_nodes = HashSet::new();
        let graph_borrow = self.graph.borrow();
        
        // Only consider nodes that are already in this subgraph
        for &node_id in &self.nodes {
            let mut matches_all = true;
            
            // Check all filters
            for (attr_name, filter) in filters {
                if let Some(attr_value) = graph_borrow.get_node_attr(node_id, attr_name)? {
                    if !filter.matches(&attr_value) {
                        matches_all = false;
                        break;
                    }
                } else {
                    // Node doesn't have the attribute, so it doesn't match
                    matches_all = false;
                    break;
                }
            }
            
            if matches_all {
                filtered_nodes.insert(node_id);
            }
        }
        drop(graph_borrow); // Release borrow before creating new subgraph
        
        // Create new subgraph with filtered nodes
        Self::from_nodes(
            self.graph.clone(),
            filtered_nodes,
            format!("{}_attr_filtered", self.subgraph_type),
        )
    }
    
    /// Filter nodes within this subgraph by a simple attribute value match
    /// This is a convenience method for the most common case
    pub fn filter_nodes_by_attribute(&self, attr_name: &AttrName, attr_value: &AttrValue) -> GraphResult<Subgraph> {
        let mut filtered_nodes = HashSet::new();
        let graph_borrow = self.graph.borrow();
        
        // Only consider nodes that are already in this subgraph
        for &node_id in &self.nodes {
            if let Some(node_attr_value) = graph_borrow.get_node_attr(node_id, attr_name)? {
                if &node_attr_value == attr_value {
                    filtered_nodes.insert(node_id);
                }
            }
        }
        drop(graph_borrow); // Release borrow before creating new subgraph
        
        // Create new subgraph with filtered nodes
        Self::from_nodes(
            self.graph.clone(),
            filtered_nodes,
            format!("{}_value_filtered", self.subgraph_type),
        )
    }
    
    /// Run BFS traversal starting from a node within this subgraph
    /// The traversal is constrained to nodes in this subgraph
    pub fn bfs(&self, start: NodeId, _options: TraversalOptions) -> GraphResult<Subgraph> {
        // Ensure start node is in this subgraph
        if !self.has_node(start) {
            return Err(GraphError::node_not_found(start, "subgraph BFS"));
        }
        
        // TODO: Implement constrained BFS within subgraph
        // For now, return a placeholder
        Ok(Subgraph::new(
            self.graph.clone(),
            HashSet::from([start]),
            HashSet::new(),
            format!("{}_bfs", self.subgraph_type),
        ))
    }
    
    /// Run DFS traversal starting from a node within this subgraph
    pub fn dfs(&self, start: NodeId, _options: TraversalOptions) -> GraphResult<Subgraph> {
        // Ensure start node is in this subgraph
        if !self.has_node(start) {
            return Err(GraphError::node_not_found(start, "subgraph DFS"));
        }
        
        // TODO: Implement constrained DFS within subgraph
        // For now, return a placeholder
        Ok(Subgraph::new(
            self.graph.clone(),
            HashSet::from([start]),
            HashSet::new(),
            format!("{}_dfs", self.subgraph_type),
        ))
    }
    
    /// Find connected components within this subgraph
    pub fn connected_components(&self) -> GraphResult<Vec<Subgraph>> {
        // TODO: Implement connected components analysis within subgraph
        // For now, return the subgraph itself as a single component
        Ok(vec![self.clone()])
    }
}

/// Column access operations for bulk attribute extraction
impl Subgraph {
    /// Get all values for a node attribute within this subgraph
    /// This is the key column access operation: subgraph[attr_name] -> Vec<AttrValue>
    pub fn get_node_attribute_column(&self, attr_name: &AttrName) -> GraphResult<Vec<AttrValue>> {
        let mut values = Vec::new();
        let graph_borrow = self.graph.borrow();
        
        for &node_id in &self.nodes {
            if let Some(attr_value) = graph_borrow.get_node_attr(node_id, attr_name)? {
                values.push(attr_value);
            } else {
                // Handle missing attributes - could use None or skip
                // For now, we'll skip missing attributes
            }
        }
        
        Ok(values)
    }
    
    /// Get all values for an edge attribute within this subgraph
    pub fn get_edge_attribute_column(&self, attr_name: &AttrName) -> GraphResult<Vec<AttrValue>> {
        let mut values = Vec::new();
        let graph_borrow = self.graph.borrow();
        
        for &edge_id in &self.edges {
            if let Some(attr_value) = graph_borrow.get_edge_attr(edge_id, attr_name)? {
                values.push(attr_value);
            } else {
                // Handle missing attributes - skip for now
            }
        }
        
        Ok(values)
    }
    
    /// Get node attribute values for specific nodes within this subgraph
    /// This enables: g.nodes[[1,2,3]][attr_name] -> [val1, val2, val3]
    pub fn get_node_attributes_for_nodes(&self, node_ids: &[NodeId], attr_name: &AttrName) -> GraphResult<Vec<AttrValue>> {
        let mut values = Vec::new();
        let graph_borrow = self.graph.borrow();
        
        for &node_id in node_ids {
            // Ensure the node is in this subgraph
            if !self.has_node(node_id) {
                return Err(GraphError::node_not_found(node_id, "subgraph attribute access"));
            }
            
            if let Some(attr_value) = graph_borrow.get_node_attr(node_id, attr_name)? {
                values.push(attr_value);
            }
        }
        
        Ok(values)
    }
}

/// Batch operations for setting attributes on multiple nodes/edges in subgraph
impl Subgraph {
    /// Set an attribute on all nodes in this subgraph
    /// This enables: subgraph.set_node_attribute_bulk("department", "Engineering")
    pub fn set_node_attribute_bulk(&self, attr_name: &AttrName, attr_value: AttrValue) -> GraphResult<()> {
        let mut graph_borrow = self.graph.borrow_mut();
        
        for &node_id in &self.nodes {
            graph_borrow.set_node_attr(node_id, attr_name.clone(), attr_value.clone())?;
        }
        
        Ok(())
    }
    
    /// Set attributes on specific nodes within this subgraph
    pub fn set_node_attributes_for_nodes(
        &self,
        node_ids: &[NodeId],
        attr_name: &AttrName,
        attr_value: AttrValue,
    ) -> GraphResult<()> {
        for &node_id in node_ids {
            if !self.has_node(node_id) {
                return Err(GraphError::node_not_found(node_id, "subgraph batch operation"));
            }
        }
        
        let mut graph_borrow = self.graph.borrow_mut();
        for &node_id in node_ids {
            graph_borrow.set_node_attr(node_id, attr_name.clone(), attr_value.clone())?;
        }
        
        Ok(())
    }
    
    /// Set multiple attributes on all nodes in this subgraph
    /// This enables: subgraph.set_bulk({attr1: val1, attr2: val2})
    pub fn set_node_attributes_bulk(&self, attributes: std::collections::HashMap<AttrName, AttrValue>) -> GraphResult<()> {
        let mut graph_borrow = self.graph.borrow_mut();
        
        for &node_id in &self.nodes {
            for (attr_name, attr_value) in &attributes {
                graph_borrow.set_node_attr(node_id, attr_name.clone(), attr_value.clone())?;
            }
        }
        
        Ok(())
    }
    
    /// Set an attribute on all edges in this subgraph
    pub fn set_edge_attribute_bulk(&self, attr_name: &AttrName, attr_value: AttrValue) -> GraphResult<()> {
        let mut graph_borrow = self.graph.borrow_mut();
        
        for &edge_id in &self.edges {
            graph_borrow.set_edge_attr(edge_id, attr_name.clone(), attr_value.clone())?;
        }
        
        Ok(())
    }
}

/// Column access syntax: subgraph[attr_name] -> Vec<AttrValue>
impl std::ops::Index<&str> for Subgraph {
    type Output = Vec<AttrValue>;
    
    fn index(&self, _attr_name: &str) -> &Self::Output {
        // Note: This is a design challenge - we can't return references to Vec<AttrValue>
        // because the Vec is computed on demand. We might need a different approach
        // for true index syntax. For now, users should use get_node_attribute_column()
        unimplemented!("Use get_node_attribute_column() for column access instead of []")
    }
}

impl std::fmt::Display for Subgraph {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(
            f,
            "Subgraph(nodes={}, edges={}, type={})",
            self.node_count(),
            self.edge_count(),
            self.subgraph_type
        )
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::api::graph::Graph;
    use crate::types::AttrValue;
    
    #[test]
    fn test_subgraph_creation() {
        // Test basic subgraph creation and functionality
        let mut graph = Graph::new();
        
        // Add test nodes
        let node1 = graph.add_node();
        let node2 = graph.add_node();
        
        // Set attributes
        graph.set_node_attr(node1, "name".to_string(), AttrValue::Text("Alice".to_string())).unwrap();
        graph.set_node_attr(node2, "name".to_string(), AttrValue::Text("Bob".to_string())).unwrap();
        
        // Create subgraph
        let graph_rc = Rc::new(RefCell::new(graph));
        let node_subset = HashSet::from([node1, node2]);
        let subgraph = Subgraph::from_nodes(
            graph_rc,
            node_subset,
            "test".to_string(),
        ).unwrap();
        
        // Test basic properties
        assert_eq!(subgraph.node_count(), 2);
        assert!(subgraph.has_node(node1));
        assert!(subgraph.has_node(node2));
        
        // Test column access
        let names = subgraph.get_node_attribute_column(&"name".to_string()).unwrap();
        assert_eq!(names.len(), 2);
        
    }
}

--- FILE: core/pool.rs ---
//! Graph Pool - Pure Data Storage Tables
//!
//! ARCHITECTURE ROLE:
//! GraphPool is the "database" - it stores ALL the data tables but doesn't 
//! know what's currently "active". It's just efficient storage for nodes,
//! edges, and attributes that can grow indefinitely.
//!
//! DESIGN PHILOSOPHY:
//! - GraphPool = Pure Storage (all the data tables, no business logic)
//! - GraphSpace = Active View (knows what's currently active)
//! - Pool provides raw storage, Space manages the active subset
//! - Pool can store "deleted" entities, Space decides what's visible

/*
=== POOL VS SPACE SEPARATION ===

GraphPool (this module):
- Stores ALL nodes/edges/attributes that have ever existed
- Grows indefinitely (append-only for performance)
- No concept of "active" vs "inactive" 
- Pure storage with efficient access methods
- Can store soft-deleted entities

GraphSpace (space.rs):
- Knows which entities are currently "active"
- Manages the active subset of pool data
- Handles add/remove operations by updating active sets
- Provides the "current view" of the graph
- Tracks changes for history commits

This separation allows:
- Pool to be optimized for storage efficiency
- Space to be optimized for current state operations
- Better separation of concerns
- Easier testing and reasoning
*/

use std::collections::HashMap;
use crate::types::{NodeId, EdgeId, AttrName, AttrValue, GraphType};

/// Columnar storage for attribute values with memory pooling
/// 
/// DESIGN: Store attribute values in a single vector for cache efficiency.
/// This is much faster for bulk operations and analytics workloads compared
/// to storing attributes per-entity.
/// 
/// USAGE: Each entity gets an index into this column. When the entity's
/// attribute changes, we append the new value and update the index.
/// 
/// MEMORY OPTIMIZATION: Uses memory pooling to reduce allocations
#[derive(Debug, Clone)]
pub struct AttributeColumn {
    /// All values ever stored for this attribute (append-only)
    values: Vec<AttrValue>,
    /// Memory pool for reused values (Memory Optimization 2)
    memory_pool: AttributeMemoryPool,
}

/// Memory pool for reusing attribute values to reduce allocations
#[derive(Debug, Clone)]
pub struct AttributeMemoryPool {
    /// Pool of reusable string allocations
    string_pool: Vec<String>,
    /// Pool of reusable float vectors
    float_vec_pool: Vec<Vec<f32>>,
    /// Pool of reusable byte vectors  
    #[allow(dead_code)] // TODO: Implement byte pool reuse
    byte_pool: Vec<Vec<u8>>,
    /// Statistics
    reuse_count: usize,
    allocation_count: usize,
}

impl AttributeMemoryPool {
    /// Create a new memory pool
    pub fn new() -> Self {
        Self {
            string_pool: Vec::new(),
            float_vec_pool: Vec::new(),
            byte_pool: Vec::new(),
            reuse_count: 0,
            allocation_count: 0,
        }
    }
    
    /// Get a reusable string or allocate a new one
    pub fn get_string(&mut self, content: &str) -> String {
        if let Some(mut reused) = self.string_pool.pop() {
            reused.clear();
            reused.push_str(content);
            self.reuse_count += 1;
            reused
        } else {
            self.allocation_count += 1;
            content.to_string()
        }
    }
    
    /// Return a string to the pool for reuse
    pub fn return_string(&mut self, mut string: String) {
        if string.capacity() <= 1024 { // Only pool reasonably sized strings
            string.clear();
            self.string_pool.push(string);
        }
    }
    
    /// Get a reusable float vector or allocate a new one
    pub fn get_float_vec(&mut self, capacity: usize) -> Vec<f32> {
        if let Some(mut reused) = self.float_vec_pool.pop() {
            reused.clear();
            reused.reserve(capacity);
            self.reuse_count += 1;
            reused
        } else {
            self.allocation_count += 1;
            Vec::with_capacity(capacity)
        }
    }
    
    /// Return a float vector to the pool for reuse
    pub fn return_float_vec(&mut self, mut vec: Vec<f32>) {
        if vec.capacity() <= 10000 { // Only pool reasonably sized vectors
            vec.clear();
            self.float_vec_pool.push(vec);
        }
    }
    
    /// Get memory pool statistics
    pub fn stats(&self) -> (usize, usize, f64) {
        let total = self.reuse_count + self.allocation_count;
        let reuse_rate = if total > 0 { 
            self.reuse_count as f64 / total as f64 
        } else { 
            0.0 
        };
        (self.reuse_count, self.allocation_count, reuse_rate)
    }
}

impl AttributeColumn {
    /// Create a new empty attribute column with memory pooling
    pub fn new() -> Self {
        Self {
            values: Vec::new(),
            memory_pool: AttributeMemoryPool::new(),
        }
    }
    
    /// Append a new value and return its index
    /// 
    /// PERFORMANCE: O(1) amortized append with memory optimization
    pub fn push(&mut self, value: AttrValue) -> usize {
        let index = self.values.len();
        // Optimize the value before storing (Memory Optimization 1)
        let optimized_value = value.optimize();
        self.values.push(optimized_value);
        index
    }
    
    /// Bulk append values using Vec::extend (VECTORIZED - much faster than push loop)
    /// 
    /// PERFORMANCE: O(n) but with vectorized operations, single allocation, and memory optimization
    /// Returns (start_index, end_index) range
    pub fn extend_values(&mut self, values: Vec<AttrValue>) -> (usize, usize) {
        let start_index = self.values.len();
        
        // Optimize all values before bulk insertion (Memory Optimization 1)
        let optimized_values: Vec<_> = values.into_iter()
            .map(|v| v.optimize())
            .collect();
        
        self.values.extend(optimized_values);  // Single vectorized operation!
        let end_index = self.values.len() - 1;
        (start_index, end_index)
    }
    
    /// Pre-allocate capacity for bulk operations (prevents reallocations)
    /// 
    /// PERFORMANCE: Critical for large bulk operations
    pub fn reserve_capacity(&mut self, additional: usize) {
        self.values.reserve(additional);
    }
    
    /// Get value at a specific index
    /// 
    /// PERFORMANCE: O(1) random access
    pub fn get(&self, index: usize) -> Option<&AttrValue> {
        self.values.get(index)
    }
    
    /// Get the number of values stored
    pub fn len(&self) -> usize {
        self.values.len()
    }
    
    /// Check if the column is empty
    pub fn is_empty(&self) -> bool {
        self.values.is_empty()
    }
    
    /// Get all values as a slice (for bulk operations)
    pub fn as_slice(&self) -> &[AttrValue] {
        &self.values
    }
    
    /// Get memory pool statistics (Memory Optimization 2)
    pub fn memory_stats(&self) -> (usize, usize, f64) {
        self.memory_pool.stats()
    }
    
    /// Calculate total memory usage of this column (Memory Optimization 1)
    pub fn memory_usage(&self) -> usize {
        let base_size = std::mem::size_of::<Self>();
        let values_size = self.values.iter()
            .map(|v| v.memory_size())
            .sum::<usize>();
        let pool_overhead = std::mem::size_of::<AttributeMemoryPool>();
        
        base_size + values_size + pool_overhead
    }
}

/// Pure data storage for all graph entities and attributes
/// 
/// DESIGN: This is just efficient storage - it doesn't know or care
/// about what's "active". That's GraphSpace's responsibility.
/// 
/// RESPONSIBILITIES:
/// - Store all nodes, edges, and attributes efficiently
/// - Provide fast access to stored data
/// - Handle memory management and growth
/// - Support bulk operations on raw data
/// 
/// NOT RESPONSIBLE FOR:
/// - Determining what's "active" (that's GraphSpace)
/// - Business logic (that's Graph coordinator)
/// - Version control (that's HistoryForest)
/// - Change tracking (that's ChangeTracker)
#[derive(Debug)]
pub struct GraphPool {
    /*
    === GRAPH CONFIGURATION ===
    Fundamental graph properties that affect storage and retrieval
    */
    
    /// Graph directionality - affects how edges are interpreted
    /// DESIGN: Stored here for consistency and potential future optimizations
    graph_type: GraphType,
    
    /*
    === COLUMNAR ATTRIBUTE STORAGE ===
    Store attributes in columns (one Vec per attribute name) rather than 
    rows (one HashMap per entity). This gives better cache locality for
    analytics workloads and bulk operations.
    */
    
    /// Node attributes: attr_name -> AttributeColumn (append-only columnar storage)
    /// DESIGN: All attribute values ever stored, indexed by position
    node_attributes: HashMap<AttrName, AttributeColumn>,
    
    /// Edge attributes: attr_name -> AttributeColumn (append-only columnar storage)
    edge_attributes: HashMap<AttrName, AttributeColumn>,
    
    /*
    === TOPOLOGY STORAGE ===
    Raw storage for all edge connectivity information
    */
    
    /// All edges ever created: edge_id -> (source_node, target_node)
    /// STORAGE: This never shrinks, even for "deleted" edges
    topology: HashMap<EdgeId, (NodeId, NodeId)>,
    
    /*
    === ID MANAGEMENT ===
    Simple incrementing counters for new entities
    */
    
    /// Next available node ID - increment on each new node
    next_node_id: NodeId,
    
    /// Next available edge ID - increment on each new edge
    next_edge_id: EdgeId,
}

impl GraphPool {
    /// Create new empty graph store with default settings (undirected)
    pub fn new() -> Self {
        Self::new_with_type(GraphType::default())
    }
    
    /// Create new empty graph store with specified directionality
    pub fn new_with_type(graph_type: GraphType) -> Self {
        Self {
            graph_type,
            node_attributes: HashMap::new(),
            edge_attributes: HashMap::new(),
            topology: HashMap::new(),
            next_node_id: 0,
            next_edge_id: 0,
        }
    }
    
    /// Get the graph type
    pub fn graph_type(&self) -> GraphType {
        self.graph_type
    }
    
    /// Commit changes (no-op for append-only storage)
    /// In append-only storage, committing just means the current indices become the new baseline
    pub fn commit_baseline(&mut self) {
        // ALGORITHM: No action needed for append-only storage
        // The current state is already the baseline - Space manages the index mappings
        // This method exists for API compatibility but is essentially a no-op
        
        // Future optimization: Could implement garbage collection of unreferenced indices here
    }
    
    /// Get attribute value by index (for Space to resolve indices)
    pub fn get_attr_by_index(&self, attr: &AttrName, index: usize, is_node: bool) -> Option<&AttrValue> {
        // ALGORITHM: Direct index lookup in columnar storage
        // 1. Get the appropriate attribute column
        // 2. Return value at the specified index
        
        let column_map = if is_node {
            &self.node_attributes
        } else {
            &self.edge_attributes
        };
        
        column_map
            .get(attr)
            .and_then(|column| column.get(index))
    }
    
    /*
    === ENTITY CREATION ===
    Pool handles creating and storing all nodes/edges
    */
    
    /// Create a new node and return its ID
    /// DESIGN: Pool creates the node, Space tracks it as active
    pub fn add_node(&mut self) -> NodeId {
        let node_id = self.next_node_id;
        self.next_node_id += 1;
        node_id
    }
    
    /// Create multiple nodes with single ID allocation (BULK OPTIMIZED)
    /// 
    /// PERFORMANCE: O(1) instead of O(n) for ID allocation
    /// Returns (start_id, end_id) range and individual node IDs
    pub fn add_nodes_bulk(&mut self, count: usize) -> (NodeId, NodeId, Vec<NodeId>) {
        let start_id = self.next_node_id;
        let end_id = start_id + count - 1;
        
        // Single ID counter update
        self.next_node_id += count;
        
        // Generate node IDs (much faster than individual calls)
        let node_ids: Vec<NodeId> = (start_id..=end_id).collect();
        
        (start_id, end_id, node_ids)
    }
    
    /// Ensure a specific node ID exists (used for state reconstruction)
    /// This is used when restoring historical states during branch switching
    pub fn ensure_node_id_exists(&mut self, node_id: NodeId) {
        // Update next_node_id if necessary to avoid ID collisions
        if node_id >= self.next_node_id {
            self.next_node_id = node_id + 1;
        }
    }
    
    /// Create a new edge between two nodes
    /// DESIGN: Pool creates and stores the edge, Space tracks it as active
    pub fn add_edge(&mut self, source: NodeId, target: NodeId) -> EdgeId {
        let edge_id = self.next_edge_id;
        self.next_edge_id += 1;
        self.topology.insert(edge_id, (source, target));
        edge_id
    }
    
    /// Create multiple edges with bulk HashMap insertion (BULK OPTIMIZED)
    /// 
    /// PERFORMANCE: Batch validation + bulk HashMap operations
    /// Returns Vec<EdgeId> for created edges
    pub fn add_edges(&mut self, edges: &[(NodeId, NodeId)]) -> Vec<EdgeId> {
        let start_id = self.next_edge_id;
        let edge_ids: Vec<EdgeId> = (start_id..start_id + edges.len()).collect();
        
        // Reserve HashMap capacity to prevent rehashing
        self.topology.reserve(edges.len());
        
        // Bulk insert into topology HashMap
        for (i, &(source, target)) in edges.iter().enumerate() {
            self.topology.insert(start_id + i, (source, target));
        }
        
        // Single counter update
        self.next_edge_id += edges.len();
        
        edge_ids
    }
    
    /// Create an edge with a specific ID (used for state reconstruction)
    /// This is used when restoring historical states during branch switching
    pub fn add_edge_with_id(&mut self, edge_id: EdgeId, source: NodeId, target: NodeId) {
        self.topology.insert(edge_id, (source, target));
        // Update next_edge_id if necessary to avoid ID collisions
        if edge_id >= self.next_edge_id {
            self.next_edge_id = edge_id + 1;
        }
    }
    
    /// Get the endpoints of an edge from storage
    pub fn get_edge_endpoints(&self, edge_id: EdgeId) -> Option<(NodeId, NodeId)> {
        self.topology.get(&edge_id).copied()
    }
    
    
    /*
    === ATTRIBUTE OPERATIONS ===
    Generic attribute storage - Graph decides which column (node/edge)
    */
    
    /// Set single attribute value (appends to specified column and returns index)
    pub fn set_attr(&mut self, attr: AttrName, value: AttrValue, is_node: bool) -> usize {
        // ALGORITHM: Append-only storage with index allocation
        // 1. Get or create the appropriate attribute column
        // 2. Append the value and return the new index
        
        let column = if is_node {
            self.node_attributes.entry(attr).or_insert_with(AttributeColumn::new)
        } else {
            self.edge_attributes.entry(attr).or_insert_with(AttributeColumn::new)
        };
        column.push(value)
    }
    
    /// Set multiple attributes on single entity (appends to columns and returns indices)
    pub fn set_attrs(&mut self, attrs: HashMap<AttrName, AttrValue>, is_node: bool) -> HashMap<AttrName, usize> {
        // ALGORITHM: Bulk append operations
        // For each attribute, append the value and collect the index
        
        let mut indices = HashMap::with_capacity(attrs.len());
        for (attr_name, value) in attrs {
            let index = self.set_attr(attr_name.clone(), value, is_node);
            indices.insert(attr_name, index);
        }
        indices
    }
    
    /// Set same attribute for multiple entities (appends to column and returns indices)
    pub fn set_bulk_attr(&mut self, attr: AttrName, values: Vec<AttrValue>, is_node: bool) -> Vec<usize> {
        // ALGORITHM: Bulk columnar append operation
        // 1. Get or create the appropriate attribute column
        // 2. Append all values and collect their indices
        
        let column = if is_node {
            self.node_attributes.entry(attr).or_insert_with(AttributeColumn::new)
        } else {
            self.edge_attributes.entry(attr).or_insert_with(AttributeColumn::new)
        };
        values.into_iter().map(|value| column.push(value)).collect()
    }
    
    /// Set multiple attributes on multiple entities (VECTORIZED BULK OPERATION)
    /// Returns the new indices for change tracking
    pub fn set_bulk_attrs<T>(&mut self, attrs_values: HashMap<AttrName, Vec<(T, AttrValue)>>, is_node: bool) -> HashMap<AttrName, Vec<(T, usize)>> 
    where T: Copy {
        // OPTIMIZED: Use vectorized column operations
        let mut all_index_changes = HashMap::new();
        
        for (attr_name, entity_values) in attrs_values {
            // Get or create column
            let column = if is_node {
                self.node_attributes.entry(attr_name.clone()).or_insert_with(AttributeColumn::new)
            } else {
                self.edge_attributes.entry(attr_name.clone()).or_insert_with(AttributeColumn::new)
            };
            
            // Pre-allocate capacity to prevent reallocations
            column.reserve_capacity(entity_values.len());
            
            // Extract values for vectorized append
            let values: Vec<_> = entity_values.iter().map(|(_, val)| val.clone()).collect();
            let (start_idx, _end_idx) = column.extend_values(values);
            
            // Generate entity->index mappings
            let index_changes: Vec<_> = entity_values.iter().enumerate()
                .map(|(i, &(entity_id, _))| (entity_id, start_idx + i))
                .collect();
            
            all_index_changes.insert(attr_name, index_changes);
        }
        
        all_index_changes
    }
    
    /*
    === BULK ATTRIBUTE OPERATIONS ===
    Single unified method for all attribute retrieval needs
    */
    
    /// Get attribute values for multiple entities using their column indices
    /// 
    /// PERFORMANCE: Single bulk operation replacing N individual lookups
    /// INPUT: Vec of (entity_id, optional_column_index) pairs  
    /// OUTPUT: Vec of (entity_id, optional_attribute_value) pairs
    pub fn get_attribute_values(&self, 
        attr_name: &AttrName, 
        entity_indices: &[(NodeId, Option<usize>)], 
        is_node: bool
    ) -> Vec<(NodeId, Option<&AttrValue>)> {
        
        // Get the columnar attribute storage once
        let attr_column = if is_node {
            self.node_attributes.get(attr_name)
        } else {
            self.edge_attributes.get(attr_name)
        };
        
        // Early return if column doesn't exist
        let column = match attr_column {
            Some(col) => col,
            None => return entity_indices.iter().map(|(id, _)| (*id, None)).collect()
        };
        
        // Get direct access to values slice to avoid repeated column access
        let values_slice = column.as_slice();
        
        // Bulk retrieval with optimized access pattern
        entity_indices
            .iter()
            .map(|(entity_id, index_opt)| {
                let attr_value = index_opt
                    .and_then(|index| values_slice.get(index));
                (*entity_id, attr_value)
            })
            .collect()
    }
    
    /// OPTIMIZED: Direct access to attribute column to avoid repeated HashMap lookups
    pub fn get_node_attribute_column(&self, attr_name: &AttrName) -> Option<&AttributeColumn> {
        self.node_attributes.get(attr_name)
    }
    
    /// OPTIMIZED: Direct access to edge attribute column
    pub fn get_edge_attribute_column(&self, attr_name: &AttrName) -> Option<&AttributeColumn> {
        self.edge_attributes.get(attr_name)
    }
    
    /// OPTIMIZED: Iterator-based attribute retrieval to eliminate intermediate allocations
    /// 
    /// PERFORMANCE: Zero-allocation bulk operation for filtering  
    /// INPUT: Iterator of (entity_id, optional_column_index) pairs
    /// OUTPUT: Vec of (entity_id, optional_attribute_value) pairs
    pub fn get_attribute_values_iter<I>(&self, 
        attr_name: &AttrName, 
        entity_indices_iter: I, 
        is_node: bool
    ) -> Vec<(NodeId, Option<&AttrValue>)> 
    where
        I: Iterator<Item = (NodeId, Option<usize>)>
    {
        // Get the columnar attribute storage
        let attr_column = if is_node {
            self.node_attributes.get(attr_name)
        } else {
            self.edge_attributes.get(attr_name)
        };
        
        // OPTIMIZED: Direct iterator processing without intermediate collections
        entity_indices_iter
            .map(|(entity_id, index_opt)| {
                let attr_value = index_opt
                    .and_then(|index| attr_column?.values.get(index));
                (entity_id, attr_value)
            })
            .collect()
    }
    
    /*
    === STATISTICS & INTROSPECTION ===
    Information about the current state of the store
    */
    
    /// Get basic statistics about the graph
    pub fn statistics(&self) -> PoolStatistics {
        // Calculate memory usage approximations
        let _node_attrs_size = self.node_attributes.iter()
            .map(|(_, column)| column.len() * std::mem::size_of::<AttrValue>())
            .sum::<usize>();
        let _edge_attrs_size = self.edge_attributes.iter()
            .map(|(_, column)| column.len() * std::mem::size_of::<AttrValue>())
            .sum::<usize>();
        
        PoolStatistics {
            node_count: self.next_node_id,
            edge_count: self.next_edge_id,
            node_attribute_count: self.node_attributes.len(),
            edge_attribute_count: self.edge_attributes.len(),
        }
    }
    
    /// List all attribute names currently in use
    pub fn attribute_names(&self) -> (Vec<AttrName>, Vec<AttrName>) {
        let node_attrs = self.node_attributes.keys().cloned().collect();
        let edge_attrs = self.edge_attributes.keys().cloned().collect();
        (node_attrs, edge_attrs)
    }
}

/// Statistics about the current state of the graph store
#[derive(Debug, Clone)]
pub struct PoolStatistics {
    pub node_count: usize,
    pub edge_count: usize,
    pub node_attribute_count: usize,
    pub edge_attribute_count: usize,
    // TODO: Add memory usage, load factors, etc.
}

impl Default for GraphPool {
    fn default() -> Self {
        Self::new()
    }
}

/*
=== IMPLEMENTATION NOTES ===

MEMORY LAYOUT:
- Columnar storage means attributes of same type are stored together
- Better cache locality for bulk operations (ML workloads)
- Slightly more complex than row-based storage but worth it

ID MANAGEMENT:
- Simple incrementing counters for now
- Could optimize later with free lists, compaction
- NodeId/EdgeId reuse after deletion is possible but complex

SPARSE vs DENSE:
- Current design is dense (all entities have slots in all attribute vectors)
- Wastes memory but gives O(1) access
- Could optimize with sparse storage (HashMap<EntityId, AttrValue>) later

PERFORMANCE CHARACTERISTICS:
- Add node/edge: O(1) amortized (may need to grow vectors)
- Remove node/edge: O(1) for edges, O(degree) for nodes  
- Attribute access: O(1)
- Neighbor queries: O(total edges) - could optimize with adjacency lists
- Bulk operations: O(n) where n is number of entities processed

ERROR HANDLING:
- Use Result<T, GraphError> for operations that can fail
- Validate entity existence before operations
- Fail fast and clear error messages
*/


--- FILE: core/array.rs ---
//! GraphArray - Enhanced array with native statistical operations
//!
//! Provides GraphArray that combines list-like functionality with
//! fast native statistical computations and intelligent caching.

use crate::types::AttrValue;
use std::cell::RefCell;

/// Cache for expensive statistical computations
#[derive(Debug, Clone)]
struct CachedStats {
    mean: Option<f64>,
    std: Option<f64>,
    min: Option<AttrValue>,
    max: Option<AttrValue>,
    count: Option<usize>,
    sum: Option<f64>,
}

impl CachedStats {
    fn new() -> Self {
        Self {
            mean: None,
            std: None,
            min: None,
            max: None,
            count: None,
            sum: None,
        }
    }
    
    fn invalidate(&mut self) {
        *self = Self::new();
    }
}

/// Statistical Array with fast native operations and intelligent caching
/// 
/// Combines list-like functionality (indexing, iteration, len) with
/// high-performance statistical methods computed in Rust.
/// 
/// PERFORMANCE FEATURES:
/// - Lazy computation: Stats calculated only when requested
/// - Intelligent caching: Expensive computations cached until data changes
/// - Native speed: All statistical operations computed in Rust
/// - Zero-copy views: Efficient access to underlying data
/// 
/// USAGE:
/// ```rust
/// let arr = GraphArray::from_vec(vec![1.0, 2.0, 3.0, 4.0, 5.0]);
/// let mean = arr.mean().unwrap();  // Computed and cached
/// let std = arr.std().unwrap();    // Uses cached mean
/// let list = arr.to_list();        // Convert to Vec for compatibility
/// ```
#[derive(Debug, Clone)]
pub struct GraphArray {
    /// Core data storage
    values: Vec<AttrValue>,
    /// Cached statistical computations (lazy evaluation)
    cached_stats: RefCell<CachedStats>,
}

impl GraphArray {
    /// Create a new GraphArray from a vector of AttrValues
    pub fn from_vec(values: Vec<AttrValue>) -> Self {
        Self {
            values,
            cached_stats: RefCell::new(CachedStats::new()),
        }
    }
    
    /// Create an empty GraphArray
    pub fn new() -> Self {
        Self::from_vec(Vec::new())
    }
    
    /// Get the number of elements
    pub fn len(&self) -> usize {
        self.values.len()
    }
    
    /// Check if the array is empty
    pub fn is_empty(&self) -> bool {
        self.values.is_empty()
    }
    
    /// Get element by index
    pub fn get(&self, index: usize) -> Option<&AttrValue> {
        self.values.get(index)
    }
    
    /// Convert to a plain Vec<AttrValue> for compatibility
    pub fn to_list(&self) -> Vec<AttrValue> {
        self.values.clone()
    }
    
    /// Get iterator over values
    pub fn iter(&self) -> std::slice::Iter<AttrValue> {
        self.values.iter()
    }
    
    /// Extract numeric values for statistical computation
    /// Returns None if array contains non-numeric values
    fn extract_numeric_values(&self) -> Option<Vec<f64>> {
        let mut numeric_values = Vec::with_capacity(self.values.len());
        
        for value in &self.values {
            match value {
                AttrValue::Int(i) => numeric_values.push(*i as f64),
                AttrValue::SmallInt(i) => numeric_values.push(*i as f64),
                AttrValue::Float(f) => numeric_values.push(*f as f64),
                _ => return None, // Non-numeric value found
            }
        }
        
        if numeric_values.is_empty() {
            None
        } else {
            Some(numeric_values)
        }
    }
    
    /// Calculate and cache count of non-null values
    pub fn count(&self) -> usize {
        let mut cache = self.cached_stats.borrow_mut();
        
        if let Some(cached_count) = cache.count {
            return cached_count;
        }
        
        let count = self.values.len();
        cache.count = Some(count);
        count
    }
    
    /// Calculate and cache mean (average) of numeric values
    pub fn mean(&self) -> Option<f64> {
        let mut cache = self.cached_stats.borrow_mut();
        
        if let Some(cached_mean) = cache.mean {
            return Some(cached_mean);
        }
        
        let numeric_values = self.extract_numeric_values()?;
        if numeric_values.is_empty() {
            return None;
        }
        
        let sum: f64 = numeric_values.iter().sum();
        let mean = sum / numeric_values.len() as f64;
        
        // Cache both sum and mean for efficiency
        cache.sum = Some(sum);
        cache.mean = Some(mean);
        
        Some(mean)
    }
    
    /// Calculate and cache sum of numeric values
    pub fn sum(&self) -> Option<f64> {
        let mut cache = self.cached_stats.borrow_mut();
        
        if let Some(cached_sum) = cache.sum {
            return Some(cached_sum);
        }
        
        let numeric_values = self.extract_numeric_values()?;
        if numeric_values.is_empty() {
            return None;
        }
        
        let sum: f64 = numeric_values.iter().sum();
        cache.sum = Some(sum);
        
        Some(sum)
    }
    
    /// Calculate and cache standard deviation of numeric values
    pub fn std(&self) -> Option<f64> {
        let mut cache = self.cached_stats.borrow_mut();
        
        if let Some(cached_std) = cache.std {
            return Some(cached_std);
        }
        
        let numeric_values = self.extract_numeric_values()?;
        if numeric_values.len() < 2 {
            return None; // Need at least 2 values for std dev
        }
        
        // Get or compute mean
        let mean = if let Some(cached_mean) = cache.mean {
            cached_mean
        } else {
            let sum: f64 = numeric_values.iter().sum();
            let mean = sum / numeric_values.len() as f64;
            cache.sum = Some(sum);
            cache.mean = Some(mean);
            mean
        };
        
        // Calculate variance
        let variance: f64 = numeric_values
            .iter()
            .map(|x| {
                let diff = x - mean;
                diff * diff
            })
            .sum::<f64>() / (numeric_values.len() - 1) as f64; // Sample standard deviation
        
        let std = variance.sqrt();
        cache.std = Some(std);
        
        Some(std)
    }
    
    /// Calculate and cache minimum value
    pub fn min(&self) -> Option<AttrValue> {
        let mut cache = self.cached_stats.borrow_mut();
        
        if let Some(ref cached_min) = cache.min {
            return Some(cached_min.clone());
        }
        
        if self.values.is_empty() {
            return None;
        }
        
        // Custom min logic since AttrValue doesn't implement Ord
        let mut min_value = &self.values[0];
        for value in &self.values[1..] {
            if self.compare_attr_values(value, min_value) < 0 {
                min_value = value;
            }
        }
        
        let min_value = min_value.clone();
        cache.min = Some(min_value.clone());
        
        Some(min_value)
    }
    
    /// Calculate and cache maximum value
    pub fn max(&self) -> Option<AttrValue> {
        let mut cache = self.cached_stats.borrow_mut();
        
        if let Some(ref cached_max) = cache.max {
            return Some(cached_max.clone());
        }
        
        if self.values.is_empty() {
            return None;
        }
        
        // Custom max logic since AttrValue doesn't implement Ord
        let mut max_value = &self.values[0];
        for value in &self.values[1..] {
            if self.compare_attr_values(value, max_value) > 0 {
                max_value = value;
            }
        }
        
        let max_value = max_value.clone();
        cache.max = Some(max_value.clone());
        
        Some(max_value)
    }
    
    /// Compare two AttrValues for ordering
    /// Returns: -1 if a < b, 0 if a == b, 1 if a > b
    fn compare_attr_values(&self, a: &AttrValue, b: &AttrValue) -> i32 {
        use AttrValue::*;
        use std::cmp::Ordering;
        
        let ord = match (a, b) {
            // Numeric comparisons
            (Int(a), Int(b)) => a.cmp(b),
            (SmallInt(a), SmallInt(b)) => a.cmp(b),
            (Float(a), Float(b)) => a.partial_cmp(b).unwrap_or(Ordering::Equal),
            
            // Cross-type numeric comparisons
            (Int(a), SmallInt(b)) => (*a as f64).partial_cmp(&(*b as f64)).unwrap_or(Ordering::Equal),
            (SmallInt(a), Int(b)) => (*a as f64).partial_cmp(&(*b as f64)).unwrap_or(Ordering::Equal),
            (Int(a), Float(b)) => (*a as f64).partial_cmp(&(*b as f64)).unwrap_or(Ordering::Equal),
            (Float(a), Int(b)) => (*a as f64).partial_cmp(&(*b as f64)).unwrap_or(Ordering::Equal),
            (SmallInt(a), Float(b)) => (*a as f64).partial_cmp(&(*b as f64)).unwrap_or(Ordering::Equal),
            (Float(a), SmallInt(b)) => (*a as f64).partial_cmp(&(*b as f64)).unwrap_or(Ordering::Equal),
            
            // String comparisons
            (Text(a), Text(b)) => a.cmp(b),
            
            // Boolean comparisons
            (Bool(a), Bool(b)) => a.cmp(b),
            
            // Default: treat different types as equal
            _ => Ordering::Equal,
        };
        
        match ord {
            Ordering::Less => -1,
            Ordering::Equal => 0,
            Ordering::Greater => 1,
        }
    }
    
    /// Calculate quantile (percentile) of numeric values
    /// quantile: 0.0 to 1.0 (e.g., 0.5 for median, 0.95 for 95th percentile)
    pub fn quantile(&self, quantile: f64) -> Option<f64> {
        if !(0.0..=1.0).contains(&quantile) {
            return None;
        }
        
        let mut numeric_values = self.extract_numeric_values()?;
        if numeric_values.is_empty() {
            return None;
        }
        
        numeric_values.sort_by(|a, b| a.partial_cmp(b).unwrap());
        
        let index = (quantile * (numeric_values.len() - 1) as f64).round() as usize;
        Some(numeric_values[index.min(numeric_values.len() - 1)])
    }
    
    /// Calculate median (50th percentile)
    pub fn median(&self) -> Option<f64> {
        self.quantile(0.5)
    }
    
    /// Get comprehensive statistical summary
    pub fn describe(&self) -> StatsSummary {
        StatsSummary {
            count: self.count(),
            mean: self.mean(),
            std: self.std(),
            min: self.min(),
            max: self.max(),
            median: self.median(),
            q25: self.quantile(0.25),
            q75: self.quantile(0.75),
        }
    }
}

/// Comprehensive statistical summary
#[derive(Debug, Clone)]
pub struct StatsSummary {
    pub count: usize,
    pub mean: Option<f64>,
    pub std: Option<f64>,
    pub min: Option<AttrValue>,
    pub max: Option<AttrValue>,
    pub median: Option<f64>,
    pub q25: Option<f64>,  // 25th percentile
    pub q75: Option<f64>,  // 75th percentile
}

impl std::fmt::Display for StatsSummary {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        writeln!(f, "Statistical Summary:")?;
        writeln!(f, "  Count: {}", self.count)?;
        
        if let Some(mean) = self.mean {
            writeln!(f, "  Mean:  {:.2}", mean)?;
        }
        
        if let Some(std) = self.std {
            writeln!(f, "  Std:   {:.2}", std)?;
        }
        
        if let Some(ref min) = self.min {
            writeln!(f, "  Min:   {:?}", min)?;
        }
        
        if let Some(q25) = self.q25 {
            writeln!(f, "  25%:   {:.2}", q25)?;
        }
        
        if let Some(median) = self.median {
            writeln!(f, "  50%:   {:.2}", median)?;
        }
        
        if let Some(q75) = self.q75 {
            writeln!(f, "  75%:   {:.2}", q75)?;
        }
        
        if let Some(ref max) = self.max {
            writeln!(f, "  Max:   {:?}", max)?;
        }
        
        Ok(())
    }
}

// Implement indexing
impl std::ops::Index<usize> for GraphArray {
    type Output = AttrValue;
    
    fn index(&self, index: usize) -> &Self::Output {
        &self.values[index]
    }
}

// Implement IntoIterator for for-loop support
impl IntoIterator for GraphArray {
    type Item = AttrValue;
    type IntoIter = std::vec::IntoIter<AttrValue>;
    
    fn into_iter(self) -> Self::IntoIter {
        self.values.into_iter()
    }
}

// Implement IntoIterator for references
impl<'a> IntoIterator for &'a GraphArray {
    type Item = &'a AttrValue;
    type IntoIter = std::slice::Iter<'a, AttrValue>;
    
    fn into_iter(self) -> Self::IntoIter {
        self.values.iter()
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::types::AttrValue;
    
    #[test]
    fn test_basic_functionality() {
        let values = vec![
            AttrValue::Int(1),
            AttrValue::Int(2),
            AttrValue::Int(3),
            AttrValue::Int(4),
            AttrValue::Int(5),
        ];
        
        let arr = GraphArray::from_vec(values);
        
        assert_eq!(arr.len(), 5);
        assert_eq!(arr[0], AttrValue::Int(1));
        assert_eq!(arr.to_list().len(), 5);
    }
    
    #[test]
    fn test_statistical_operations() {
        let values = vec![
            AttrValue::Float(1.0),
            AttrValue::Float(2.0),
            AttrValue::Float(3.0),
            AttrValue::Float(4.0),
            AttrValue::Float(5.0),
        ];
        
        let arr = GraphArray::from_vec(values);
        
        assert_eq!(arr.mean(), Some(3.0));
        assert_eq!(arr.median(), Some(3.0));
        assert_eq!(arr.min(), Some(AttrValue::Float(1.0)));
        assert_eq!(arr.max(), Some(AttrValue::Float(5.0)));
        
        // Test caching by calling twice
        assert_eq!(arr.mean(), Some(3.0));
    }
    
    #[test]
    fn test_describe() {
        let values = vec![
            AttrValue::Int(10),
            AttrValue::Int(20),
            AttrValue::Int(30),
        ];
        
        let arr = GraphArray::from_vec(values);
        let summary = arr.describe();
        
        assert_eq!(summary.count, 3);
        assert_eq!(summary.mean, Some(20.0));
        assert_eq!(summary.median, Some(20.0));
    }
    
    #[test]
    fn test_iteration() {
        let values = vec![
            AttrValue::Int(1),
            AttrValue::Int(2),
            AttrValue::Int(3),
        ];
        
        let arr = GraphArray::from_vec(values);
        
        let mut sum = 0;
        for value in &arr {
            if let AttrValue::Int(i) = value {
                sum += i;
            }
        }
        
        assert_eq!(sum, 6);
    }
}

--- FILE: core/adjacency.rs ---
//! GraphMatrix Operations - High-Performance Matrix Generation using GraphArray
//!
//! This module provides efficient adjacency matrix generation for graphs and subgraphs
//! with native Rust performance using our existing GraphArray infrastructure.
//!
//! # Features
//! - GraphMatrix built on GraphArray for consistency and statistical operations
//! - Dense and sparse matrix representations
//! - Compact indexing for subgraphs  
//! - Weighted and unweighted matrices
//! - Laplacian matrix generation
//! - Leverages existing statistical operations from GraphArray
//! - Memory-efficient storage formats

use crate::types::{NodeId, EdgeId, AttrValue};
use crate::errors::GraphResult;
use crate::core::space::GraphSpace;
use crate::core::pool::GraphPool;
use crate::core::array::GraphArray;  // Our enhanced array type
use std::collections::HashMap;

/// GraphMatrix - dense matrix representation using GraphArray for efficiency
#[derive(Debug, Clone)]
pub struct GraphMatrix {
    /// Matrix data stored as GraphArray for native statistical operations
    pub data: GraphArray,
    /// Number of rows (and columns, since square)
    pub size: usize,
    /// Storage format: row-major order
    pub row_major: bool,
    /// Optional row/column labels (node IDs)
    pub labels: Option<Vec<NodeId>>,
}

impl GraphMatrix {
    /// Get matrix element at (row, col) position
    pub fn get(&self, row: usize, col: usize) -> Option<&AttrValue> {
        if row < self.size && col < self.size {
            let index = if self.row_major {
                row * self.size + col
            } else {
                col * self.size + row  // Column-major
            };
            self.data.get(index)
        } else {
            None
        }
    }
    
    /// Get row as a slice of the underlying GraphArray
    pub fn get_row(&self, row: usize) -> Option<Vec<AttrValue>> {
        if row < self.size {
            let start = row * self.size;
            let end = start + self.size;
            Some(self.data.to_list()[start..end].to_vec())
        } else {
            None
        }
    }
    
    /// Get column values
    pub fn get_column(&self, col: usize) -> Option<Vec<AttrValue>> {
        if col < self.size {
            let mut column = Vec::with_capacity(self.size);
            for row in 0..self.size {
                if let Some(value) = self.get(row, col) {
                    column.push(value.clone());
                }
            }
            Some(column)
        } else {
            None
        }
    }
    
    /// Get diagonal values
    pub fn diagonal(&self) -> Vec<AttrValue> {
        let mut diag = Vec::with_capacity(self.size);
        for i in 0..self.size {
            if let Some(value) = self.get(i, i) {
                diag.push(value.clone());
            }
        }
        diag
    }
    
    /// Calculate trace (sum of diagonal elements) using GraphArray's sum method
    pub fn trace(&self) -> Option<f64> {
        let diag_array = GraphArray::from_vec(self.diagonal());
        diag_array.sum()
    }
}

/// Sparse adjacency matrix representation using COO format with GraphArray values
#[derive(Debug, Clone)]
pub struct SparseGraphMatrix {
    /// Row indices
    pub rows: Vec<usize>,
    /// Column indices  
    pub cols: Vec<usize>,
    /// Values at (row, col) positions as GraphArray for statistical operations
    pub values: GraphArray,
    /// Matrix dimensions (rows, cols)
    pub shape: (usize, usize),
    /// Optional row/column labels (node IDs)
    pub labels: Option<Vec<NodeId>>,
}

impl SparseGraphMatrix {
    /// Get matrix element at (row, col) position
    pub fn get(&self, row: usize, col: usize) -> Option<&AttrValue> {
        if row >= self.shape.0 || col >= self.shape.1 {
            return None;
        }
        
        // Find the entry in sparse format
        for i in 0..self.rows.len() {
            if self.rows[i] == row && self.cols[i] == col {
                return self.values.get(i);
            }
        }
        
        None  // Entry not found, implicitly zero
    }
    
    /// Get number of non-zero entries
    pub fn nnz(&self) -> usize {
        self.values.len()
    }
    
    /// Get density (fraction of non-zero entries)
    pub fn density(&self) -> f64 {
        let total_entries = self.shape.0 * self.shape.1;
        if total_entries > 0 {
            self.nnz() as f64 / total_entries as f64
        } else {
            0.0
        }
    }
    
    /// Get diagonal values (if they exist in sparse representation)
    pub fn diagonal(&self) -> Vec<AttrValue> {
        let mut diag = Vec::new();
        
        // Find diagonal entries
        for i in 0..self.rows.len() {
            if self.rows[i] == self.cols[i] {
                if let Some(value) = self.values.get(i) {
                    diag.push(value.clone());
                }
            }
        }
        
        diag
    }
    
    /// Calculate trace (sum of diagonal elements) using GraphArray's sum method
    pub fn trace(&self) -> Option<f64> {
        let diag_array = GraphArray::from_vec(self.diagonal());
        diag_array.sum()
    }
    
    /// Convert to dense representation if needed for certain operations
    pub fn to_dense(&self) -> GraphMatrix {
        let mut data = vec![AttrValue::Float(0.0); self.shape.0 * self.shape.1];
        
        // Fill in non-zero values
        for i in 0..self.rows.len() {
            let row = self.rows[i];
            let col = self.cols[i];
            let index = row * self.shape.1 + col;
            if let Some(value) = self.values.get(i) {
                data[index] = value.clone();
            }
        }
        
        GraphMatrix {
            data: GraphArray::from_vec(data),
            size: self.shape.0,
            row_major: true,
            labels: self.labels.clone(),
        }
    }
}

/// Matrix format options
#[derive(Debug, Clone, Copy, PartialEq)]
pub enum MatrixFormat {
    Dense,
    Sparse,
}

/// Matrix type options
#[derive(Debug, Clone, PartialEq)]
pub enum MatrixType {
    /// Simple 0/1 adjacency matrix
    Unweighted,
    /// Weighted matrix using edge attributes
    Weighted { weight_attr: Option<String> },
    /// Graph Laplacian matrix
    Laplacian { normalized: bool },
}

/// Index mapping for subgraph matrices
#[derive(Debug, Clone)]
pub struct IndexMapping {
    /// Maps compact matrix index to original node ID
    pub index_to_node: Vec<NodeId>,
    /// Maps original node ID to compact matrix index
    pub node_to_index: HashMap<NodeId, usize>,
}

impl IndexMapping {
    /// Create mapping from a list of node IDs
    pub fn from_nodes(nodes: &[NodeId]) -> Self {
        let index_to_node = nodes.to_vec();
        let node_to_index = nodes.iter()
            .enumerate()
            .map(|(i, &node_id)| (node_id, i))
            .collect();
        
        Self { index_to_node, node_to_index }
    }
    
    /// Get matrix index for a node ID
    pub fn get_index(&self, node_id: NodeId) -> Option<usize> {
        self.node_to_index.get(&node_id).copied()
    }
    
    /// Get node ID for a matrix index
    pub fn get_node(&self, index: usize) -> Option<NodeId> {
        self.index_to_node.get(index).copied()
    }
}

/// High-performance adjacency matrix generator
pub struct AdjacencyMatrixBuilder {
    format: MatrixFormat,
    matrix_type: MatrixType,
    use_compact_indexing: bool,
}

impl AdjacencyMatrixBuilder {
    /// Create new builder with default settings
    pub fn new() -> Self {
        Self {
            format: MatrixFormat::Sparse,
            matrix_type: MatrixType::Unweighted,
            use_compact_indexing: true,
        }
    }
    
    /// Set matrix format (dense or sparse)
    pub fn format(mut self, format: MatrixFormat) -> Self {
        self.format = format;
        self
    }
    
    /// Set matrix type (unweighted, weighted, or Laplacian)
    pub fn matrix_type(mut self, matrix_type: MatrixType) -> Self {
        self.matrix_type = matrix_type;
        self
    }
    
    /// Enable/disable compact indexing for subgraphs
    pub fn compact_indexing(mut self, compact: bool) -> Self {
        self.use_compact_indexing = compact;
        self
    }
    
    /// Build adjacency matrix for full graph
    pub fn build_full_graph(
        &self,
        pool: &GraphPool,
        space: &mut GraphSpace,
    ) -> GraphResult<AdjacencyMatrix> {
        let node_ids = space.node_ids();
        let mapping = if self.use_compact_indexing {
            Some(IndexMapping::from_nodes(&node_ids))
        } else {
            None
        };
        
        self.build_matrix(pool, space, &node_ids, mapping)
    }
    
    /// Build adjacency matrix for subgraph with specific nodes
    pub fn build_subgraph(
        &self,
        pool: &GraphPool,
        space: &mut GraphSpace,
        subgraph_nodes: &[NodeId],
    ) -> GraphResult<AdjacencyMatrix> {
        let mapping = if self.use_compact_indexing {
            Some(IndexMapping::from_nodes(subgraph_nodes))
        } else {
            None
        };
        
        self.build_matrix(pool, space, subgraph_nodes, mapping)
    }
    
    /// Core matrix building logic
    fn build_matrix(
        &self,
        pool: &GraphPool,
        space: &mut GraphSpace,
        nodes: &[NodeId],
        mapping: Option<IndexMapping>,
    ) -> GraphResult<AdjacencyMatrix> {
        let size = nodes.len();
        
        // Get graph topology (separate from matrix building to avoid borrow conflicts)
        let (edge_ids_ref, sources_ref, targets_ref, _) = space.snapshot(pool);
        // Clone the vectors to avoid borrow conflicts
        let edge_ids: Vec<EdgeId> = edge_ids_ref.as_ref().clone();
        let sources: Vec<NodeId> = sources_ref.as_ref().clone();
        let targets: Vec<NodeId> = targets_ref.as_ref().clone();
        
        match self.format {
            MatrixFormat::Dense => {
                let dense = self.build_dense_matrix(
                    pool, space, nodes, &edge_ids, &sources, &targets, size, &mapping
                )?;
                Ok(AdjacencyMatrix::Dense(dense))
            },
            MatrixFormat::Sparse => {
                let sparse = self.build_sparse_matrix(
                    pool, space, nodes, &edge_ids, &sources, &targets, size, &mapping
                )?;
                Ok(AdjacencyMatrix::Sparse(sparse))
            },
        }
    }
    
    /// Build dense adjacency matrix
    fn build_dense_matrix(
        &self,
        pool: &GraphPool,
        space: &mut GraphSpace,
        nodes: &[NodeId],
        edge_ids: &[EdgeId],
        sources: &[NodeId],
        targets: &[NodeId],
        size: usize,
        mapping: &Option<IndexMapping>,
    ) -> GraphResult<GraphMatrix> {
        let mut data = vec![AttrValue::Float(0.0); size * size];
        let node_set: HashMap<NodeId, usize> = if let Some(ref map) = mapping {
            map.node_to_index.clone()
        } else {
            nodes.iter().enumerate().map(|(i, &node)| (node, i)).collect()
        };
        
        // Fill matrix based on edges - respect graph directionality
        let is_directed = pool.graph_type() == crate::types::GraphType::Directed;
        
        for i in 0..edge_ids.len() {
            let source = sources[i];
            let target = targets[i];
            let edge_id = edge_ids[i];
            
            // Only include edges where both nodes are in our subgraph
            if let (Some(&src_idx), Some(&tgt_idx)) = (node_set.get(&source), node_set.get(&target)) {
                let value = self.get_edge_value(pool, space, edge_id)?;
                
                // Always add the primary direction (source → target)
                data[src_idx * size + tgt_idx] = AttrValue::Float(value as f32);
                
                // For undirected graphs, also add the reverse direction (target → source)
                if !is_directed && src_idx != tgt_idx {  // Avoid double-counting self-loops
                    data[tgt_idx * size + src_idx] = AttrValue::Float(value as f32);
                }
            }
        }
        
        // Apply matrix type transformations
        self.apply_matrix_type_dense(&mut data, size)?;
        
        Ok(GraphMatrix {
            data: GraphArray::from_vec(data),
            size,
            row_major: true,
            labels: mapping.as_ref().map(|m| m.index_to_node.clone()),
        })
    }
    
    /// Build sparse adjacency matrix
    fn build_sparse_matrix(
        &self,
        pool: &GraphPool,
        space: &mut GraphSpace,
        nodes: &[NodeId],
        edge_ids: &[EdgeId],
        sources: &[NodeId],
        targets: &[NodeId],
        size: usize,
        mapping: &Option<IndexMapping>,
    ) -> GraphResult<SparseGraphMatrix> {
        let mut rows = Vec::new();
        let mut cols = Vec::new();
        let mut values = Vec::new();
        
        let node_set: HashMap<NodeId, usize> = if let Some(ref map) = mapping {
            map.node_to_index.clone()
        } else {
            nodes.iter().enumerate().map(|(i, &node)| (node, i)).collect()
        };
        
        // Collect edges within subgraph - respect graph directionality
        let is_directed = pool.graph_type() == crate::types::GraphType::Directed;
        
        for i in 0..edge_ids.len() {
            let source = sources[i];
            let target = targets[i];
            let edge_id = edge_ids[i];
            
            if let (Some(&src_idx), Some(&tgt_idx)) = (node_set.get(&source), node_set.get(&target)) {
                let value = self.get_edge_value(pool, space, edge_id)?;
                
                // Always add the primary direction (source → target)
                rows.push(src_idx);
                cols.push(tgt_idx);
                values.push(AttrValue::Float(value as f32));
                
                // For undirected graphs, also add the reverse direction (target → source)
                if !is_directed && src_idx != tgt_idx {  // Avoid duplicate self-loops
                    rows.push(tgt_idx);
                    cols.push(src_idx);
                    values.push(AttrValue::Float(value as f32));
                }
            }
        }
        
        // Apply matrix type transformations  
        self.apply_matrix_type_sparse(&mut rows, &mut cols, &mut values, size)?;
        
        Ok(SparseGraphMatrix {
            rows,
            cols,
            values: GraphArray::from_vec(values),
            shape: (size, size),
            labels: mapping.as_ref().map(|m| m.index_to_node.clone()),
        })
    }
    
    /// Get edge value based on matrix type
    fn get_edge_value(&self, pool: &GraphPool, space: &GraphSpace, edge_id: EdgeId) -> GraphResult<f64> {
        match &self.matrix_type {
            MatrixType::Unweighted => Ok(1.0),
            MatrixType::Weighted { weight_attr } => {
                if let Some(attr_name) = weight_attr {
                    // Get the current index for this attribute from space
                    if let Some(index) = space.get_attr_index(edge_id, attr_name, false) {
                        // Get the value from pool using the index
                        if let Some(attr_value) = pool.get_attr_by_index(attr_name, index, false) {
                            match attr_value {
                                AttrValue::Float(f) => Ok(*f as f64),
                                AttrValue::Int(i) => Ok(*i as f64),
                                AttrValue::SmallInt(i) => Ok(*i as f64),
                                _ => Ok(1.0),  // Default for non-numeric weights
                            }
                        } else {
                            Ok(1.0)  // Default if attribute missing
                        }
                    } else {
                        Ok(1.0)  // Default if attribute missing
                    }
                } else {
                    Ok(1.0)  // Default unweighted
                }
            },
            MatrixType::Laplacian { .. } => Ok(1.0),  // Will be transformed later
        }
    }
    
    /// Apply matrix type transformations to dense matrix
    fn apply_matrix_type_dense(&self, data: &mut [AttrValue], size: usize) -> GraphResult<()> {
        match self.matrix_type {
            MatrixType::Laplacian { normalized } => {
                // Convert adjacency to Laplacian: L = D - A
                let mut degrees = vec![0.0; size];
                
                // Calculate degrees - extract float values
                for i in 0..size {
                    for j in 0..size {
                        if let AttrValue::Float(val) = data[i * size + j] {
                            degrees[i] += val as f64;
                        }
                    }
                }
                
                // Create Laplacian matrix
                for i in 0..size {
                    for j in 0..size {
                        if let AttrValue::Float(val) = data[i * size + j] {
                            let new_val = if i == j {
                                degrees[i] - (val as f64)
                            } else {
                                -(val as f64)
                            };
                            data[i * size + j] = AttrValue::Float(new_val as f32);
                        }
                    }
                }
                
                // Normalize if requested
                if normalized {
                    for i in 0..size {
                        for j in 0..size {
                            if let AttrValue::Float(val) = data[i * size + j] {
                                if degrees[i] > 0.0 && degrees[j] > 0.0 {
                                    let normalized_val = (val as f64) / (degrees[i] * degrees[j]).sqrt();
                                    data[i * size + j] = AttrValue::Float(normalized_val as f32);
                                }
                            }
                        }
                    }
                }
            },
            _ => {}, // No transformation needed
        }
        Ok(())
    }
    
    /// Apply matrix type transformations to sparse matrix
    fn apply_matrix_type_sparse(
        &self,
        rows: &mut Vec<usize>,
        cols: &mut Vec<usize>,
        values: &mut Vec<AttrValue>,
        size: usize,
    ) -> GraphResult<()> {
        match self.matrix_type {
            MatrixType::Laplacian { normalized } => {
                // Calculate degrees - extract float values
                let mut degrees = vec![0.0; size];
                for i in 0..rows.len() {
                    if let AttrValue::Float(val) = values[i] {
                        degrees[rows[i]] += val as f64;
                    }
                }
                
                // Convert to Laplacian format
                for i in 0..values.len() {
                    let row = rows[i];
                    let col = cols[i];
                    
                    if let AttrValue::Float(val) = values[i] {
                        let new_val = if row == col {
                            degrees[row] - (val as f64)
                        } else {
                            -(val as f64)
                        };
                        values[i] = AttrValue::Float(new_val as f32);
                    }
                }
                
                // Add diagonal entries if missing
                for i in 0..size {
                    let has_diagonal = rows.iter().zip(cols.iter())
                        .any(|(&r, &c)| r == i && c == i);
                    
                    if !has_diagonal && degrees[i] > 0.0 {
                        rows.push(i);
                        cols.push(i);
                        values.push(AttrValue::Float(degrees[i] as f32));
                    }
                }
                
                // Normalize if requested
                if normalized {
                    for i in 0..values.len() {
                        let row = rows[i];
                        let col = cols[i];
                        if let AttrValue::Float(val) = values[i] {
                            if degrees[row] > 0.0 && degrees[col] > 0.0 {
                                let normalized_val = (val as f64) / (degrees[row] * degrees[col]).sqrt();
                                values[i] = AttrValue::Float(normalized_val as f32);
                            }
                        }
                    }
                }
            },
            _ => {}, // No transformation needed
        }
        Ok(())
    }
}

impl Default for AdjacencyMatrixBuilder {
    fn default() -> Self {
        Self::new()
    }
}

/// Adjacency matrix result using our GraphArray infrastructure
#[derive(Debug, Clone)]
pub enum AdjacencyMatrix {
    Dense(GraphMatrix),
    Sparse(SparseGraphMatrix),
}

impl AdjacencyMatrix {
    /// Get matrix dimensions
    pub fn shape(&self) -> (usize, usize) {
        match self {
            AdjacencyMatrix::Dense(m) => (m.size, m.size),
            AdjacencyMatrix::Sparse(m) => m.shape,
        }
    }
    
    /// Get node labels if available
    pub fn labels(&self) -> Option<&[NodeId]> {
        match self {
            AdjacencyMatrix::Dense(m) => m.labels.as_deref(),
            AdjacencyMatrix::Sparse(m) => m.labels.as_deref(),
        }
    }
    
    /// Check if matrix is sparse
    pub fn is_sparse(&self) -> bool {
        matches!(self, AdjacencyMatrix::Sparse(_))
    }
    
    /// Get memory usage in bytes (approximate)
    pub fn memory_usage(&self) -> usize {
        match self {
            AdjacencyMatrix::Dense(m) => {
                m.data.len() * std::mem::size_of::<AttrValue>() +
                m.labels.as_ref().map_or(0, |l| l.len() * std::mem::size_of::<NodeId>())
            },
            AdjacencyMatrix::Sparse(m) => {
                (m.rows.len() + m.cols.len()) * std::mem::size_of::<usize>() +
                m.values.len() * std::mem::size_of::<AttrValue>() +
                m.labels.as_ref().map_or(0, |l| l.len() * std::mem::size_of::<NodeId>())
            },
        }
    }
}

--- FILE: core/delta.rs ---
//! Delta Storage System - Efficient representation of changes between graph states.
//!
//! ARCHITECTURE ROLE:
//! This module provides the core data structures for representing changes 
//! (deltas) between different graph states. It's the foundation of the 
//! version control system, enabling efficient storage and application of changes.
//!
//! DESIGN PHILOSOPHY:
//! - Columnar storage for bulk operations and cache efficiency
//! - Content-addressed deltas for automatic deduplication
//! - Immutable delta objects for safe sharing
//! - Sparse representation (only store what changed)

/*
=== DELTA SYSTEM OVERVIEW ===

The delta system is responsible for:
1. EFFICIENT REPRESENTATION: Store only what changed, not full snapshots
2. COLUMNAR LAYOUT: Group changes by attribute for bulk operations
3. CONTENT ADDRESSING: Hash-based deduplication of identical changes
4. FAST APPLICATION: Apply changes efficiently to reconstruct states
5. MERGING: Combine deltas from different sources (branch merging)

KEY INSIGHTS:
- Sparse storage: Most entities don't change between states
- Columnar layout: Better cache locality for bulk attribute operations
- Sorted indices: Enable binary search and efficient merging
- Immutable design: Safe for concurrent access and sharing
*/

use std::collections::HashMap;
use std::sync::Arc;
use std::hash::{Hash, Hasher};
use crate::types::{AttrName, AttrValue, NodeId, EdgeId};

/// Index-based columnar delta for efficient temporal versioning
#[derive(Debug, Clone)]
pub struct ColumnIndexDelta {
    /// Entity indices that changed (sorted)
    pub entity_indices: Vec<usize>,
    /// Previous column indices (None = attribute was new)
    pub old_column_indices: Vec<Option<usize>>,
    /// New column indices
    pub new_column_indices: Vec<usize>,
}

impl ColumnIndexDelta {
    /// Create a new empty index delta
    pub fn new() -> Self {
        Self {
            entity_indices: Vec::new(),
            old_column_indices: Vec::new(),
            new_column_indices: Vec::new(),
        }
    }
    
    /// Add an index change at the specified entity index
    pub fn add_index_change(&mut self, entity_index: usize, old_idx: Option<usize>, new_idx: usize) {
        // Find insertion point to maintain sorted order by entity_index
        let pos = self.entity_indices.binary_search(&entity_index).unwrap_or_else(|e| e);
        
        if pos < self.entity_indices.len() && self.entity_indices[pos] == entity_index {
            // Update existing change - keep original old_idx, update to latest new_idx
            self.new_column_indices[pos] = new_idx;
        } else {
            // Insert new change
            self.entity_indices.insert(pos, entity_index);
            self.old_column_indices.insert(pos, old_idx);
            self.new_column_indices.insert(pos, new_idx);
        }
    }
    
    /// Get the change at a specific entity index
    pub fn get_change(&self, entity_index: usize) -> Option<(Option<usize>, usize)> {
        self.entity_indices.binary_search(&entity_index)
            .ok()
            .map(|pos| (self.old_column_indices[pos], self.new_column_indices[pos]))
    }
    
    /// Check if this delta has changes at the given entity index
    pub fn has_change(&self, entity_index: usize) -> bool {
        self.entity_indices.binary_search(&entity_index).is_ok()
    }
    
    /// Get the number of changes in this delta
    pub fn len(&self) -> usize {
        self.entity_indices.len()
    }
    
    /// Check if this delta is empty
    pub fn is_empty(&self) -> bool {
        self.entity_indices.is_empty()
    }
}

impl Hash for ColumnIndexDelta {
    fn hash<H: Hasher>(&self, state: &mut H) {
        self.entity_indices.hash(state);
        self.old_column_indices.hash(state);
        self.new_column_indices.hash(state);
    }
}

/// Columnar delta storage for efficient bulk operations (legacy - stores values)
#[derive(Debug, Clone)]
pub struct ColumnDelta {
    /// Sorted indices where changes occurred
    pub indices: Vec<usize>,
    /// Corresponding values (parallel array to indices)
    pub values: Vec<AttrValue>,
}

impl ColumnDelta {
    /// Create a new empty column delta
    pub fn new() -> Self {
        Self {
            indices: Vec::new(),
            values: Vec::new(),
        }
    }

    /// Create a column delta with initial capacity
    pub fn with_capacity(capacity: usize) -> Self {
        Self {
            indices: Vec::with_capacity(capacity),
            values: Vec::with_capacity(capacity),
        }
    }

    /// Add a change at the specified index
    pub fn add_change(&mut self, index: usize, value: AttrValue) {
        // Find insertion point to maintain sorted order
        let pos = self.indices.binary_search(&index).unwrap_or_else(|e| e);
        
        if pos < self.indices.len() && self.indices[pos] == index {
            // Update existing value
            self.values[pos] = value;
        } else {
            // Insert new value
            self.indices.insert(pos, index);
            self.values.insert(pos, value);
        }
    }

    /// Get the value at a specific index, if it exists
    pub fn get(&self, index: usize) -> Option<&AttrValue> {
        self.indices.binary_search(&index)
            .ok()
            .map(|pos| &self.values[pos])
    }

    /// Check if this delta has changes at the given index
    pub fn has_change(&self, index: usize) -> bool {
        self.indices.binary_search(&index).is_ok()
    }

    /// Get the number of changes in this delta
    pub fn len(&self) -> usize {
        self.indices.len()
    }

    /// Check if this delta is empty
    pub fn is_empty(&self) -> bool {
        self.indices.is_empty()
    }

    /// Merge another column delta into this one
    pub fn merge(&mut self, other: &ColumnDelta) {
        for (i, &index) in other.indices.iter().enumerate() {
            self.add_change(index, other.values[i].clone());
        }
    }
}

impl Hash for ColumnDelta {
    fn hash<H: Hasher>(&self, state: &mut H) {
        self.indices.hash(state);
        for value in &self.values {
            value.hash(state);
        }
    }
}

/// Immutable delta object representing changes between states
#[derive(Debug, Clone)]
pub struct DeltaObject {
    /// Node attribute changes stored columnarly
    pub node_attrs: Arc<HashMap<AttrName, ColumnDelta>>,
    /// Edge attribute changes stored columnarly  
    pub edge_attrs: Arc<HashMap<AttrName, ColumnDelta>>,
    /// Nodes that became active/inactive
    pub node_active_changes: Arc<ColumnDelta>,
    /// Edges that became active/inactive
    pub edge_active_changes: Arc<ColumnDelta>,
    /// Content hash for deduplication
    pub content_hash: [u8; 32],
}

impl DeltaObject {
    /// Create a new delta object
    pub fn new(
        node_attrs: HashMap<AttrName, ColumnDelta>,
        edge_attrs: HashMap<AttrName, ColumnDelta>,
        node_active_changes: ColumnDelta,
        edge_active_changes: ColumnDelta,
    ) -> Self {
        let delta = Self {
            node_attrs: Arc::new(node_attrs),
            edge_attrs: Arc::new(edge_attrs),
            node_active_changes: Arc::new(node_active_changes),
            edge_active_changes: Arc::new(edge_active_changes),
            content_hash: [0; 32], // Will be computed below
        };
        
        // Compute content hash by converting HashMaps to sorted vectors
        let mut hasher = std::collections::hash_map::DefaultHasher::new();
        
        // Hash node attributes in sorted order
        let mut node_attrs_sorted: Vec<_> = delta.node_attrs.iter().collect();
        node_attrs_sorted.sort_by_key(|(k, _)| *k);
        for (key, value) in node_attrs_sorted {
            key.hash(&mut hasher);
            value.hash(&mut hasher);
        }
        
        // Hash edge attributes in sorted order
        let mut edge_attrs_sorted: Vec<_> = delta.edge_attrs.iter().collect();
        edge_attrs_sorted.sort_by_key(|(k, _)| *k);
        for (key, value) in edge_attrs_sorted {
            key.hash(&mut hasher);
            value.hash(&mut hasher);
        }
        
        // Hash active changes
        delta.node_active_changes.hash(&mut hasher);
        delta.edge_active_changes.hash(&mut hasher);
        
        let hash_value = hasher.finish();
        let mut hash = [0u8; 32];
        hash[..8].copy_from_slice(&hash_value.to_le_bytes());
        
        Self {
            content_hash: hash,
            ..delta
        }
    }
    
    /// Create a new index-based delta object (placeholder for future full implementation)
    /// Currently adapts to existing value-based structure
    pub fn new_with_indices(
        _node_attr_indices: HashMap<AttrName, ColumnIndexDelta>,
        _edge_attr_indices: HashMap<AttrName, ColumnIndexDelta>,
        _nodes_added: Vec<NodeId>,
        _nodes_removed: Vec<NodeId>,
        _edges_added: Vec<(EdgeId, NodeId, NodeId)>,
        _edges_removed: Vec<EdgeId>,
    ) -> Self {
        // NOTE: This is a temporary adapter implementation
        // In a full implementation, we'd have a separate IndexDeltaObject
        // or modify DeltaObject to natively support index-based deltas
        
        // For now, create an empty value-based delta
        // The index information is preserved in the ChangeTracker
        Self::new(
            HashMap::new(), // Would need Pool access to resolve indices to values
            HashMap::new(),
            ColumnDelta::new(),
            ColumnDelta::new(),
        )
    }

    /// Create an empty delta object
    pub fn empty() -> Self {
        Self::new(
            HashMap::new(),
            HashMap::new(),
            ColumnDelta::new(),
            ColumnDelta::new(),
        )
    }

    /// Check if this delta is empty (no changes)
    pub fn is_empty(&self) -> bool {
        self.node_attrs.is_empty() 
            && self.edge_attrs.is_empty()
            && self.node_active_changes.is_empty()
            && self.edge_active_changes.is_empty()
    }

    /// Get the total number of changes in this delta
    pub fn change_count(&self) -> usize {
        let node_attr_changes: usize = self.node_attrs.values().map(|d| d.len()).sum();
        let edge_attr_changes: usize = self.edge_attrs.values().map(|d| d.len()).sum();
        node_attr_changes + edge_attr_changes + 
            self.node_active_changes.len() + self.edge_active_changes.len()
    }
}

impl Hash for DeltaObject {
    fn hash<H: Hasher>(&self, state: &mut H) {
        self.content_hash.hash(state);
    }
}

impl PartialEq for DeltaObject {
    fn eq(&self, other: &Self) -> bool {
        self.content_hash == other.content_hash
    }
}

impl Eq for DeltaObject {}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_column_delta_basic_operations() {
        let mut delta = ColumnDelta::new();
        
        delta.add_change(5, AttrValue::Int(42));
        delta.add_change(2, AttrValue::Text("hello".to_string()));
        delta.add_change(8, AttrValue::Bool(true));
        
        assert_eq!(delta.len(), 3);
        assert_eq!(delta.get(5), Some(&AttrValue::Int(42)));
        assert_eq!(delta.get(2), Some(&AttrValue::Text("hello".to_string())));
        assert!(delta.has_change(8));
        assert!(!delta.has_change(10));
    }

    #[test]
    fn test_column_delta_maintains_order() {
        let mut delta = ColumnDelta::new();
        
        delta.add_change(5, AttrValue::Int(1));
        delta.add_change(2, AttrValue::Int(2));
        delta.add_change(8, AttrValue::Int(3));
        delta.add_change(1, AttrValue::Int(4));
        
        assert_eq!(delta.indices, vec![1, 2, 5, 8]);
    }
}


--- FILE: core/ref_manager.rs ---
//! Reference Management System - Git-like branch and tag management.
//!
//! ARCHITECTURE ROLE:
//! This module provides Git-like reference management for organizing and
//! navigating the graph's history. It manages branches (mutable references)
//! and tags (immutable references) that point to specific states.
//!
//! DESIGN PHILOSOPHY:
//! - Lightweight references (just pointers to states)
//! - Git-like workflow (branch, merge, tag operations)
//! - Metadata-rich references (creation time, author, description)
//! - Concurrent-safe operations

use std::collections::{HashMap, HashSet};
use crate::types::{StateId, BranchName};
use crate::errors::{GraphError, GraphResult};

/*
=== REFERENCE SYSTEM OVERVIEW ===

The reference system provides:
1. BRANCH MANAGEMENT: Mutable pointers to evolving history lines
2. TAG MANAGEMENT: Immutable markers for important states
3. CURRENT CONTEXT: Track which branch is currently checked out
4. MERGE OPERATIONS: Combine history from different branches
5. GARBAGE COLLECTION: Clean up references to non-existent states

KEY DESIGN DECISIONS:
- Branches are lightweight (just state pointers + metadata)
- Tags are immutable once created
- Always maintain a "current branch" for context
- Support branch descriptions and creation metadata
- Automatic cleanup of invalid references
*/

/// A branch pointer to a specific state in the graph history
/// 
/// DESIGN: Branches are mutable references that can be updated to point
/// to new states as development progresses. They carry metadata about
/// their creation and purpose.
/// 
/// LIFECYCLE:
/// 1. Created pointing to an initial state
/// 2. Updated as new commits are made on the branch
/// 3. Can be merged with other branches
/// 4. Can be deleted when no longer needed
#[derive(Debug, Clone)]
pub struct Branch {
    /// Human-readable branch name (must be unique)
    /// EXAMPLES: "main", "feature/user-auth", "hotfix/security-patch"
    pub name: BranchName,
    
    /// Current head state (most recent commit on this branch)
    /// This is the state that new commits will build upon
    pub head: StateId,
    
    /// Optional human-readable description
    /// USAGE: Explain the purpose of this branch
    pub description: Option<String>,
    
    /// When this branch was created (Unix timestamp)
    /// USAGE: For sorting, cleanup, and auditing
    pub created_at: u64,
    
    /// Who created this branch
    /// USAGE: For auditing and contact information
    pub created_by: String,
}

impl Branch {
    /// Create a new branch pointing to a specific state
    pub fn new(name: BranchName, head: StateId, created_by: String) -> Self {
        Self {
            name,
            head,
            description: None,
            created_at: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap_or_default()
                .as_secs(),
            created_by,
        }
    }

    /// Create a branch with a description
    pub fn with_description(
        name: BranchName, 
        head: StateId, 
        created_by: String, 
        description: String
    ) -> Self {
        Self {
            name,
            head,
            description: Some(description),
            created_at: std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap_or_default()
                .as_secs(),
            created_by,
        }
    }

    /// Update the head of this branch to a new state
    /// 
    /// USAGE: Called when new commits are made on this branch
    pub fn update_head(&mut self, new_head: StateId) {
        self.head = new_head;
    }

    /// Set or update the description
    pub fn set_description(&mut self, description: Option<String>) {
        self.description = description;
    }

    /// Check if this branch is older than a certain number of days
    pub fn is_older_than_days(&self, days: u64) -> bool {
        let now = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap_or_default()
            .as_secs();
        let threshold = days * 24 * 60 * 60; // Convert to seconds
        now.saturating_sub(self.created_at) > threshold
    }
}

/// Manages all branches and tags in the graph system
/// 
/// RESPONSIBILITIES:
/// - Maintain the collection of all branches and tags
/// - Track which branch is currently checked out
/// - Provide operations for creating, deleting, and updating references
/// - Handle branch switching and merging
/// - Clean up stale references
/// 
/// NOT RESPONSIBLE FOR:
/// - Actually storing graph states (that's HistoryForest's job)
/// - Performing merge operations (that's Graph's job)
/// - Validating state existence (that's HistoryForest's job)
#[derive(Debug)]
pub struct RefManager {
    /*
    === BRANCH MANAGEMENT ===
    */
    
    /// All branches indexed by name
    /// INVARIANT: Always contains at least the default branch
    branches: HashMap<BranchName, Branch>,
    
    /// Currently checked out branch
    /// INVARIANT: Must always exist in the branches map
    current_branch: BranchName,
    
    /// Default branch name (usually "main" or "master")
    /// INVARIANT: This branch cannot be deleted
    default_branch: BranchName,
    
    /*
    === TAG MANAGEMENT ===
    */
    
    /// Tags (immutable refs to specific states)
    /// DESIGN: Simple map from tag name to state ID
    /// IMMUTABILITY: Tags cannot be moved once created
    tags: HashMap<String, StateId>,
}

impl RefManager {
    /// Create a new reference manager with a default branch
    pub fn new() -> Self {
        let default_branch = "main".to_string();
        let mut branches = HashMap::new();
        
        // Create the default branch pointing to state 0 (empty state)
        let default_branch_obj = Branch::new(
            default_branch.clone(), 
            0, // StateId is just usize
            "system".to_string()
        );
        branches.insert(default_branch.clone(), default_branch_obj);
        
        Self {
            branches,
            current_branch: default_branch.clone(),
            default_branch,
            tags: HashMap::new(),
        }
    }
    
    /// Create a new reference manager with a custom default branch name
    pub fn with_default_branch(default_name: BranchName) -> Self {
        let mut branches = HashMap::new();
        
        // Create the default branch pointing to state 0 (empty state)
        let default_branch_obj = Branch::new(
            default_name.clone(), 
            0, // StateId is just usize
            "system".to_string()
        );
        branches.insert(default_name.clone(), default_branch_obj);
        
        Self {
            branches,
            current_branch: default_name.clone(),
            default_branch: default_name,
            tags: HashMap::new(),
        }
    }

    /*
    === BRANCH OPERATIONS ===
    */

    /// Create a new branch pointing to a specific state
    /// 
    /// ALGORITHM:
    /// 1. Check that branch name doesn't already exist
    /// 2. Validate that the target state exists (optional check)
    /// 3. Create Branch object with metadata
    /// 4. Add to branches map
    pub fn create_branch(
        &mut self,
        name: BranchName,
        start_state: StateId,
        created_by: String,
        description: Option<String>,
    ) -> GraphResult<()> {
        if self.branches.contains_key(&name) {
            return Err(GraphError::BranchAlreadyExists { 
                branch_name: name.clone(), 
                existing_head: self.branches[&name].head,
            });
        }
        
        let branch = if let Some(desc) = description {
            Branch::with_description(name.clone(), start_state, created_by, desc)
        } else {
            Branch::new(name.clone(), start_state, created_by)
        };
        
        self.branches.insert(name, branch);
        Ok(())
    }

    /// Switch to a different branch (checkout)
    /// 
    /// ALGORITHM:
    /// 1. Verify the target branch exists
    /// 2. Update current_branch pointer
    /// 3. Return the state ID that should be loaded
    pub fn checkout_branch(&mut self, name: &BranchName) -> GraphResult<StateId> {
        if !self.branches.contains_key(name) {
            return Err(GraphError::BranchNotFound {
                branch_name: name.clone(),
                operation: "checkout".to_string(),
                available_branches: self.branches.keys().cloned().collect(),
            });
        }
        
        self.current_branch = name.clone();
        Ok(self.branches[name].head)
    }

    /// Delete a branch
    /// 
    /// RESTRICTIONS:
    /// - Cannot delete the default branch
    /// - Cannot delete the currently checked out branch
    /// - Branch must exist
    pub fn delete_branch(&mut self, name: &BranchName) -> GraphResult<()> {
        if name == &self.default_branch {
            return Err(GraphError::InvalidInput(format!(
                "Cannot delete default branch '{}': The default branch cannot be deleted", name
            )));
        }
        
        if name == &self.current_branch {
            return Err(GraphError::CannotDeleteCurrentBranch { 
                branch_name: name.clone(),
            });
        }
        
        if !self.branches.contains_key(name) {
            return Err(GraphError::BranchNotFound {
                branch_name: name.clone(),
                operation: "delete".to_string(),
                available_branches: self.branches.keys().cloned().collect(),
            });
        }
        
        self.branches.remove(name);
        Ok(())
    }

    /// List all branches with their metadata
    pub fn list_branches(&self) -> Vec<BranchInfo> {
        self.branches.values()
            .map(|branch| BranchInfo {
                name: branch.name.clone(),
                head: branch.head,
                description: branch.description.clone(),
                created_at: branch.created_at,
                created_by: branch.created_by.clone(),
                is_current: branch.name == self.current_branch,
                is_default: branch.name == self.default_branch,
            })
            .collect()
    }

    /// Get the currently checked out branch
    pub fn get_current_branch(&self) -> GraphResult<&Branch> {
        self.branches.get(&self.current_branch)
            .ok_or_else(|| GraphError::BranchNotFound {
                branch_name: self.current_branch.clone(),
                operation: "get current".to_string(),
                available_branches: self.branches.keys().cloned().collect(),
            })
    }

    /// Get a specific branch by name
    pub fn get_branch(&self, name: &BranchName) -> GraphResult<&Branch> {
        self.branches.get(name)
            .ok_or_else(|| GraphError::BranchNotFound {
                branch_name: name.clone(),
                operation: "get branch".to_string(),
                available_branches: self.branches.keys().cloned().collect(),
            })
    }

    /// Update the head of the current branch
    /// 
    /// USAGE: Called after making a new commit
    pub fn update_current_branch_head(&mut self, new_head: StateId) -> GraphResult<()> {
        let current_name = self.current_branch.clone();
        if let Some(branch) = self.branches.get_mut(&current_name) {
            branch.update_head(new_head);
            Ok(())
        } else {
            Err(GraphError::BranchNotFound {
                branch_name: current_name,
                operation: "update head".to_string(),
                available_branches: self.branches.keys().cloned().collect(),
            })
        }
    }

    /// Update the head of a specific branch
    pub fn update_branch_head(&mut self, branch_name: &BranchName, new_head: StateId) -> GraphResult<()> {
        if let Some(branch) = self.branches.get_mut(branch_name) {
            branch.update_head(new_head);
            Ok(())
        } else {
            Err(GraphError::BranchNotFound {
                branch_name: branch_name.clone(),
                operation: "update head".to_string(),
                available_branches: self.branches.keys().cloned().collect(),
            })
        }
    }

    /*
    === TAG OPERATIONS ===
    */

    /// Create a new tag pointing to a specific state
    /// 
    /// IMMUTABILITY: Tags cannot be moved once created
    pub fn create_tag(&mut self, tag_name: String, state_id: StateId) -> GraphResult<()> {
        if self.tags.contains_key(&tag_name) {
            return Err(GraphError::InvalidInput(format!(
                "Tag '{}' already exists pointing to state {}", tag_name, self.tags[&tag_name]
            )));
        }
        
        self.tags.insert(tag_name, state_id);
        Ok(())
    }

    /// Delete a tag
    pub fn delete_tag(&mut self, tag_name: &str) -> GraphResult<()> {
        if !self.tags.contains_key(tag_name) {
            return Err(GraphError::InvalidInput(format!(
                "Tag '{}' not found. Available tags: {}", 
                tag_name, self.tags.keys().cloned().collect::<Vec<_>>().join(", ")
            )));
        }
        
        self.tags.remove(tag_name);
        Ok(())
    }

    /// List all tags
    pub fn list_tags(&self) -> Vec<TagInfo> {
        self.tags.iter()
            .map(|(name, &state_id)| TagInfo {
                name: name.clone(),
                state_id,
            })
            .collect()
    }

    /// Get the state ID for a specific tag
    pub fn get_tag(&self, tag_name: &str) -> Option<StateId> {
        self.tags.get(tag_name).copied()
    }

    /*
    === UTILITY AND MAINTENANCE OPERATIONS ===
    */

    /// Get all state IDs referenced by branches and tags
    /// 
    /// USAGE: For garbage collection - these states should not be deleted
    pub fn get_referenced_states(&self) -> Vec<StateId> {
        let mut states = Vec::new();
        
        // Add branch heads
        for branch in self.branches.values() {
            states.push(branch.head);
        }
        
        // Add tag states
        for &state_id in self.tags.values() {
            states.push(state_id);
        }
        
        // Remove duplicates and sort
        states.sort();
        states.dedup();
        states
    }

    /// Clean up branches that point to non-existent states
    /// 
    /// USAGE: After garbage collection in the history system
    /// RETURNS: Number of branches that were removed
    pub fn prune_invalid_branches(&mut self, valid_states: &[StateId]) -> usize {
        let valid_set: HashSet<_> = valid_states.iter().collect();
        let mut removed_count = 0;
        
        let branch_names: Vec<_> = self.branches.keys().cloned().collect();
        for branch_name in branch_names {
            if let Some(branch) = self.branches.get(&branch_name) {
                if !valid_set.contains(&branch.head) && branch_name != self.default_branch {
                    self.branches.remove(&branch_name);
                    removed_count += 1;
                }
            }
        }
        
        removed_count
    }

    /// Clean up tags that point to non-existent states
    /// 
    /// RETURNS: Number of tags that were removed
    pub fn prune_invalid_tags(&mut self, valid_states: &[StateId]) -> usize {
        let valid_set: HashSet<_> = valid_states.iter().collect();
        let mut removed_count = 0;
        
        let tag_names: Vec<_> = self.tags.keys().cloned().collect();
        for tag_name in tag_names {
            if let Some(&state_id) = self.tags.get(&tag_name) {
                if !valid_set.contains(&state_id) {
                    self.tags.remove(&tag_name);
                    removed_count += 1;
                }
            }
        }
        
        removed_count
    }

    /// Get basic information about the reference manager
    pub fn statistics(&self) -> RefStatistics {
        RefStatistics {
            branch_count: self.branches.len(),
            tag_count: self.tags.len(),
            current_branch: self.current_branch.clone(),
            default_branch: self.default_branch.clone(),
        }
    }

    /*
    === HELPER METHODS ===
    */

    /// Get list of all branch names (for error messages)
    #[allow(dead_code)]
    fn list_branch_names(&self) -> Vec<BranchName> {
        self.branches.keys().cloned().collect()
    }

    /// Get the current branch name
    pub fn current_branch_name(&self) -> &BranchName {
        &self.current_branch
    }

    /// Get the default branch name
    pub fn default_branch_name(&self) -> &BranchName {
        &self.default_branch
    }

    /// Check if a branch exists
    pub fn has_branch(&self, name: &BranchName) -> bool {
        self.branches.contains_key(name)
    }

    /// Check if a tag exists
    pub fn has_tag(&self, name: &str) -> bool {
        self.tags.contains_key(name)
    }
}

impl Default for RefManager {
    fn default() -> Self {
        Self::new()
    }
}

/*
=== SUPPORTING DATA STRUCTURES ===
*/

/// Information about a branch for listing and display
#[derive(Debug, Clone)]
pub struct BranchInfo {
    pub name: BranchName,
    pub head: StateId,
    pub description: Option<String>,
    pub created_at: u64,
    pub created_by: String,
    pub is_current: bool,
    pub is_default: bool,
}

impl BranchInfo {
    /// Get a human-readable description of this branch
    pub fn display_name(&self) -> String {
        let mut result = self.name.clone();
        if self.is_current {
            result.push_str(" *");
        }
        if self.is_default {
            result.push_str(" (default)");
        }
        result
    }

    /// Get the age of this branch in days
    pub fn age_days(&self) -> u64 {
        let now = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap_or_default()
            .as_secs();
        (now.saturating_sub(self.created_at)) / (24 * 60 * 60)
    }
}

/// Information about a tag for listing and display
#[derive(Debug, Clone)]
pub struct TagInfo {
    pub name: String,
    pub state_id: StateId,
}

/// Statistics about the reference manager
#[derive(Debug, Clone)]
pub struct RefStatistics {
    pub branch_count: usize,
    pub tag_count: usize,
    pub current_branch: BranchName,
    pub default_branch: BranchName,
}

/*
=== COMPREHENSIVE TEST SUITE ===
*/

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_ref_manager_creation() {
        // TODO: Uncomment when RefManager is implemented
        /*
        let ref_manager = RefManager::new();
        
        // Should have default branch
        assert_eq!(ref_manager.branch_count(), 1);
        assert_eq!(ref_manager.current_branch_name(), &"main".to_string());
        assert_eq!(ref_manager.default_branch_name(), &"main".to_string());
        assert!(ref_manager.has_branch(&"main".to_string()));
        */
    }

    #[test]
    fn test_branch_creation_and_deletion() {
        // TODO: Test branch lifecycle
        /*
        let mut ref_manager = RefManager::new();
        
        // Create a new branch
        ref_manager.create_branch(
            "feature".to_string(),
            StateId(1),
            "user".to_string(),
            Some("Feature branch".to_string()),
        ).unwrap();

        assert!(ref_manager.has_branch(&"feature".to_string()));
        assert_eq!(ref_manager.branch_count(), 2);
        
        let branch = ref_manager.get_branch(&"feature".to_string()).unwrap();
        assert_eq!(branch.head, StateId(1));
        assert_eq!(branch.description, Some("Feature branch".to_string()));

        // Delete the branch
        ref_manager.delete_branch(&"feature".to_string()).unwrap();
        assert!(!ref_manager.has_branch(&"feature".to_string()));
        assert_eq!(ref_manager.branch_count(), 1);
        */
    }

    #[test]
    fn test_branch_checkout() {
        // TODO: Test branch switching
        /*
        let mut ref_manager = RefManager::new();
        
        ref_manager.create_branch(
            "dev".to_string(), 
            StateId(2), 
            "user".to_string(), 
            None
        ).unwrap();
        
        let head = ref_manager.checkout_branch(&"dev".to_string()).unwrap();
        assert_eq!(head, StateId(2));
        assert_eq!(ref_manager.current_branch_name(), &"dev".to_string());
        */
    }

    #[test]
    fn test_tag_operations() {
        // TODO: Test tag lifecycle
        /*
        let mut ref_manager = RefManager::new();
        
        // Create tag
        ref_manager.create_tag("v1.0".to_string(), StateId(5)).unwrap();
        
        assert!(ref_manager.has_tag("v1.0"));
        assert_eq!(ref_manager.get_tag("v1.0"), Some(StateId(5)));
        
        // List tags
        let tags = ref_manager.list_tags();
        assert_eq!(tags.len(), 1);
        assert_eq!(tags[0].name, "v1.0");
        assert_eq!(tags[0].state_id, StateId(5));
        
        // Delete tag
        ref_manager.delete_tag("v1.0").unwrap();
        assert!(!ref_manager.has_tag("v1.0"));
        */
    }

    #[test]
    fn test_reference_cleanup() {
        // TODO: Test cleanup of invalid references
        /*
        let mut ref_manager = RefManager::new();
        
        // Create branches and tags
        ref_manager.create_branch("temp".to_string(), StateId(999), "user".to_string(), None).unwrap();
        ref_manager.create_tag("old_tag".to_string(), StateId(888)).unwrap();
        
        // Prune invalid references
        let valid_states = vec![StateId(0), StateId(1), StateId(2)];
        let removed_branches = ref_manager.prune_invalid_branches(&valid_states);
        let removed_tags = ref_manager.prune_invalid_tags(&valid_states);
        
        assert_eq!(removed_branches, 1); // temp branch removed
        assert_eq!(removed_tags, 1); // old_tag removed
        */
    }

    #[test]
    fn test_error_handling() {
        // TODO: Test error conditions
        /*
        let mut ref_manager = RefManager::new();
        
        // Try to create duplicate branch
        let result = ref_manager.create_branch(
            "main".to_string(), 
            StateId(1), 
            "user".to_string(), 
            None
        );
        assert!(result.is_err());
        
        // Try to checkout non-existent branch
        let result = ref_manager.checkout_branch(&"nonexistent".to_string());
        assert!(result.is_err());
        
        // Try to delete default branch
        let result = ref_manager.delete_branch(&"main".to_string());
        assert!(result.is_err());
        
        // Try to delete current branch
        ref_manager.create_branch("test".to_string(), StateId(1), "user".to_string(), None).unwrap();
        ref_manager.checkout_branch(&"test".to_string()).unwrap();
        let result = ref_manager.delete_branch(&"test".to_string());
        assert!(result.is_err());
        */
    }
}

/*
=== IMPLEMENTATION NOTES ===

PERFORMANCE CHARACTERISTICS:
- Branch operations: O(1) for most operations (HashMap lookups)
- Tag operations: O(1) for most operations
- Listing operations: O(n) where n = number of branches/tags
- Cleanup operations: O(n) where n = number of references

MEMORY USAGE:
- Very lightweight - just metadata and pointers
- No duplication of state data
- Efficient HashMap storage for fast lookups

CONCURRENCY:
- Thread-safe for read operations
- Mutations require exclusive access
- No internal locking (handled at higher level)

INTEGRATION WITH HISTORY:
- RefManager doesn't validate state existence
- HistoryForest is responsible for state management
- Cleanup operations bridge the two systems

FUTURE ENHANCEMENTS:
- Branch permissions and access control
- Branch-specific configuration
- Automatic branch cleanup policies
- Integration with external version control systems
*/

--- FILE: api/graph.rs ---
//! Main Graph API - the primary facade and coordinator for all graph operations.
//!
//! *** ARCHITECTURE OVERVIEW ***
//! The Graph is the MAIN MANAGER and single entry point for all operations.
//! It coordinates between specialized components but doesn't delegate through layers.
//! 
//! DESIGN PHILOSOPHY:
//! - Graph = Smart Coordinator (knows about all components, delegates wisely)
//! - Graphpool = Pure Data Storage (no business logic, just efficient storage)
//! - GraphSpace = Active Set + Change Tracking (minimal responsibility)
//! - HistoryForest = Version Control (immutable snapshots, branching)
//! - QueryEngine = Read-only Analysis (filtering, aggregation, views)

use crate::core::change_tracker::ChangeTracker;
use crate::core::pool::GraphPool;
use std::rc::Rc;
use std::cell::RefCell;
use std::sync::Arc;
use crate::core::space::GraphSpace;
use crate::core::history::{HistoryForest, HistoricalView, CommitDiff};
use crate::core::query::{QueryEngine, NodeFilter, EdgeFilter};
use crate::core::traversal::TraversalEngine;
use crate::core::ref_manager::BranchInfo;
use crate::core::adjacency::{AdjacencyMatrixBuilder, AdjacencyMatrix, MatrixFormat, MatrixType};
use crate::config::GraphConfig;
use crate::types::{NodeId, EdgeId, AttrName, AttrValue, StateId, BranchName, MemoryStatistics, MemoryEfficiency, CompressionStatistics};
use crate::errors::{GraphError, GraphResult};
use std::collections::HashMap;
use std::path::Path;


/*
=== THE GRAPH: MASTER COORDINATOR ===

This is the main API that users interact with. It's responsible for:
1. Coordinating between storage, history, and query components
2. Managing transactions and ensuring consistency
3. Providing a clean, intuitive API surface
4. Handling all the complex interactions between subsystems

Key insight: Graph should be SMART about how it uses its components,
not just a thin wrapper that passes calls through layers.

*/

/// The main Graph structure - your primary interface for all graph operations
/// 
/// RESPONSIBILITIES:
/// - Coordinate all graph operations across components
/// - Manage transactional boundaries and consistency
/// - Handle ID generation and entity lifecycle
/// - Provide intuitive API for users
/// - Optimize cross-component operations
/// 
/// COMPONENTS IT MANAGES:
/// - GraphSpace: Active topology and change tracking (nodes, edges, modifications)
/// - GraphPool: Core attribute storage (columnar data for nodes and edges)
/// - HistoryForest: Version control and branching  
/// - QueryEngine: Read-only views and analysis
/// - Configuration: Settings and performance tuning
#[derive(Debug)]
pub struct Graph {
    /*
    === CORE DATA STORAGE ===
    The source of truth for current graph state
    */
    /// Attribute storage - holds columnar data for node and edge attributes
    /// This is where the actual attribute data lives
    /// Wrapped in Rc<RefCell<>> for interior mutability access from GraphSpace
    pool: Rc<RefCell<GraphPool>>,
    
    /*
    === VERSION CONTROL SYSTEM ===
    Git-like functionality for graph evolution
    */
    /// Immutable history of graph states
    /// Manages snapshots, branching, merging
    history: HistoryForest,
    
    /// Current branch and commit information
    /// Tracks where we are in the version history
    current_branch: BranchName,
    current_commit: StateId,
    
    /*
    === QUERY AND ANALYSIS ENGINE ===
    Read-only operations, filtering, views
    */
    /// Query processor for complex read operations
    /// Handles filtering, aggregation, pattern matching
    query_engine: QueryEngine,
    
    /// Graph traversal engine for BFS, DFS, pathfinding
    /// Handles connectivity analysis and traversal algorithms
    traversal_engine: TraversalEngine,
    
    /*
    === TRANSACTION MANAGEMENT ===
    Track what's changed since last commit
    */
    /// Current active state (which entities exist, current attribute indices)
    /// Space ONLY manages current state, not change deltas
    space: GraphSpace,
    
    /// Tracks changes for history commits (deltas between states)
    /// ChangeTracker ONLY manages deltas, not current state
    change_tracker: ChangeTracker,
    
    /*
    === CONFIGURATION ===
    Performance tuning and behavior control
    */
    /// Configuration settings
    #[allow(dead_code)]
    config: GraphConfig,
}

impl Graph {
    /// Create a new empty graph with default settings (undirected by default)
    pub fn new() -> Self {
        Self::new_with_type(crate::types::GraphType::default())
    }
    
    /// Create a new empty graph with specified directionality
    /// 
    /// # Arguments
    /// * `graph_type` - Whether the graph is directed or undirected
    /// 
    /// # Examples
    /// ```
    /// use groggy::api::Graph;
    /// use groggy::types::GraphType;
    /// 
    /// // Create a directed graph (like NetworkX DiGraph)
    /// let directed_graph = Graph::new_with_type(GraphType::Directed);
    /// 
    /// // Create an undirected graph (like NetworkX Graph)  
    /// let undirected_graph = Graph::new_with_type(GraphType::Undirected);
    /// ```
    pub fn new_with_type(graph_type: crate::types::GraphType) -> Self {
        let mut config = GraphConfig::new();
        config.graph_type = graph_type;
        let pool = Rc::new(RefCell::new(GraphPool::new_with_type(graph_type)));
        Self {
            space: GraphSpace::new(pool.clone(), 0), // base state = 0
            pool,
            history: HistoryForest::new(),
            current_branch: "main".to_string(),
            current_commit: 0,
            query_engine: QueryEngine::new(),
            traversal_engine: TraversalEngine::new(),
            change_tracker: ChangeTracker::new(),
            config,
        }
    }
    
    /// Create a new directed graph (like NetworkX DiGraph)
    /// 
    /// This is a convenience method equivalent to `new_with_type(GraphType::Directed)`
    pub fn new_directed() -> Self {
        Self::new_with_type(crate::types::GraphType::Directed)
    }
    
    /// Create a new undirected graph (like NetworkX Graph)
    /// 
    /// This is a convenience method equivalent to `new_with_type(GraphType::Undirected)`
    pub fn new_undirected() -> Self {
        Self::new_with_type(crate::types::GraphType::Undirected)
    }
    
    /// Create a graph with custom configuration
    pub fn with_config(config: GraphConfig) -> Self {
        let pool = Rc::new(RefCell::new(GraphPool::new_with_type(config.graph_type)));
        Self {
            space: GraphSpace::new(pool.clone(), 0), // base state = 0
            pool,
            history: HistoryForest::new(),
            current_branch: "main".to_string(),
            current_commit: 0,
            query_engine: QueryEngine::new(),
            traversal_engine: TraversalEngine::new(),
            change_tracker: ChangeTracker::new(),
            config,
        }
    }
    
    /// Load an existing graph from storage
    pub fn load_from_path(path: &Path) -> Result<Self, GraphError> {
        // TODO: This is for persistence - load from disk
        // TODO: Deserialize pool, history, branches, etc.
        let _ = path; // Silence unused parameter warning
        Err(GraphError::NotImplemented {
            feature: "load_from_path".to_string(),
            tracking_issue: None,
        })
    }
    
    /// Get the graph type (directed or undirected)
    pub fn graph_type(&self) -> crate::types::GraphType {
        self.config.graph_type
    }
    
    /// Check if this graph is directed
    pub fn is_directed(&self) -> bool {
        matches!(self.config.graph_type, crate::types::GraphType::Directed)
    }
    
    /// Check if this graph is undirected
    pub fn is_undirected(&self) -> bool {
        matches!(self.config.graph_type, crate::types::GraphType::Undirected)
    }
    
    /*
    === CORE GRAPH OPERATIONS ===
    These are the fundamental operations that modify graph structure.
    The Graph coordinates between pool, history, and change tracking.
    */
    
    /// Add a new node to the graph
    /// 
    /// ALGORITHM:
    /// 1. Pool creates and stores the node
    /// 2. Space tracks it as active
    /// 3. Return the node ID to caller
    /// 
    /// PERFORMANCE: O(1) amortized
    pub fn add_node(&mut self) -> NodeId {
        let node_id = self.pool.borrow_mut().add_node();        // Pool creates and stores
        self.space.activate_node(node_id);         // Space tracks as active
        self.change_tracker.record_node_addition(node_id);  // Track change for commit
        node_id
    }
    
    /// Add multiple nodes efficiently
    /// OPTIMIZED: True bulk operation using vectorized pool operations
    pub fn add_nodes(&mut self, count: usize) -> Vec<NodeId> {
        // Use optimized bulk pool operation
        let (_start_id, _end_id, node_ids) = self.pool.borrow_mut().add_nodes_bulk(count);
        
        // Use optimized bulk space activation  
        self.space.activate_nodes(node_ids.clone());
        
        // Single bulk change tracking update
        self.change_tracker.record_nodes_addition(&node_ids);
        
        node_ids
    }
    
    /// Add an edge between two existing nodes
    /// 
    /// ALGORITHM:
    /// 1. Validate nodes exist in active set
    /// 2. Pool creates and stores the edge
    /// 3. Space tracks it as active
    /// 4. Return edge ID
    pub fn add_edge(&mut self, source: NodeId, target: NodeId) -> Result<EdgeId, GraphError> {
        if !self.space.contains_node(source) || !self.space.contains_node(target) {
            return Err(GraphError::node_not_found(source, "add edge"));
        }
        let edge_id = self.pool.borrow_mut().add_edge(source, target);  // Pool creates and stores
        self.space.activate_edge(edge_id, source, target); // Space tracks as active
        self.change_tracker.record_edge_addition(edge_id, source, target); // Track change
        Ok(edge_id)
    }

    /// Add multiple edges efficiently
    /// OPTIMIZED: True bulk operation with batch validation and vectorized operations
    pub fn add_edges(&mut self, edges: &[(NodeId, NodeId)]) -> Vec<EdgeId> {
        // Pre-filter valid edges in single pass
        let valid_edges: Vec<_> = edges.iter()
            .filter(|&&(source, target)| {
                self.space.contains_node(source) && self.space.contains_node(target)
            })
            .cloned()
            .collect();
        
        if valid_edges.is_empty() {
            return Vec::new();
        }
        
        // Use optimized bulk pool operation
        let edge_ids = self.pool.borrow_mut().add_edges(&valid_edges);
        
        // Use optimized bulk space activation
        self.space.activate_edges(edge_ids.clone());
        
        // Prepare data for change tracking
        let change_data: Vec<_> = edge_ids.iter()
            .zip(valid_edges.iter())
            .map(|(&edge_id, &(source, target))| (edge_id, source, target))
            .collect();
        
        // Single bulk change tracking update
        self.change_tracker.record_edges_addition(&change_data);
        
        edge_ids
    }
    
    /// Remove a node and all its incident edges
    /// 
    /// ALGORITHM:
    /// 1. Ask space to remove the node (it handles incident edges)
    pub fn remove_node(&mut self, node: NodeId) -> Result<(), GraphError> {
        if !self.space.contains_node(node) {
            return Err(GraphError::NodeNotFound {
                node_id: node,
                operation: "remove node".to_string(),
                suggestion: "Check if node exists with contains_node()".to_string(),
            });
        }
        
        self.change_tracker.record_node_removal(node);
        self.space.deactivate_node(node);
        Ok(())
    }
    
    /// Remove an edge
    pub fn remove_edge(&mut self, edge: EdgeId) -> Result<(), GraphError> {
        if !self.space.contains_edge(edge) {
            return Err(GraphError::EdgeNotFound {
                edge_id: edge,
                operation: "remove edge".to_string(),
                suggestion: "Check if edge exists with contains_edge()".to_string(),
            });
        }
        
        self.change_tracker.record_edge_removal(edge);
        self.space.deactivate_edge(edge);
        Ok(())
    }

    /// Remove multiple edges efficiently
    pub fn remove_edges(&mut self, edges: &[EdgeId]) -> Result<(), GraphError> {
        for &edge_id in edges {
            self.remove_edge(edge_id)?;
        }
        Ok(())
    }

    /// Remove multiple nodes efficiently
    pub fn remove_nodes(&mut self, nodes: &[NodeId]) -> Result<(), GraphError> {
        for &node_id in nodes {
            self.remove_node(node_id)?;
        }
        Ok(())
    }
    
    /*
    === ATTRIBUTE OPERATIONS ===
    Setting and getting properties on nodes and edges.
    These go directly to the pool with change tracking.
    */
    
    /// Set an attribute value on a node
    ///
    /// ALGORITHM:
    /// 1. Pool sets value and returns baseline (integrated change tracking)
    /// 2. Space records the change for commit delta
    pub fn set_node_attr(&mut self, node: NodeId, attr: AttrName, value: AttrValue) -> Result<(), GraphError> {
        // 1. Validate node is active
        if !self.space.contains_node(node) {
            return Err(GraphError::node_not_found(node, "set attribute"));
        }
        
        // 2. Get old index for change tracking
        let old_index = self.space.get_node_attr_index(node, &attr);
        
        // 3. Pool stores value and returns new index (is_node = true)
        let new_index = self.pool.borrow_mut().set_attr(attr.clone(), value, true);
        
        // 4. Space updates current mapping
        self.space.set_node_attr_index(node, attr.clone(), new_index);
        
        // 5. ChangeTracker records the delta
        self.change_tracker.record_attr_change(node, attr, old_index, new_index, true);
        
        Ok(())
    }
    
    
    
    /// Set node attributes in bulk (OPTIMIZED: True vectorized bulk operation)
    pub fn set_node_attrs(&mut self, attrs_values: HashMap<AttrName, Vec<(NodeId, AttrValue)>>) -> Result<(), GraphError> {
        // Batch validation - check all nodes exist upfront
        for node_values in attrs_values.values() {
            for &(node_id, _) in node_values {
                if !self.space.contains_node(node_id) {
                    return Err(GraphError::node_not_found(node_id, "set bulk node attributes"));
                }
            }
        }
        
        // Use optimized vectorized pool operation
        let index_changes = self.pool.borrow_mut().set_bulk_attrs(attrs_values, true);
        
        // Update space attribute indices in bulk
        for (attr_name, entity_indices) in index_changes {
            for (node_id, new_index) in entity_indices {
                self.space.set_node_attr_index(node_id, attr_name.clone(), new_index);
            }
        }
        
        // TODO: Bulk change tracking for attributes
        // For now, we skip individual change tracking for bulk operations
        // This could be optimized further with bulk change recording
        
        Ok(())
    }
    
    /// Set an attribute value on an edge
    ///
    /// ALGORITHM:
    /// 1. Pool sets value and returns baseline (integrated change tracking)
    /// 2. Space records the change for commit delta
    pub fn set_edge_attr(&mut self, edge: EdgeId, attr: AttrName, value: AttrValue) -> Result<(), GraphError> {
        // 1. Validate edge is active
        if !self.space.contains_edge(edge) {
            return Err(GraphError::EdgeNotFound {
                edge_id: edge,
                operation: "set attribute".to_string(),
                suggestion: "Check if edge exists with contains_edge()".to_string(),
            });
        }
        
        // 2. Get old index for change tracking
        let old_index = self.space.get_edge_attr_index(edge, &attr);
        
        // 3. Pool stores value and returns new index (is_node = false)
        let new_index = self.pool.borrow_mut().set_attr(attr.clone(), value, false);
        
        // 4. Space updates current mapping
        self.space.set_edge_attr_index(edge, attr.clone(), new_index);
        
        // 5. ChangeTracker records the delta
        self.change_tracker.record_attr_change(edge, attr, old_index, new_index, false);
        
        Ok(())
    }
    
    /// Set edge attributes in bulk (OPTIMIZED: True vectorized bulk operation)
    pub fn set_edge_attrs(&mut self, attrs_values: HashMap<AttrName, Vec<(EdgeId, AttrValue)>>) -> Result<(), GraphError> {
        // Batch validation - check all edges exist upfront
        for edge_values in attrs_values.values() {
            for &(edge_id, _) in edge_values {
                if !self.space.contains_edge(edge_id) {
                    return Err(GraphError::edge_not_found(edge_id, "set bulk edge attributes"));
                }
            }
        }
        
        // Use optimized vectorized pool operation
        let index_changes = self.pool.borrow_mut().set_bulk_attrs(attrs_values, false);
        
        // Update space attribute indices in bulk
        for (attr_name, entity_indices) in index_changes {
            for (edge_id, new_index) in entity_indices {
                self.space.set_edge_attr_index(edge_id, attr_name.clone(), new_index);
            }
        }
        
        // TODO: Bulk change tracking for attributes
        // For now, we skip individual change tracking for bulk operations
        // This could be optimized further with bulk change recording
        
        Ok(())
    }
    
    /// Get an attribute value from a node
    ///
    /// ALGORITHM:
    /// 1. Ask pool to get the current value
    /// 2. Return the value
    pub fn get_node_attr(&self, node: NodeId, attr: &AttrName) -> Result<Option<AttrValue>, GraphError> {
        if !self.space.contains_node(node) {
            return Err(GraphError::NodeNotFound {
                node_id: node,
                operation: "get attribute".to_string(),
                suggestion: "Check if node exists with contains_node()".to_string(),
            });
        }
        
        // Get the current index for this attribute from space
        if let Some(index) = self.space.get_attr_index(node, attr, true) {
            // Get the value from pool using the index
            Ok(self.pool.borrow().get_attr_by_index(attr, index, true).cloned())
        } else {
            Ok(None)  // Attribute not set for this node
        }
    }
    
    /// Get an attribute value from an edge
    ///
    /// ALGORITHM:
    /// 1. Ask pool to get the current value
    /// 2. Return the value
    pub fn get_edge_attr(&self, edge: EdgeId, attr: &AttrName) -> Result<Option<AttrValue>, GraphError> {
        if !self.space.contains_edge(edge) {
            return Err(GraphError::EdgeNotFound {
                edge_id: edge,
                operation: "get attribute".to_string(),
                suggestion: "Check if edge exists with contains_edge()".to_string(),
            });
        }
        
        // Get the current index for this attribute from space
        if let Some(index) = self.space.get_attr_index(edge, attr, false) {
            // Get the value from pool using the index
            Ok(self.pool.borrow().get_attr_by_index(attr, index, false).cloned())
        } else {
            Ok(None)  // Attribute not set for this edge
        }
    }
    
    /// Get all attributes for a node efficiently
    /// 
    /// ALGORITHM:
    /// 1. Get all attribute indices from space for this node
    /// 2. Use indices to retrieve actual values from pool
    /// 3. Return the attributes
    pub fn get_node_attrs(&self, node: NodeId) -> Result<HashMap<AttrName, AttrValue>, GraphError> {
        if !self.space.contains_node(node) {
            return Err(GraphError::NodeNotFound {
                node_id: node,
                operation: "get attributes".to_string(),
                suggestion: "Check if node exists with contains_node()".to_string(),
            });
        }
        
        let mut attributes = HashMap::new();
        let attr_indices = self.space.get_node_attr_indices(node);
        
        for (attr_name, index) in attr_indices {
            if let Some(value) = self.pool.borrow().get_attr_by_index(&attr_name, index, true) {
                attributes.insert(attr_name, value.clone());
            }
        }
        
        Ok(attributes)
    }
    
    /// Get all attributes for an edge efficiently
    ///
    /// ALGORITHM:
    /// 1. Get all attribute indices from space for this edge
    /// 2. Use indices to retrieve actual values from pool
    /// 3. Return the attributes
    pub fn get_edge_attrs(&self, edge: EdgeId) -> Result<HashMap<AttrName, AttrValue>, GraphError> {
        if !self.space.contains_edge(edge) {
            return Err(GraphError::EdgeNotFound {
                edge_id: edge,
                operation: "get attributes".to_string(),
                suggestion: "Check if edge exists with contains_edge()".to_string(),
            });
        }
        
        let mut attributes = HashMap::new();
        let attr_indices = self.space.get_edge_attr_indices(edge);
        
        for (attr_name, index) in attr_indices {
            if let Some(value) = self.pool.borrow().get_attr_by_index(&attr_name, index, false) {
                attributes.insert(attr_name, value.clone());
            }
        }
        
        Ok(attributes)
    }
    
    /*
    === EFFICIENT BULK OPERATIONS ===
    Graph provides secure external API while using efficient internal operations.
    
    ARCHITECTURE:
    - Pool: Provides full column access internally for efficiency
    - Graph: Filters by active entities and provides secure external API
    - Users: Only see data for entities they specify and that are active
    
    SECURITY: External API requires explicit indices and only returns active entity data
    PERFORMANCE: Internal implementation uses efficient full column access
    
    USAGE EXAMPLES:
    ```rust
    // Get attributes for specific active nodes
    let user_ids = vec![alice, bob, charlie];
    let ages = graph.get_nodes_attrs("age", &user_ids)?;

    ```
    */
    
    /// Get attribute values for specific nodes (secure and efficient)
    /// 
    /// ALGORITHM:
    /// 1. Get full attribute column from pool (O(1) HashMap lookup)
    /// 2. For each requested node: get its attribute index and extract value
    /// 3. Return results aligned with requested nodes
    /// 
    /// SECURITY: Only returns data for active nodes that were explicitly requested
    /// PERFORMANCE: Uses bulk columnar access - much faster than individual get_node_attr calls
    pub fn get_nodes_attrs(&self, attr: &AttrName, requested_nodes: &[NodeId]) -> GraphResult<Vec<Option<AttrValue>>> {
        let mut results = Vec::with_capacity(requested_nodes.len());
        
        // Get the attribute column once (O(1) HashMap lookup)
        if let Some(attr_column) = self.pool.borrow().get_node_attribute_column(attr) {
            // Bulk process all nodes using direct column access
            for &node_id in requested_nodes {
                if !self.space.contains_node(node_id) {
                    results.push(None); // Node doesn't exist
                } else if let Some(index) = self.space.get_node_attr_index(node_id, attr) {
                    // Direct O(1) access to column value
                    results.push(attr_column.get(index).cloned());
                } else {
                    results.push(None); // Attribute not set for this node
                }
            }
        } else {
            // Attribute doesn't exist in the graph
            results.resize(requested_nodes.len(), None);
        }
        
        Ok(results)
    }
    
    /// Get attribute values for specific edges (secure and efficient)
    pub fn get_edges_attrs(&self, attr: &AttrName, requested_edges: &[EdgeId]) -> GraphResult<Vec<Option<AttrValue>>> {
        let mut results = Vec::with_capacity(requested_edges.len());
        
        // Get the attribute column once (O(1) HashMap lookup)
        if let Some(attr_column) = self.pool.borrow().get_edge_attribute_column(attr) {
            // Bulk process all edges using direct column access
            for &edge_id in requested_edges {
                if !self.space.contains_edge(edge_id) {
                    results.push(None); // Edge doesn't exist
                } else if let Some(index) = self.space.get_edge_attr_index(edge_id, attr) {
                    // Direct O(1) access to column value
                    results.push(attr_column.get(index).cloned());
                } else {
                    results.push(None); // Attribute not set for this edge
                }
            }
        } else {
            // Attribute doesn't exist in the graph
            results.resize(requested_edges.len(), None);
        }
        
        Ok(results)
    }
    
    /// INTERNAL: Get attribute column for ALL active nodes (optimized for GraphTable)
    /// 
    /// This is the key optimization for GraphTable - instead of O(n*m) individual calls,
    /// we make O(m) bulk calls to get complete attribute columns.
    /// 
    /// PERFORMANCE: Single column access + filtering by active nodes only
    /// USAGE: Internal use by table(), DataFrame creation, bulk data export
    pub fn _get_node_attribute_column(&self, attr: &AttrName) -> GraphResult<Vec<Option<AttrValue>>> {
        let node_ids = self.space.node_ids(); // Get all active node IDs
        let mut results = Vec::with_capacity(node_ids.len());
        
        // Get the attribute column once (O(1) HashMap lookup)
        if let Some(attr_column) = self.pool.borrow().get_node_attribute_column(attr) {
            // Process all active nodes using direct column access
            for node_id in node_ids {
                if let Some(index) = self.space.get_node_attr_index(node_id, attr) {
                    results.push(attr_column.get(index).cloned());
                } else {
                    results.push(None); // Attribute not set for this node
                }
            }
        } else {
            // Attribute doesn't exist in the graph
            results.resize(node_ids.len(), None);
        }
        
        Ok(results)
    }
    
    /// INTERNAL: Get attribute column for ALL active edges (optimized for GraphTable)
    pub fn _get_edge_attribute_column(&self, attr: &AttrName) -> GraphResult<Vec<Option<AttrValue>>> {
        let edge_ids = self.space.edge_ids(); // Get all active edge IDs
        let mut results = Vec::with_capacity(edge_ids.len());
        
        // Get the attribute column once (O(1) HashMap lookup)
        if let Some(attr_column) = self.pool.borrow().get_edge_attribute_column(attr) {
            // Process all active edges using direct column access
            for edge_id in edge_ids {
                if let Some(index) = self.space.get_edge_attr_index(edge_id, attr) {
                    results.push(attr_column.get(index).cloned());
                } else {
                    results.push(None); // Attribute not set for this edge
                }
            }
        } else {
            // Attribute doesn't exist in the graph
            results.resize(edge_ids.len(), None);
        }
        
        Ok(results)
    }
    
    /// Get attribute column for specific nodes (optimized for subgraph tables)
    /// 
    /// INTERNAL: This enables subgraph.table() to be as efficient as graph.table()
    /// by using bulk column access instead of individual attribute calls.
    pub fn _get_node_attributes_for_nodes(&self, node_ids: &[NodeId], attr: &AttrName) -> GraphResult<Vec<Option<AttrValue>>> {
        // This is the same as get_nodes_attrs but with a more descriptive name
        // for use in subgraph table creation
        self.get_nodes_attrs(attr, node_ids)
    }
    
    /// INTERNAL: Get attribute column for specific edges (optimized for subgraph edge tables)
    pub fn _get_edge_attributes_for_edges(&self, edge_ids: &[EdgeId], attr: &AttrName) -> GraphResult<Vec<Option<AttrValue>>> {
        // This is the same as get_edges_attrs but with a more descriptive name
        // for use in subgraph edge table creation
        self.get_edges_attrs(attr, edge_ids)
    }

    // NOTE: Removed set_node_attr_bulk - use set_node_attrs for all bulk operations
    
    // NOTE: Removed set_edge_attr_bulk - use set_edge_attrs for all bulk operations
    
    /*
    === TOPOLOGY QUERIES ===
    Read-only operations about graph structure.
    These delegate to space for the active graph topology.
    */
    
    /// Check if a node exists in the graph
    pub fn contains_node(&self, node: NodeId) -> bool {
        self.space.contains_node(node)
    }
    
    /// Check if an edge exists in the graph
    pub fn contains_edge(&self, edge: EdgeId) -> bool {
        self.space.contains_edge(edge)
    }
    
    /// Get all node IDs currently in the graph
    pub fn node_ids(&self) -> Vec<NodeId> {
        self.space.get_active_nodes().iter().copied().collect()
    }
    
    /// Get all edge IDs currently in the graph
    pub fn edge_ids(&self) -> Vec<EdgeId> {
        self.space.get_active_edges().iter().copied().collect()
    }
    
    /// Get the degree of a node (number of incident edges)
    pub fn degree(&self, node: NodeId) -> Result<usize, GraphError> {
        if !self.space.contains_node(node) {
            return Err(GraphError::NodeNotFound {
                node_id: node,
                operation: "get degree".to_string(),
                suggestion: "Check if node exists with contains_node()".to_string(),
            });
        }
        
        // Get fresh topology snapshot
        let (_, sources, targets, _) = self.space.snapshot(&*self.pool.borrow());
        let mut count = 0;
        for i in 0..sources.len() {
            if sources[i] == node || targets[i] == node {
                count += 1;
            }
        }
        Ok(count)
    }
    
    /// Get the neighbors of a node
    pub fn neighbors(&self, node: NodeId) -> Result<Vec<NodeId>, GraphError> {
        if !self.space.contains_node(node) {
            return Err(GraphError::NodeNotFound {
                node_id: node,
                operation: "get neighbors".to_string(),
                suggestion: "Check if node exists with contains_node()".to_string(),
            });
        }
        
        // Get fresh adjacency snapshot - much more efficient than columnar scan
        let (_, _, _, neighbors_map) = self.space.snapshot(&*self.pool.borrow());
        
        if let Some(neighbors) = neighbors_map.get(&node) {
            // Extract just the neighbor nodes (not the edge IDs)
            let neighbor_nodes: Vec<NodeId> = neighbors.iter().map(|(neighbor, _)| *neighbor).collect();
            Ok(neighbor_nodes)
        } else {
            // Node exists but has no neighbors
            Ok(Vec::new())
        }
    }
    
    /// Get columnar topology vectors for efficient subgraph operations
    /// 
    /// Returns (edge_ids, sources, targets) as parallel vectors where:
    /// - edge_ids[i] is the EdgeId 
    /// - sources[i] is the source NodeId of that edge
    /// - targets[i] is the target NodeId of that edge
    ///
    /// This is used internally for optimized operations like subgraph edge calculation.
    pub fn get_columnar_topology(&self) -> (Arc<Vec<EdgeId>>, Arc<Vec<NodeId>>, Arc<Vec<NodeId>>) {
        let (edge_ids, sources, targets, _) = self.space.snapshot(&*self.pool.borrow());
        (edge_ids, sources, targets)
    }
    
    /// Get the endpoints of an edge
    pub fn edge_endpoints(&self, edge: EdgeId) -> Result<(NodeId, NodeId), GraphError> {
        self.pool.borrow().get_edge_endpoints(edge)
            .ok_or_else(|| GraphError::EdgeNotFound {
                edge_id: edge,
                operation: "get endpoints".to_string(),
                suggestion: "Check if edge exists with contains_edge()".to_string(),
            })
    }
    
    
    
    /// Get basic statistics about the current graph
    pub fn statistics(&self) -> GraphStatistics {
        let _pool_stats = self.pool.borrow().statistics();
        let _history_stats = self.history.statistics();
        
        // Accurate memory calculation using new memory monitoring
        // let memory_stats = self.memory_statistics();
        
        // Simple memory calculation to avoid stack overflow
        let pool_stats = self.pool.borrow().statistics();
        let history_stats = self.history.statistics();
        
        // Basic memory estimate
        let base_memory = 1024 * 1024; // 1MB base
        let entity_memory = (pool_stats.node_count + pool_stats.edge_count) * 100; // rough estimate
        let total_memory_mb = (base_memory + entity_memory) as f64 / (1024.0 * 1024.0);
        
        GraphStatistics {
            node_count: self.space.node_count(),
            edge_count: self.space.edge_count(),
            attribute_count: pool_stats.node_attribute_count + pool_stats.edge_attribute_count,
            commit_count: history_stats.total_commits,
            branch_count: history_stats.total_branches,
            uncommitted_changes: self.has_uncommitted_changes(),
            memory_usage_mb: total_memory_mb,
        }
    }
    
    /// Get comprehensive memory statistics (Memory Optimization 4)
    pub fn memory_statistics(&self) -> MemoryStatistics {
        // Calculate component memory usage
        let pool_memory = self.calculate_pool_memory();
        let space_memory = self.calculate_space_memory();
        let history_memory = self.calculate_history_memory();
        let change_tracker_memory = self.change_tracker.memory_usage();
        
        let total_bytes = pool_memory + space_memory + history_memory + change_tracker_memory;
        
        MemoryStatistics {
            pool_memory_bytes: pool_memory,
            space_memory_bytes: space_memory,
            history_memory_bytes: history_memory,
            change_tracker_memory_bytes: change_tracker_memory,
            total_memory_bytes: total_bytes,
            total_memory_mb: total_bytes as f64 / (1024.0 * 1024.0),
            memory_efficiency: self.calculate_memory_efficiency(total_bytes),
            compression_stats: self.calculate_compression_stats(),
        }
    }
    
    /// Calculate pool memory usage with detailed breakdown
    fn calculate_pool_memory(&self) -> usize {
        // Basic structure overhead
        let base_size = std::mem::size_of::<crate::core::pool::GraphPool>();
        
        // Node and edge storage
        let topology_size = std::mem::size_of::<std::collections::HashMap<crate::types::EdgeId, (crate::types::NodeId, crate::types::NodeId)>>();
        
        // Attribute storage (this is where the main memory is)
        let node_attrs_size = self.estimate_attribute_memory(true);
        let edge_attrs_size = self.estimate_attribute_memory(false);
        
        base_size + topology_size + node_attrs_size + edge_attrs_size
    }
    
    /// Estimate attribute memory usage (with access to pool internals)
    fn estimate_attribute_memory(&self, is_node: bool) -> usize {
        // This is a simplified estimate - in a real implementation,
        // we'd need access to pool internals or expose memory_usage() methods
        let attr_count = if is_node { 
            self.pool.borrow().statistics().node_attribute_count 
        } else { 
            self.pool.borrow().statistics().edge_attribute_count 
        };
        
        // Rough estimate: assume average of 100 bytes per attribute value
        attr_count * 100
    }
    
    /// Calculate space memory usage
    fn calculate_space_memory(&self) -> usize {
        let base_size = std::mem::size_of::<crate::core::space::GraphSpace>();
        
        // Active sets
        let active_nodes_size = self.space.node_count() * std::mem::size_of::<crate::types::NodeId>();
        let active_edges_size = self.space.edge_count() * std::mem::size_of::<crate::types::EdgeId>();
        
        // Topology cache
        let topology_cache_size = self.space.edge_count() * 3 * std::mem::size_of::<usize>(); // edge_ids, sources, targets
        
        // Attribute index maps (simplified estimate)
        let index_maps_size = (self.space.node_count() + self.space.edge_count()) * 50; // rough estimate
        
        base_size + active_nodes_size + active_edges_size + topology_cache_size + index_maps_size
    }
    
    /// Calculate history memory usage
    fn calculate_history_memory(&self) -> usize {
        // Simplified estimate - in real implementation, would query history component
        let base_size = std::mem::size_of::<crate::core::history::HistoryForest>();
        let commits = self.statistics().commit_count;
        let estimated_commit_size = 1000; // bytes per commit (rough estimate)
        
        base_size + commits * estimated_commit_size
    }
    
      /// Calculate memory efficiency metrics
      fn calculate_memory_efficiency(&self, total_memory_bytes: usize) -> MemoryEfficiency {
          let total_entities = self.space.node_count() + self.space.edge_count();
          
          let bytes_per_entity = if total_entities > 0 {
              total_memory_bytes as f64 / total_entities as f64
          } else {
              0.0
          };
          
          // Memory overhead ratio (structure overhead vs actual data)
          let estimated_data_size = total_entities * 32; // rough estimate of minimal entity data
          let overhead_ratio = if estimated_data_size > 0 {
              (total_memory_bytes as f64 - estimated_data_size as f64) / estimated_data_size as f64
          } else {
              0.0
          };
          
          MemoryEfficiency {
              bytes_per_node: if self.space.node_count() > 0 {
                  total_memory_bytes as f64 / self.space.node_count() as f64
              } else {
                  0.0
              },
              bytes_per_edge: if self.space.edge_count() > 0 {
                  total_memory_bytes as f64 / self.space.edge_count() as f64
              } else {
                  0.0
              },
              bytes_per_entity,
              overhead_ratio,
              cache_efficiency: 0.95, // Placeholder - would be calculated from actual cache hit rates
          }
      }    /// Calculate compression statistics
    fn calculate_compression_stats(&self) -> CompressionStatistics {
        // This would require querying the pool for compression ratios
        // For now, provide placeholder statistics
        let pool_stats = self.pool.borrow().statistics();
        let total_attributes = pool_stats.node_attribute_count + pool_stats.edge_attribute_count;
        
        CompressionStatistics {
            compressed_attributes: 0,
            total_attributes,
            average_compression_ratio: 1.0,
            memory_saved_bytes: 0,
            memory_saved_percentage: 0.0,
        }
    }
    
    /*
    === VERSION CONTROL OPERATIONS ===
    Git-like functionality for managing graph evolution.
    These coordinate between history system and current state.
    */
    
    
    /// Commit current changes to history
    /// 
    /// ALGORITHM:
    /// 1. Create a snapshot of current changes (ask space)
    /// 2. pool the snapshot in history system with metadata
    /// 3. Update current commit pointer
    /// 4. Clear change tracker
    /// 5. Return new commit ID
    pub fn commit(&mut self, message: String, author: String) -> Result<StateId, GraphError> {
        // Create changeset from current changes
        let changeset = self.change_tracker.create_changeset();
        
        // Check if there are any changes to commit
        if changeset.is_empty() {
            return Err(GraphError::NoChangesToCommit);
        }
        
        // Determine parent commit (current commit, unless it's 0 which is the empty state)
        let parent = if self.current_commit == 0 { None } else { Some(self.current_commit) };
        
        // Create commit in history
        let new_commit_id = self.history.create_commit(changeset, message, author, parent)?;
        
        // Update current commit and branch head
        self.current_commit = new_commit_id;
        self.history.update_branch_head(&self.current_branch, new_commit_id)?;
        
        // Clear the change tracker since changes are now committed
        self.change_tracker.clear();
        
        Ok(new_commit_id)
    }
    
    /// Check if there are uncommitted changes
    pub fn has_uncommitted_changes(&self) -> bool {
        !self.change_tracker.create_changeset().is_empty()
    }
    
    /// Reset all uncommitted changes
    pub fn reset_hard(&mut self) -> Result<(), GraphError> {
        // Clear the change tracker (this loses all uncommitted changes)
        self.change_tracker.clear();
        
        // TODO: When HistoryForest is implemented:
        // - Reset space to match current_commit state
        // - Reload pool from historical state
        
        Ok(())
    }
    
    /// Create a new branch from current state
    pub fn create_branch(&mut self, branch_name: BranchName) -> Result<(), GraphError> {
        self.history.create_branch(branch_name, self.current_commit)?;
        Ok(())
    }
    
    /// Switch to a different branch
    pub fn checkout_branch(&mut self, branch_name: BranchName) -> Result<(), GraphError> {
        // 1. Validate the branch exists
        let target_head = self.history.get_branch_head(&branch_name)?;
        
        // 2. Check for uncommitted changes
        if self.has_uncommitted_changes() {
            return Err(GraphError::InvalidInput(
                "Cannot switch branches with uncommitted changes. Please commit or reset first.".to_string()
            ));
        }
        
        // 3. Reconstruct the graph state at the target branch's head
        if target_head != self.current_commit {
            let target_snapshot = self.history.reconstruct_state_at(target_head)?;
            
            // 4. Reset the current graph state to match the target snapshot
            self.reset_to_snapshot(target_snapshot)?;
        }
        
        // 5. Update current branch and commit pointers
        self.current_branch = branch_name;
        self.current_commit = target_head;
        
        // 6. Clear any change tracking since we're at a clean state
        self.change_tracker.clear();
        
        Ok(())
    }
    
    /// List all branches
    pub fn list_branches(&self) -> Vec<BranchInfo> {
        let mut branches = self.history.list_branches();
        // Mark the current branch
        for branch in &mut branches {
            if branch.name == self.current_branch {
                branch.is_current = true;
                break;
            }
        }
        branches
    }
    
    /// Get the commit history
    pub fn commit_history(&self) -> Vec<CommitInfo> {
        // Basic implementation returns empty - full implementation would query history system
        Vec::new()
    }
    
    /*
    === QUERY AND ANALYSIS OPERATIONS ===  
    Complex read-only operations that might benefit from specialized processing.
    These delegate to query_engine which can optimize across multiple access patterns.
    */
    
    /// Find nodes matching attribute criteria
    pub fn find_nodes(&mut self, filter: NodeFilter) -> Result<Vec<NodeId>, GraphError> {
        self.query_engine.find_nodes_by_filter_with_space(&*self.pool.borrow(), &self.space, &filter)
            .map_err(|e| e.into())
    }
    
    /// Find edges matching attribute criteria
    pub fn find_edges(&mut self, filter: EdgeFilter) -> Result<Vec<EdgeId>, GraphError> {
        self.query_engine.find_edges_by_filter_with_space(&*self.pool.borrow(), &self.space, &filter)
            .map_err(|e| e.into())
    }
    
    /*
    === GRAPH TRAVERSAL OPERATIONS ===
    Advanced graph algorithms for traversal, pathfinding, and connectivity analysis.
    These delegate to the traversal_engine for optimized traversal algorithms.
    */
    
    /// Perform Breadth-First Search from a starting node
    pub fn bfs(&mut self, start: NodeId, options: crate::core::traversal::TraversalOptions) -> Result<crate::core::traversal::TraversalResult, GraphError> {
        self.traversal_engine.bfs(&*self.pool.borrow(), &mut self.space, start, options)
            .map_err(|e| e.into())
    }
    
    /// Perform Depth-First Search from a starting node
    pub fn dfs(&mut self, start: NodeId, options: crate::core::traversal::TraversalOptions) -> Result<crate::core::traversal::TraversalResult, GraphError> {
        self.traversal_engine.dfs(&*self.pool.borrow(), &mut self.space, start, options)
            .map_err(|e| e.into())
    }
    
    /// Find shortest path between two nodes
    pub fn shortest_path(&mut self, start: NodeId, end: NodeId, options: crate::core::traversal::PathFindingOptions) -> Result<Option<crate::core::traversal::Path>, GraphError> {
        self.traversal_engine.shortest_path(&*self.pool.borrow(), &mut self.space, start, end, options)
            .map_err(|e| e.into())
    }
    
    /// Find all simple paths between two nodes
    pub fn all_paths(&mut self, start: NodeId, end: NodeId, max_length: usize) -> Result<Vec<crate::core::traversal::Path>, GraphError> {
        self.traversal_engine.all_paths(&*self.pool.borrow(), &mut self.space, start, end, max_length)
            .map_err(|e| e.into())
    }
    
    /// Find all connected components in the graph
    pub fn connected_components(&mut self, options: crate::core::traversal::TraversalOptions) -> Result<crate::core::traversal::ConnectedComponentsResult, GraphError> {
        self.traversal_engine.connected_components(&*self.pool.borrow(), &mut self.space, options)
            .map_err(|e| e.into())
    }
    
    /// Get traversal performance statistics
    pub fn traversal_statistics(&self) -> &crate::core::traversal::TraversalStats {
        self.traversal_engine.statistics()
    }
    
    // TODO: Implement complex query composition when needed
    
    /// Create a new complex query builder
    pub fn query(&self) -> Result<(), GraphError> {
        Err(GraphError::NotImplemented {
            feature: "complex query builder".to_string(),
            tracking_issue: None,
        })
    }
    
    /// Create a read-only view of the graph for analysis
    /// TODO: Implement when GraphView is designed
    // pub fn create_view(&self) -> GraphView {
    //     // TODO: GraphView::new(&self.pool, &self.query_engine)
    // }
    
    /*
    === TIME TRAVEL OPERATIONS ===
    Working with historical states of the graph.
    These create special views that delegate to history system.
    */
    
    /// Create a read-only view of the graph at a specific commit
    pub fn view_at_commit(&self, commit_id: StateId) -> Result<HistoricalView, GraphError> {
        let _ = commit_id; // Silence unused parameter warning
        Err(GraphError::NotImplemented {
            feature: "historical views".to_string(),
            tracking_issue: None,
        })
    }
    
    /// Compare two commits and show differences
    pub fn diff_commits(&self, from: StateId, to: StateId) -> Result<CommitDiff, GraphError> {
        let _ = (from, to); // Silence unused parameter warning
        Err(GraphError::NotImplemented {
            feature: "commit diffs".to_string(),
            tracking_issue: None,
        })
    }
    
    /*
    === INTERNAL STATE MANAGEMENT ===
    Helper methods for branch switching and state reconstruction
    */
    
    /// Reset the current graph state (pool + space) to match a historical snapshot
    /// This is used during branch switching to restore the graph to a specific state
    fn reset_to_snapshot(&mut self, snapshot: crate::core::state::GraphSnapshot) -> Result<(), GraphError> {
        // 1. Clear current state
        self.pool = Rc::new(RefCell::new(crate::core::pool::GraphPool::new()));
        self.space = crate::core::space::GraphSpace::new(self.pool.clone(), snapshot.state_id);
        
        // 2. Restore nodes
        for &node_id in &snapshot.active_nodes {
            // Ensure node ID exists in pool
            self.pool.borrow_mut().ensure_node_id_exists(node_id);
            // Activate in space
            self.space.activate_node(node_id);
            
            // Restore node attributes
            if let Some(attrs) = snapshot.node_attributes.get(&node_id) {
                for (attr_name, attr_value) in attrs {
                    let index = self.pool.borrow_mut().set_attr(attr_name.clone(), attr_value.clone(), true);
                    self.space.set_node_attr_index(node_id, attr_name.clone(), index);
                }
            }
        }
        
        // 3. Restore edges
        for (&edge_id, &(source, target)) in &snapshot.edges {
            // Store topology in pool with specific ID
            self.pool.borrow_mut().add_edge_with_id(edge_id, source, target);
            // Activate in space
            self.space.activate_edge(edge_id, source, target);
            
            // Restore edge attributes
            if let Some(attrs) = snapshot.edge_attributes.get(&edge_id) {
                for (attr_name, attr_value) in attrs {
                    let index = self.pool.borrow_mut().set_attr(attr_name.clone(), attr_value.clone(), false);
                    self.space.set_edge_attr_index(edge_id, attr_name.clone(), index);
                }
            }
        }
        
        Ok(())
    }
    
    /*
    === MAINTENANCE OPERATIONS ===
    Housekeeping, optimization, and system management.
    */
    
    /// Optimize internal data structures for better performance
    pub fn optimize(&mut self) -> Result<(), GraphError> {
        // Basic implementation is a no-op
        // Full implementation would optimize pool, history, and query structures
        Ok(())
    }
    
    /// Garbage collect unreferenced historical states
    pub fn gc_history(&mut self) -> Result<usize, GraphError> {
        // Basic implementation performs no garbage collection
        // Full implementation would garbage collect unreachable commits
        Ok(0)
    }
    
    /// Save graph to persistent storage
    pub fn save_to_path(&self, path: &Path) -> Result<(), GraphError> {
        let _ = path; // Silence unused parameter warning
        Err(GraphError::NotImplemented {
            feature: "save_to_path".to_string(),
            tracking_issue: None,
        })
    }
    
    /*
    === AGGREGATION AND ANALYTICS ===
    Statistical operations and data analysis functionality.
    */
    
    /// Compute aggregate statistics for a node attribute
    pub fn aggregate_node_attribute(&self, attr_name: &AttrName, operation: &str) -> Result<AggregationResult, GraphError> {
        // Get all active nodes
        let node_ids: Vec<NodeId> = self.space.get_active_nodes().iter().copied().collect();
        
        // Use bulk attribute retrieval for much better performance (10-100x faster than individual lookups)
        let bulk_attributes = self._get_node_attributes_for_nodes(&node_ids, attr_name)?;
        let mut values = Vec::new();
        
        // Extract values from bulk result
        for attr_value in bulk_attributes {
            if let Some(value) = attr_value {
                values.push(value);
            }
        }
        
        if values.is_empty() {
            return Ok(AggregationResult::new(0.0));
        }
        
        // Perform the requested aggregation
        let result = match operation {
            "count" => values.len() as f64,
            "average" | "mean" => {
                let sum = values.iter().fold(0.0, |acc, val| acc + extract_numeric(val));
                sum / values.len() as f64
            },
            "sum" => values.iter().fold(0.0, |acc, val| acc + extract_numeric(val)),
            "min" => values.iter().fold(f64::INFINITY, |acc, val| acc.min(extract_numeric(val))),
            "max" => values.iter().fold(f64::NEG_INFINITY, |acc, val| acc.max(extract_numeric(val))),
            "stddev" => {
                let mean = values.iter().fold(0.0, |acc, val| acc + extract_numeric(val)) / values.len() as f64;
                let variance = values.iter().fold(0.0, |acc, val| {
                    let diff = extract_numeric(val) - mean;
                    acc + diff * diff
                }) / values.len() as f64;
                variance.sqrt()
            },
            "median" => {
                let mut numeric_values: Vec<f64> = values.iter().map(extract_numeric).collect();
                numeric_values.sort_by(|a, b| a.partial_cmp(b).unwrap());
                let mid = numeric_values.len() / 2;
                if numeric_values.len() % 2 == 0 {
                    (numeric_values[mid - 1] + numeric_values[mid]) / 2.0
                } else {
                    numeric_values[mid]
                }
            },
            "percentile_95" => {
                let mut numeric_values: Vec<f64> = values.iter().map(extract_numeric).collect();
                numeric_values.sort_by(|a, b| a.partial_cmp(b).unwrap());
                let index = ((numeric_values.len() as f64 - 1.0) * 0.95).round() as usize;
                numeric_values[index.min(numeric_values.len() - 1)]
            },
            "unique_count" => {
                let mut unique_values = std::collections::HashSet::new();
                for value in values {
                    unique_values.insert(value);
                }
                unique_values.len() as f64
            },
            _ => return Err(GraphError::InvalidInput(format!("Unsupported aggregation operation: {}", operation)))
        };
        
        Ok(AggregationResult::new(result))
    }
    
    /// Compute aggregate statistics for an edge attribute  
    pub fn aggregate_edge_attribute(&self, attr_name: &AttrName, operation: &str) -> Result<AggregationResult, GraphError> {
        // Get all active edges
        let edge_ids: Vec<EdgeId> = self.space.get_active_edges().iter().copied().collect();
        
        // Use bulk attribute retrieval for much better performance (10-100x faster than individual lookups)
        let bulk_attributes = self._get_edge_attributes_for_edges(&edge_ids, attr_name)?;
        let mut values = Vec::new();
        
        // Extract values from bulk result
        for attr_value in bulk_attributes {
            if let Some(value) = attr_value {
                values.push(value);
            }
        }
        
        if values.is_empty() {
            return Ok(AggregationResult::new(0.0));
        }
        
        // Perform the requested aggregation (same logic as node aggregation)
        let result = match operation {
            "count" => values.len() as f64,
            "average" | "mean" => {
                let sum = values.iter().fold(0.0, |acc, val| acc + extract_numeric(val));
                sum / values.len() as f64
            },
            "sum" => values.iter().fold(0.0, |acc, val| acc + extract_numeric(val)),
            "min" => values.iter().fold(f64::INFINITY, |acc, val| acc.min(extract_numeric(val))),
            "max" => values.iter().fold(f64::NEG_INFINITY, |acc, val| acc.max(extract_numeric(val))),
            "stddev" => {
                let mean = values.iter().fold(0.0, |acc, val| acc + extract_numeric(val)) / values.len() as f64;
                let variance = values.iter().fold(0.0, |acc, val| {
                    let diff = extract_numeric(val) - mean;
                    acc + diff * diff
                }) / values.len() as f64;
                variance.sqrt()
            },
            _ => return Err(GraphError::InvalidInput(format!("Unsupported aggregation operation: {}", operation)))
        };
        
        Ok(AggregationResult::new(result))
    }
    
    /// Group nodes by attribute value and compute aggregates for each group
    /// OPTIMIZED: O(N) algorithm using bulk attribute retrieval instead of O(N²) individual lookups
    pub fn group_nodes_by_attribute(&self, group_by_attr: &AttrName, aggregate_attr: &AttrName, operation: &str) -> Result<std::collections::HashMap<AttrValue, AggregationResult>, GraphError> {
        // Get all active nodes
        let node_ids: Vec<NodeId> = self.space.get_active_nodes().iter().copied().collect();
        
        if node_ids.is_empty() {
            return Ok(std::collections::HashMap::new());
        }
        
        // BULK OPERATION 1: Get group_by attribute for all nodes at once (O(N))
        let pool_ref = self.pool.borrow();
        let group_by_values = self.space.get_attributes_for_nodes(&*pool_ref, group_by_attr, &node_ids);
        
        // BULK OPERATION 2: Get aggregate attribute for all nodes at once (O(N))  
        let aggregate_values = self.space.get_attributes_for_nodes(&*pool_ref, aggregate_attr, &node_ids);
        
        // Create lookup maps for efficient access
        let group_by_map: std::collections::HashMap<NodeId, &AttrValue> = group_by_values
            .iter()
            .filter_map(|(node_id, opt_val)| opt_val.map(|val| (*node_id, val)))
            .collect();
            
        let aggregate_map: std::collections::HashMap<NodeId, &AttrValue> = aggregate_values
            .iter()
            .filter_map(|(node_id, opt_val)| opt_val.map(|val| (*node_id, val)))
            .collect();
        
        // Group nodes by attribute value and collect aggregate values (O(N))
        let mut groups: std::collections::HashMap<AttrValue, Vec<AttrValue>> = std::collections::HashMap::new();
        
        for &node_id in &node_ids {
            if let (Some(&group_val), Some(&agg_val)) = (group_by_map.get(&node_id), aggregate_map.get(&node_id)) {
                groups.entry(group_val.clone()).or_insert_with(Vec::new).push(agg_val.clone());
            }
        }
        
        // Compute aggregations for each group (O(N) total across all groups)
        let mut results = std::collections::HashMap::new();
        
        for (group_value, values) in groups {
            if !values.is_empty() {
                let result = match operation {
                    "count" => values.len() as f64,
                    "average" | "mean" => {
                        let sum = values.iter().fold(0.0, |acc, val| acc + extract_numeric(val));
                        sum / values.len() as f64
                    },
                    "sum" => values.iter().fold(0.0, |acc, val| acc + extract_numeric(val)),
                    "min" => values.iter().fold(f64::INFINITY, |acc, val| acc.min(extract_numeric(val))),
                    "max" => values.iter().fold(f64::NEG_INFINITY, |acc, val| acc.max(extract_numeric(val))),
                    _ => return Err(GraphError::InvalidInput(format!("Unsupported aggregation operation: {}", operation)))
                };
                
                results.insert(group_value, AggregationResult::new(result));
            }
        }
        
        Ok(results)
    }

    // ===== ADJACENCY MATRIX OPERATIONS =====

    /// Generate adjacency matrix for the entire graph
    pub fn adjacency_matrix(&mut self) -> GraphResult<AdjacencyMatrix> {
        AdjacencyMatrixBuilder::new().build_full_graph(&*self.pool.borrow(), &mut self.space)
    }

    /// Generate weighted adjacency matrix using specified edge attribute
    pub fn weighted_adjacency_matrix(&mut self, weight_attr: &str) -> GraphResult<AdjacencyMatrix> {
        AdjacencyMatrixBuilder::new()
            .matrix_type(MatrixType::Weighted { weight_attr: Some(weight_attr.to_string()) })
            .build_full_graph(&*self.pool.borrow(), &mut self.space)
    }

    /// Generate dense adjacency matrix
    pub fn dense_adjacency_matrix(&mut self) -> GraphResult<AdjacencyMatrix> {
        AdjacencyMatrixBuilder::new()
            .format(MatrixFormat::Dense)
            .build_full_graph(&*self.pool.borrow(), &mut self.space)
    }

    /// Generate sparse adjacency matrix
    pub fn sparse_adjacency_matrix(&mut self) -> GraphResult<AdjacencyMatrix> {
        AdjacencyMatrixBuilder::new()
            .format(MatrixFormat::Sparse)
            .build_full_graph(&*self.pool.borrow(), &mut self.space)
    }

    /// Generate Laplacian matrix
    pub fn laplacian_matrix(&mut self, normalized: bool) -> GraphResult<AdjacencyMatrix> {
        AdjacencyMatrixBuilder::new()
            .matrix_type(MatrixType::Laplacian { normalized })
            .build_full_graph(&*self.pool.borrow(), &mut self.space)
    }

    /// Generate adjacency matrix for a subgraph with specific nodes
    pub fn subgraph_adjacency_matrix(&mut self, node_ids: &[NodeId]) -> GraphResult<AdjacencyMatrix> {
        AdjacencyMatrixBuilder::new()
            .build_subgraph(&*self.pool.borrow(), &mut self.space, node_ids)
    }

    /// Generate custom adjacency matrix with full control
    pub fn custom_adjacency_matrix(
        &mut self,
        format: MatrixFormat,
        matrix_type: MatrixType,
        compact_indexing: bool,
        node_ids: Option<&[NodeId]>,
    ) -> GraphResult<AdjacencyMatrix> {
        let builder = AdjacencyMatrixBuilder::new()
            .format(format)
            .matrix_type(matrix_type)
            .compact_indexing(compact_indexing);

        if let Some(nodes) = node_ids {
            builder.build_subgraph(&*self.pool.borrow(), &mut self.space, nodes)
        } else {
            builder.build_full_graph(&*self.pool.borrow(), &mut self.space)
        }
    }
}

/*
=== SUPPORTING TYPES ===
These are the types that the Graph API uses for its operations.
*/

// NOTE: GraphConfig is defined in config.rs - removed duplicate definition

/// Statistics about the current graph state
#[derive(Debug, Clone)]
pub struct GraphStatistics {
    pub node_count: usize,
    pub edge_count: usize,
    pub attribute_count: usize,
    pub commit_count: usize,
    pub branch_count: usize,
    pub uncommitted_changes: bool,
    pub memory_usage_mb: f64,
}

/// Information about a commit
#[derive(Debug, Clone)]
pub struct CommitInfo {
    pub id: StateId,
    pub parent: Option<StateId>,
    pub message: String,
    pub author: String,
    pub timestamp: u64,
    pub changes_summary: String,
}

/// Result of an aggregation operation
#[derive(Debug, Clone)]
pub struct AggregationResult {
    pub value: f64,
}

impl AggregationResult {
    pub fn new(value: f64) -> Self {
        Self { value }
    }
}

/// Extract numeric value from AttrValue for aggregation
fn extract_numeric(attr_value: &AttrValue) -> f64 {
    match attr_value {
        AttrValue::Int(i) => *i as f64,
        AttrValue::Float(f) => *f as f64,
        AttrValue::SmallInt(i) => *i as f64,
        _ => 0.0, // Non-numeric values default to 0
    }
}

impl Default for Graph {
    fn default() -> Self {
        Self::new()
    }
}

/*
=== IMPLEMENTATION STRATEGY NOTES ===

COMPONENT COORDINATION:
- Graph should be smart about when to use which component
- Some operations might touch multiple components (e.g., commit touches pool + history + space)
- Graph should handle all the complex interactions

PERFORMANCE OPTIMIZATIONS:
- Batch operations when possible (add_nodes vs add_node)
- Direct access to columnar data for analytics workloads
- Change tracking should be lightweight (don't pool full snapshots on every change)

ERROR HANDLING:
- Use Result<T, GraphError> for all fallible operations
- Provide clear error messages with context
- Fail fast and maintain consistency

TRANSACTION BOUNDARIES:
- Individual operations are atomic (add_node can't partially fail)
- Multi-operation sequences should be wrapped in transactions
- Change tracker provides rollback capability

FUTURE EXTENSIBILITY:
- Plugin system for custom query processors
- Multiple storage backends (in-memory, disk-based, distributed)
- Custom attribute types beyond the basic AttrValue enum
*/

--- FILE: display/matrix_formatter.rs ---
/*!
Rich display formatter for GraphMatrix structures.
*/

use std::collections::HashMap;
use super::{DisplayConfig, unicode_chars::*};

/// Format a GraphMatrix for rich display
pub fn format_matrix(matrix_data: HashMap<String, serde_json::Value>, config: &DisplayConfig) -> String {
    let formatter = MatrixDisplayFormatter::new(config);
    formatter.format(matrix_data)
}

pub struct MatrixDisplayFormatter {
    max_rows: usize,
    max_cols: usize,
    use_color: bool,
}

impl MatrixDisplayFormatter {
    pub fn new(config: &DisplayConfig) -> Self {
        Self {
            max_rows: config.max_rows,
            max_cols: config.max_cols,
            use_color: config.use_color,
        }
    }
    
    pub fn format(&self, matrix_data: HashMap<String, serde_json::Value>) -> String {
        let shape = self.extract_shape(&matrix_data);
        let data = self.extract_data(&matrix_data);
        let dtype = self.extract_dtype(&matrix_data);
        let column_names = self.extract_column_names(&matrix_data);
        
        let mut lines = Vec::new();
        
        // Header
        lines.push(format!("{} gr.matrix", Symbols::HEADER_PREFIX));
        
        if data.is_empty() {
            lines.push("(empty matrix)".to_string());
            return lines.join("\n");
        }
        
        // Matrix data (simplified table format)
        let max_display_rows = self.max_rows.min(data.len());
        let max_display_cols = if !data.is_empty() {
            self.max_cols.min(data[0].len())
        } else {
            0
        };
        
        // Show truncated data
        for (_i, row) in data.iter().enumerate() {
            let row_values: Vec<String> = row.iter()
                .take(max_display_cols)
                .map(|v| self.format_matrix_value(v))
                .collect();
            
            let row_str = if row.len() > max_display_cols {
                format!("[{}{}{}]", 
                    row_values.join(", "), 
                    if !row_values.is_empty() { ", " } else { "" },
                    Symbols::TRUNCATION_INDICATOR)
            } else {
                format!("[{}]", row_values.join(", "))
            };
            
            lines.push(format!("  {}", row_str));
        }
        
        if data.len() > max_display_rows {
            lines.push(format!("  {}", Symbols::TRUNCATION_INDICATOR));
        }
        
        // Shape and type info
        let shape_info = if column_names.is_empty() {
            format!("shape: ({}, {}) • dtype: {}", shape.0, shape.1, dtype)
        } else {
            let cols_info = if column_names.len() > 3 {
                format!("cols: [{}{}{}]", 
                    column_names.iter().take(2).map(|s| format!("'{}'", s)).collect::<Vec<_>>().join(", "),
                    if column_names.len() > 2 { ", " } else { "" },
                    Symbols::TRUNCATION_INDICATOR)
            } else {
                format!("cols: [{}]", 
                    column_names.iter().map(|s| format!("'{}'", s)).collect::<Vec<_>>().join(", "))
            };
            format!("shape: ({}, {}) • {} • dtype: {}", shape.0, shape.1, cols_info, dtype)
        };
        
        lines.push(shape_info);
        
        lines.join("\n")
    }
    
    fn format_matrix_value(&self, value: &serde_json::Value) -> String {
        match value {
            serde_json::Value::Null => Symbols::NULL_DISPLAY.to_string(),
            serde_json::Value::Number(n) => {
                if let Some(f) = n.as_f64() {
                    if f.fract() == 0.0 && f.abs() < 1e10 {
                        format!("{}", f as i64)
                    } else {
                        format!("{:.2}", f)
                    }
                } else {
                    n.to_string()
                }
            }
            serde_json::Value::String(s) => {
                if s.len() > 8 {
                    format!("{}{}", &s[..7], Symbols::ELLIPSIS)
                } else {
                    s.clone()
                }
            }
            serde_json::Value::Bool(b) => b.to_string(),
            _ => value.to_string().trim_matches('"').to_string(),
        }
    }
    
    fn extract_shape(&self, data: &HashMap<String, serde_json::Value>) -> (usize, usize) {
        data.get("shape")
            .and_then(|v| v.as_array())
            .and_then(|arr| {
                if arr.len() >= 2 {
                    let rows = arr[0].as_u64().unwrap_or(0) as usize;
                    let cols = arr[1].as_u64().unwrap_or(0) as usize;
                    Some((rows, cols))
                } else {
                    None
                }
            })
            .unwrap_or((0, 0))
    }
    
    fn extract_data(&self, data: &HashMap<String, serde_json::Value>) -> Vec<Vec<serde_json::Value>> {
        data.get("data")
            .and_then(|v| v.as_array())
            .map(|arr| {
                arr.iter()
                    .filter_map(|row| row.as_array().cloned())
                    .collect()
            })
            .unwrap_or_default()
    }
    
    fn extract_dtype(&self, data: &HashMap<String, serde_json::Value>) -> String {
        data.get("dtype")
            .and_then(|v| v.as_str())
            .unwrap_or("mixed")
            .to_string()
    }
    
    fn extract_column_names(&self, data: &HashMap<String, serde_json::Value>) -> Vec<String> {
        data.get("column_names")
            .and_then(|v| v.as_array())
            .map(|arr| {
                arr.iter()
                    .filter_map(|v| v.as_str().map(String::from))
                    .collect()
            })
            .unwrap_or_default()
    }
}


--- FILE: display/mod.rs ---
/*!
Pure Rust display formatting for GraphArray, GraphMatrix, and GraphTable.

This module provides professional Unicode table formatting without Python dependencies,
replacing the previous Python-based display system for better performance and 
architectural consistency.
*/

pub mod table_formatter;
pub mod matrix_formatter;
pub mod array_formatter;
pub mod unicode_chars;
pub mod truncation;

use std::collections::HashMap;

/// Re-export main formatting functions
pub use table_formatter::format_table;
pub use matrix_formatter::format_matrix;
pub use array_formatter::format_array;

/// Trait for types that can be displayed with rich formatting
pub trait RichDisplay {
    fn rich_display(&self) -> String;
    fn to_display_data(&self) -> HashMap<String, serde_json::Value>;
}

/// Common display configuration
#[derive(Debug, Clone)]
pub struct DisplayConfig {
    pub max_rows: usize,
    pub max_cols: usize,
    pub max_width: usize,
    pub precision: usize,
    pub use_color: bool,
}

impl Default for DisplayConfig {
    fn default() -> Self {
        Self {
            max_rows: 10,
            max_cols: 8,
            max_width: 120,
            precision: 2,
            use_color: console::Term::stdout().features().colors_supported(),
        }
    }
}

/// Auto-detect data structure type from display data
pub fn detect_display_type(data: &HashMap<String, serde_json::Value>) -> &'static str {
    if data.contains_key("columns") && data.contains_key("dtypes") {
        "table"
    } else if data.contains_key("data") {
        if let Some(data_array) = data.get("data").and_then(|v| v.as_array()) {
            if let Some(first_item) = data_array.first() {
                if first_item.is_array() {
                    "matrix"
                } else {
                    "array"
                }
            } else {
                "array"
            }
        } else {
            "array"
        }
    } else {
        "table" // Default fallback
    }
}

/// Format any data structure automatically
pub fn format_data_structure(
    data: HashMap<String, serde_json::Value>,
    data_type: Option<&str>,
    config: &DisplayConfig,
) -> String {
    let detected_type = data_type.unwrap_or_else(|| detect_display_type(&data));
    
    match detected_type {
        "table" => format_table(data, config),
        "matrix" => format_matrix(data, config),
        "array" => format_array(data, config),
        _ => format!("Unknown data type: {}", detected_type),
    }
}


--- FILE: display/unicode_chars.rs ---
/*!
Unicode box-drawing characters and display symbols for professional formatting.
Direct Rust port of the Python unicode_chars.py module.
*/

/// Unicode box-drawing characters for professional table display
pub struct BoxChars;

impl BoxChars {
    // Corners
    pub const TOP_LEFT: &'static str = "╭";
    pub const TOP_RIGHT: &'static str = "╮";
    pub const BOTTOM_LEFT: &'static str = "╰";
    pub const BOTTOM_RIGHT: &'static str = "╯";
    
    // Lines
    pub const HORIZONTAL: &'static str = "─";
    pub const VERTICAL: &'static str = "│";
    
    // Intersections
    pub const CROSS: &'static str = "┼";
    pub const T_TOP: &'static str = "┬";
    pub const T_BOTTOM: &'static str = "┴";
    pub const T_LEFT: &'static str = "├";
    pub const T_RIGHT: &'static str = "┤";
    
    // Double lines for emphasis
    pub const HORIZONTAL_DOUBLE: &'static str = "═";
    pub const VERTICAL_DOUBLE: &'static str = "║";
}

/// Special symbols for data display
pub struct Symbols;

impl Symbols {
    pub const ELLIPSIS: &'static str = "…";           // For truncated content
    pub const DOT_SEPARATOR: &'static str = "•";      // For summary statistics  
    pub const NULL_DISPLAY: &'static str = "NaN";     // For null/missing values
    pub const TRUNCATION_INDICATOR: &'static str = "⋯"; // For matrix truncation
    pub const HEADER_PREFIX: &'static str = "⊖⊖";     // For section headers
}

/// ANSI color codes for enhanced display
pub struct Colors;

impl Colors {
    pub const RESET: &'static str = "\x1b[0m";
    pub const BOLD: &'static str = "\x1b[1m";
    pub const DIM: &'static str = "\x1b[2m";
    
    // Text colors
    pub const RED: &'static str = "\x1b[31m";
    pub const GREEN: &'static str = "\x1b[32m";
    pub const YELLOW: &'static str = "\x1b[33m";
    pub const BLUE: &'static str = "\x1b[34m";
    pub const MAGENTA: &'static str = "\x1b[35m";
    pub const CYAN: &'static str = "\x1b[36m";
    pub const WHITE: &'static str = "\x1b[37m";
    pub const GRAY: &'static str = "\x1b[90m";
}

/// Apply color formatting to text if color is supported
pub fn colorize(text: &str, color: Option<&str>, bold: bool, dim: bool, use_color: bool) -> String {
    if !use_color {
        return text.to_string();
    }
    
    let mut result = String::new();
    
    if bold {
        result.push_str(Colors::BOLD);
    }
    if dim {
        result.push_str(Colors::DIM);
    }
    if let Some(color_code) = color {
        result.push_str(color_code);
    }
    
    result.push_str(text);
    
    if bold || dim || color.is_some() {
        result.push_str(Colors::RESET);
    }
    
    result
}

/// Simple colorize for bold text
pub fn bold(text: &str, use_color: bool) -> String {
    colorize(text, None, true, false, use_color)
}

/// Simple colorize for dim text
pub fn dim(text: &str, use_color: bool) -> String {
    colorize(text, None, false, true, use_color)
}


--- FILE: display/array_formatter.rs ---
/*!
Rich display formatter for GraphArray structures.
*/

use std::collections::HashMap;
use super::{DisplayConfig, unicode_chars::*};

/// Format a GraphArray for rich display
pub fn format_array(array_data: HashMap<String, serde_json::Value>, config: &DisplayConfig) -> String {
    let formatter = ArrayDisplayFormatter::new(config);
    formatter.format(array_data)
}

pub struct ArrayDisplayFormatter {
    max_rows: usize,
    precision: usize,
    use_color: bool,
}

impl ArrayDisplayFormatter {
    pub fn new(config: &DisplayConfig) -> Self {
        Self {
            max_rows: config.max_rows,
            precision: config.precision,
            use_color: config.use_color,
        }
    }
    
    pub fn format(&self, array_data: HashMap<String, serde_json::Value>) -> String {
        let data = self.extract_data(&array_data);
        let dtype = self.extract_dtype(&array_data);
        let shape = self.extract_shape(&array_data);
        let name = self.extract_name(&array_data);
        
        let mut lines = Vec::new();
        
        // Header
        lines.push(format!("{} gr.array", Symbols::HEADER_PREFIX));
        
        if data.is_empty() {
            lines.push("(empty array)".to_string());
            return lines.join("\n");
        }
        
        // Table-like display for arrays
        let col_name = if name.is_empty() { "array" } else { &name };
        let header_line = format!("{} {} {}", 
            BoxChars::TOP_LEFT,
            format!("{}{}{}",
                BoxChars::HORIZONTAL.repeat(3),
                BoxChars::T_TOP,
                BoxChars::HORIZONTAL.repeat(col_name.len() + 2)
            ),
            BoxChars::TOP_RIGHT
        );
        lines.push(header_line);
        
        // Column headers
        let header_row = format!("{} {} {} {} {} {}",
            BoxChars::VERTICAL,
            bold("#", self.use_color),
            BoxChars::VERTICAL,
            bold(col_name, self.use_color),
            BoxChars::VERTICAL,
            ""
        );
        lines.push(header_row);
        
        // Type header
        let type_row = format!("{} {} {} {} {} {}",
            BoxChars::VERTICAL,
            "",
            BoxChars::VERTICAL,
            dim(&self.format_dtype(&dtype), self.use_color),
            BoxChars::VERTICAL,
            ""
        );
        lines.push(type_row);
        
        // Separator
        let sep_line = format!("{} {} {} {} {} {}",
            BoxChars::T_LEFT,
            BoxChars::HORIZONTAL.repeat(3),
            BoxChars::CROSS,
            BoxChars::HORIZONTAL.repeat(col_name.len() + 2),
            BoxChars::T_RIGHT,
            ""
        );
        lines.push(sep_line);
        
        // Data rows
        let max_display = self.max_rows.min(data.len());
        let show_truncation = data.len() > self.max_rows;
        
        if show_truncation && max_display >= 4 {
            // Show first few and last few
            let show_first = (max_display - 1) / 2;
            let show_last = max_display - show_first - 1;
            
            // First rows
            for i in 0..show_first {
                let formatted_value = self.format_array_value(&data[i], &dtype);
                let data_row = format!("{} {:>3} {} {:<width$} {}",
                    BoxChars::VERTICAL,
                    i,
                    BoxChars::VERTICAL,
                    formatted_value,
                    BoxChars::VERTICAL,
                    width = col_name.len()
                );
                lines.push(data_row);
            }
            
            // Ellipsis row
            let ellipsis_row = format!("{} {:>3} {} {:<width$} {}",
                BoxChars::VERTICAL,
                Symbols::ELLIPSIS,
                BoxChars::VERTICAL,
                Symbols::ELLIPSIS,
                BoxChars::VERTICAL,
                width = col_name.len()
            );
            lines.push(ellipsis_row);
            
            // Last rows
            for i in (data.len() - show_last)..data.len() {
                let formatted_value = self.format_array_value(&data[i], &dtype);
                let data_row = format!("{} {:>3} {} {:<width$} {}",
                    BoxChars::VERTICAL,
                    i,
                    BoxChars::VERTICAL,
                    formatted_value,
                    BoxChars::VERTICAL,
                    width = col_name.len()
                );
                lines.push(data_row);
            }
        } else {
            // Show all rows (up to max_display)
            for i in 0..max_display {
                let formatted_value = self.format_array_value(&data[i], &dtype);
                let data_row = format!("{} {:>3} {} {:<width$} {}",
                    BoxChars::VERTICAL,
                    i,
                    BoxChars::VERTICAL,
                    formatted_value,
                    BoxChars::VERTICAL,
                    width = col_name.len()
                );
                lines.push(data_row);
            }
        }
        
        // Bottom border
        let bottom_line = format!("{} {} {} {} {} {}",
            BoxChars::BOTTOM_LEFT,
            BoxChars::HORIZONTAL.repeat(3),
            BoxChars::T_BOTTOM,
            BoxChars::HORIZONTAL.repeat(col_name.len() + 2),
            BoxChars::BOTTOM_RIGHT,
            ""
        );
        lines.push(bottom_line);
        
        // Shape info
        lines.push(format!("shape: ({})", shape));
        
        lines.join("\n")
    }
    
    fn format_array_value(&self, value: &serde_json::Value, dtype: &str) -> String {
        match value {
            serde_json::Value::Null => Symbols::NULL_DISPLAY.to_string(),
            serde_json::Value::Number(n) => {
                if dtype.contains("float") {
                    if let Some(f) = n.as_f64() {
                        if f.is_nan() || f.is_infinite() {
                            Symbols::NULL_DISPLAY.to_string()
                        } else {
                            format!("{:.prec$}", f, prec = self.precision)
                        }
                    } else {
                        n.to_string()
                    }
                } else {
                    n.to_string()
                }
            }
            serde_json::Value::String(s) => {
                if s.len() > 12 {
                    format!("{}{}", &s[..11], Symbols::ELLIPSIS)
                } else {
                    s.clone()
                }
            }
            serde_json::Value::Bool(b) => b.to_string(),
            _ => value.to_string().trim_matches('"').to_string(),
        }
    }
    
    fn format_dtype(&self, dtype: &str) -> String {
        let dtype_map = [
            ("string", "str"),
            ("int64", "i64"),
            ("int32", "i32"),
            ("float64", "f64"),
            ("float32", "f32"),
            ("bool", "bool"),
            ("object", "obj"),
        ];
        
        dtype_map.iter()
            .find(|(k, _)| *k == dtype)
            .map(|(_, v)| v.to_string())
            .unwrap_or_else(|| dtype.to_string())
    }
    
    fn extract_data(&self, data: &HashMap<String, serde_json::Value>) -> Vec<serde_json::Value> {
        data.get("data")
            .and_then(|v| v.as_array())
            .map(|arr| arr.clone())
            .unwrap_or_default()
    }
    
    fn extract_dtype(&self, data: &HashMap<String, serde_json::Value>) -> String {
        data.get("dtype")
            .and_then(|v| v.as_str())
            .unwrap_or("object")
            .to_string()
    }
    
    fn extract_shape(&self, data: &HashMap<String, serde_json::Value>) -> usize {
        data.get("shape")
            .and_then(|v| v.as_array())
            .and_then(|arr| arr.first())
            .and_then(|v| v.as_u64())
            .unwrap_or(0) as usize
    }
    
    fn extract_name(&self, data: &HashMap<String, serde_json::Value>) -> String {
        data.get("name")
            .and_then(|v| v.as_str())
            .unwrap_or("array")
            .to_string()
    }
}


--- FILE: display/truncation.rs ---
/*!
Text truncation utilities for display formatting.
Direct Rust port of the Python truncation.py module.
*/

use std::cmp;

/// Truncate a string to specified width, adding ellipsis if needed
pub fn truncate_string(text: &str, max_width: usize) -> String {
    if text.chars().count() <= max_width {
        text.to_string()
    } else {
        let truncated: String = text.chars().take(max_width.saturating_sub(1)).collect();
        format!("{}{}", truncated, super::unicode_chars::Symbols::ELLIPSIS)
    }
}

/// Truncate rows to maximum display count
pub fn truncate_rows<T: Clone>(data: Vec<T>, max_rows: usize) -> (Vec<T>, bool) {
    if data.len() <= max_rows {
        (data, false)
    } else {
        let show_first = max_rows / 2;
        let show_last = max_rows - show_first - 1; // -1 for ellipsis row
        
        let mut result = Vec::new();
        
        // Add first rows
        result.extend(data.iter().take(show_first).cloned());
        
        // Add ellipsis placeholder (represented as special marker)
        // We'll handle this in the calling code
        
        // Add last rows
        if show_last > 0 {
            result.extend(data.iter().skip(data.len() - show_last).cloned());
        }
        
        (result, true)
    }
}

/// Truncate columns to maximum display count
pub fn truncate_columns<T: Clone>(
    headers: Vec<T>,
    data: Vec<Vec<T>>,
    max_cols: usize,
) -> (Vec<T>, Vec<Vec<T>>, bool) {
    if headers.len() <= max_cols {
        (headers, data, false)
    } else {
        let show_first = max_cols / 2;
        let show_last = max_cols - show_first - 1; // -1 for ellipsis column
        
        // Truncate headers
        let mut truncated_headers = Vec::new();
        truncated_headers.extend(headers.iter().take(show_first).cloned());
        // Ellipsis header will be added by calling code
        if show_last > 0 {
            truncated_headers.extend(headers.iter().skip(headers.len() - show_last).cloned());
        }
        
        // Truncate data rows
        let truncated_data: Vec<Vec<T>> = data
            .into_iter()
            .map(|row| {
                let mut truncated_row = Vec::new();
                truncated_row.extend(row.iter().take(show_first).cloned());
                // Ellipsis cell will be added by calling code
                if show_last > 0 {
                    truncated_row.extend(row.iter().skip(row.len() - show_last).cloned());
                }
                truncated_row
            })
            .collect();
        
        (truncated_headers, truncated_data, true)
    }
}

/// Calculate optimal column widths for display
pub fn calculate_column_widths(
    headers: &[String],
    data: &[Vec<String>],
    max_total_width: usize,
) -> Vec<usize> {
    let num_cols = headers.len();
    if num_cols == 0 {
        return Vec::new();
    }
    
    // Calculate minimum required width for each column
    let mut min_widths: Vec<usize> = headers.iter().map(|h| h.chars().count()).collect();
    
    for row in data {
        for (i, cell) in row.iter().enumerate() {
            if i < min_widths.len() {
                min_widths[i] = cmp::max(min_widths[i], cell.chars().count());
            }
        }
    }
    
    // Calculate available width (accounting for borders and padding)
    // Each column needs: | padding content padding |
    // So we need: num_cols * 3 + 1 characters for borders/padding
    let border_overhead = num_cols * 3 + 1;
    let available_width = max_total_width.saturating_sub(border_overhead);
    
    let total_min_width: usize = min_widths.iter().sum();
    
    if total_min_width <= available_width {
        // We have extra space - distribute it proportionally
        let extra_space = available_width - total_min_width;
        let extra_per_col = extra_space / num_cols;
        let remainder = extra_space % num_cols;
        
        for (i, width) in min_widths.iter_mut().enumerate() {
            *width += extra_per_col;
            if i < remainder {
                *width += 1; // Distribute remainder to first few columns
            }
        }
    } else {
        // Not enough space - we need to truncate some columns
        // For now, just use minimum widths (truncation will happen in formatting)
    }
    
    min_widths
}


--- FILE: display/table_formatter.rs ---
/*!
Rich display formatter for GraphTable structures.
Direct Rust port of the Python table_display.py module using native Rust.
*/

use std::collections::HashMap;
use super::{DisplayConfig, unicode_chars::*, truncation::*};

/// Format a GraphTable for rich display
pub fn format_table(table_data: HashMap<String, serde_json::Value>, config: &DisplayConfig) -> String {
    let formatter = TableDisplayFormatter::new(config);
    formatter.format(table_data)
}

/// Formatter for GraphTable rich display with Polars-style formatting
pub struct TableDisplayFormatter {
    max_rows: usize,
    max_cols: usize,
    max_width: usize,
    precision: usize,
    use_color: bool,
}

impl TableDisplayFormatter {
    pub fn new(config: &DisplayConfig) -> Self {
        Self {
            max_rows: config.max_rows,
            max_cols: config.max_cols,
            max_width: config.max_width,
            precision: config.precision,
            use_color: config.use_color,
        }
    }
    
    pub fn format(&self, table_data: HashMap<String, serde_json::Value>) -> String {
        let columns = self.extract_columns(&table_data);
        let dtypes = self.extract_dtypes(&table_data);
        let data = self.extract_data(&table_data);
        let shape = self.extract_shape(&table_data);
        let nulls = self.extract_nulls(&table_data);
        let index_type = self.extract_index_type(&table_data);
        
        if columns.is_empty() || data.is_empty() {
            return self.format_empty_table();
        }
        
        // Add index column
        let mut headers = vec!["#".to_string()];
        headers.extend(columns.clone());
        
        let mut type_headers = vec!["".to_string()];
        for col in &columns {
            type_headers.push(self.format_dtype(dtypes.get(col).map(String::as_str).unwrap_or("object")));
        }
        
        // Add row indices to data
        let mut indexed_data = Vec::new();
        for (i, row) in data.iter().enumerate() {
            let mut indexed_row = vec![i.to_string()];
            for (j, val) in row.iter().enumerate() {
                let col_dtype = if j < columns.len() {
                    dtypes.get(&columns[j]).map(String::as_str).unwrap_or("object")
                } else {
                    "object"
                };
                indexed_row.push(self.format_value(val, col_dtype));
            }
            indexed_data.push(indexed_row);
        }
        
        // Truncate if necessary
        let (truncated_data, _rows_truncated) = truncate_rows(indexed_data, self.max_rows);
        let (truncated_headers, truncated_data, _cols_truncated) = 
            truncate_columns(headers, truncated_data, self.max_cols);
        let truncated_type_headers: Vec<String> = type_headers.into_iter()
            .take(truncated_headers.len()).collect();
        
        // Calculate column widths
        let col_widths = calculate_column_widths(&truncated_headers, &truncated_data, self.max_width);
        
        // Build the formatted table
        let mut lines = Vec::new();
        
        // Header with section indicator
        lines.push(format!("{} gr.table", Symbols::HEADER_PREFIX));
        
        // Top border
        lines.push(self.build_border_line(&col_widths, BorderPosition::Top));
        
        // Column headers
        lines.push(self.build_data_line(&truncated_headers, &col_widths, LineStyle::Bold));
        lines.push(self.build_data_line(&truncated_type_headers, &col_widths, LineStyle::Dim));
        
        // Header separator
        lines.push(self.build_border_line(&col_widths, BorderPosition::Middle));
        
        // Data rows
        for row in &truncated_data {
            lines.push(self.build_data_line(row, &col_widths, LineStyle::Normal));
        }
        
        // Bottom border
        lines.push(self.build_border_line(&col_widths, BorderPosition::Bottom));
        
        // Summary statistics
        let mut summary_parts = vec![
            format!("rows: {}", self.format_number(shape.0)),
            format!("cols: {}", shape.1),
        ];
        
        if !nulls.is_empty() {
            let null_info: Vec<String> = nulls.iter()
                .map(|(col, count)| format!("{}={}", col, count))
                .collect();
            summary_parts.push(format!("nulls: {}", null_info.join(", ")));
        }
        
        summary_parts.push(format!("index: {}", index_type));
        let summary = summary_parts.join(&format!(" {} ", Symbols::DOT_SEPARATOR));
        lines.push(summary);
        
        lines.join("\n")
    }
    
    fn format_empty_table(&self) -> String {
        format!("{} gr.table (empty)", Symbols::HEADER_PREFIX)
    }
    
    fn format_dtype(&self, dtype: &str) -> String {
        let dtype_map = [
            ("string", "str"),
            ("category", "cat"),
            ("int64", "i64"),
            ("int32", "i32"),
            ("float64", "f64"),
            ("float32", "f32"),
            ("bool", "bool"),
            ("datetime", "date"),
            ("object", "obj"),
        ];
        
        let base_type = dtype_map.iter()
            .find(|(k, _)| *k == dtype)
            .map(|(_, v)| *v)
            .unwrap_or(dtype);
        
        // Add size hints for string/category types
        match dtype {
            "string" | "str" => format!("{}[8]", base_type),
            "category" | "cat" => format!("{}(12)", base_type),
            _ => base_type.to_string(),
        }
    }
    
    fn format_value(&self, value: &serde_json::Value, dtype: &str) -> String {
        match value {
            serde_json::Value::Null => Symbols::NULL_DISPLAY.to_string(),
            serde_json::Value::Number(n) => {
                if dtype.contains("float") {
                    if let Some(f) = n.as_f64() {
                        if f.is_nan() || f.is_infinite() {
                            Symbols::NULL_DISPLAY.to_string()
                        } else {
                            format!("{:.prec$}", f, prec = self.precision)
                        }
                    } else {
                        n.to_string()
                    }
                } else {
                    n.to_string()
                }
            }
            serde_json::Value::String(s) => {
                if dtype.contains("date") {
                    truncate_string(s, 10)
                } else {
                    truncate_string(s, 12)
                }
            }
            serde_json::Value::Bool(b) => b.to_string(),
            _ => value.to_string().trim_matches('"').to_string(),
        }
    }
    
    fn format_number(&self, n: usize) -> String {
        // Note: Rust doesn't support comma formatting by default
        // For now, just return the number as string
        n.to_string()
    }
    
    // Helper methods for extraction
    fn extract_columns(&self, data: &HashMap<String, serde_json::Value>) -> Vec<String> {
        data.get("columns")
            .and_then(|v| v.as_array())
            .map(|arr| arr.iter().filter_map(|v| v.as_str().map(String::from)).collect())
            .unwrap_or_default()
    }
    
    fn extract_dtypes(&self, data: &HashMap<String, serde_json::Value>) -> HashMap<String, String> {
        data.get("dtypes")
            .and_then(|v| v.as_object())
            .map(|obj| {
                obj.iter()
                    .filter_map(|(k, v)| v.as_str().map(|s| (k.clone(), s.to_string())))
                    .collect()
            })
            .unwrap_or_default()
    }
    
    fn extract_data(&self, data: &HashMap<String, serde_json::Value>) -> Vec<Vec<serde_json::Value>> {
        data.get("data")
            .and_then(|v| v.as_array())
            .map(|arr| {
                arr.iter()
                    .filter_map(|row| {
                        row.as_array().map(|row_arr| row_arr.clone())
                    })
                    .collect()
            })
            .unwrap_or_default()
    }
    
    fn extract_shape(&self, data: &HashMap<String, serde_json::Value>) -> (usize, usize) {
        data.get("shape")
            .and_then(|v| v.as_array())
            .and_then(|arr| {
                if arr.len() >= 2 {
                    let rows = arr[0].as_u64().unwrap_or(0) as usize;
                    let cols = arr[1].as_u64().unwrap_or(0) as usize;
                    Some((rows, cols))
                } else {
                    None
                }
            })
            .unwrap_or((0, 0))
    }
    
    fn extract_nulls(&self, data: &HashMap<String, serde_json::Value>) -> HashMap<String, usize> {
        data.get("nulls")
            .and_then(|v| v.as_object())
            .map(|obj| {
                obj.iter()
                    .filter_map(|(k, v)| v.as_u64().map(|n| (k.clone(), n as usize)))
                    .collect()
            })
            .unwrap_or_default()
    }
    
    fn extract_index_type(&self, data: &HashMap<String, serde_json::Value>) -> String {
        data.get("index_type")
            .and_then(|v| v.as_str())
            .unwrap_or("int64")
            .to_string()
    }
}

#[derive(Copy, Clone)]
enum BorderPosition {
    Top,
    Middle,
    Bottom,
}

#[derive(Copy, Clone)]
enum LineStyle {
    Normal,
    Bold,
    Dim,
}

impl TableDisplayFormatter {
    fn build_border_line(&self, col_widths: &[usize], position: BorderPosition) -> String {
        let (left, right, sep) = match position {
            BorderPosition::Top => (BoxChars::TOP_LEFT, BoxChars::TOP_RIGHT, BoxChars::T_TOP),
            BorderPosition::Middle => (BoxChars::T_LEFT, BoxChars::T_RIGHT, BoxChars::CROSS),
            BorderPosition::Bottom => (BoxChars::BOTTOM_LEFT, BoxChars::BOTTOM_RIGHT, BoxChars::T_BOTTOM),
        };
        
        let segments: Vec<String> = col_widths.iter()
            .map(|&width| BoxChars::HORIZONTAL.repeat(width + 2)) // +2 for padding
            .collect();
        
        format!("{}{}{}", left, segments.join(sep), right)
    }
    
    fn build_data_line(&self, row_data: &[String], col_widths: &[usize], style: LineStyle) -> String {
        let cells: Vec<String> = row_data.iter()
            .zip(col_widths.iter())
            .enumerate()
            .map(|(i, (value, &width))| {
                // Truncate if value is too long
                let display_value = truncate_string(value, width);
                
                // Pad to column width (left-align for most, right-align for numbers in index)
                let padded = if i == 0 {
                    // Index column - right align
                    format!("{:>width$}", display_value, width = width)
                } else {
                    // Data columns - left align
                    format!("{:<width$}", display_value, width = width)
                };
                
                // Apply formatting
                let formatted = match style {
                    LineStyle::Bold => bold(&padded, self.use_color),
                    LineStyle::Dim => dim(&padded, self.use_color),
                    LineStyle::Normal => padded,
                };
                
                format!(" {} ", formatted) // Add padding around content
            })
            .collect();
        
        format!("{}{}{}", BoxChars::VERTICAL, cells.join(BoxChars::VERTICAL), BoxChars::VERTICAL)
    }
}


